name: Run build and tests (ya make)
description: Run test targets listed in repository root ya.make (to be created previously)
inputs:
  build_target:
    required: true
  build_preset:
    required: true
    default: "relwithdebinfo"
    description: "relwithdebinfo, release-asan, release-tsan"
  test_type:
    required: false
    type: string
    default: ""
    description: "run only specific test types (or all by default)"
  test_size:
    required: false
    default: "small,medium,large"
    description: "small or small-medium or all"
  test_threads:
    required: false
    default: "56"
    description: "Test threads count"
  link_threads:
    required: false
    default: "12"
    description: "link threads count"
  additional_ya_make_args:
    type: string
    default: ""
  increment:
    type: boolean
    required: true
    description: If true, compares build graphs between the current and previous commits to find a list of test suites to run. Otherwise, runs all tests.
  put_build_results_to_cache:
    required: false
    default: "true"
  bazel_remote_uri:
    required: false
    description: "bazel-remote endpoint"
  bazel_remote_username:
    required: false
    description: "bazel-remote username"
  bazel_remote_password:
    required: false
    description: "bazel-remote password"
  run_tests:
    type: boolean
    default: true
    description: "run tests"
  test_retry_count:
    type: string
    default: ""
    description: "how many times to retry failed tests"
  custom_branch_name:
    description: "Custom branch name required when workflow branch != checkout branch"
    type: string
    required: false
  add_vcs_info:
    type: boolean
    default: false
    description: "add ya make vars with git info"
  telegram_ydbot_token:
    type: string
    required: false
    description: "Telegram bot token"
  telegram_alert_logins:
    type: string
    required: false
    description: "Telegram alert logins"
  telegram_alert_chat:
    type: string
    required: false
    description: "Telegram alert chat"
  collect_coredumps:
    type: boolean
    default: false
    description: "Collect coredumps via enabling ulimit -c unlimited"
  pull_number:
    type: string
    required: false
    description: "Pull request number (for workflow_call events)"

outputs:
  success:
    value: ${{ steps.build.outputs.status }}
    description: "build success"

runs:
  using: "composite"
  steps:
    - name: comment-build-start
      if: github.event_name == 'pull_request' || github.event_name == 'pull_request_target'
      shell: bash
      env:
        BUILD_PRESET: ${{ inputs.build_preset }}
        GITHUB_TOKEN: ${{ github.token }}
      run: |
        jobs_url="https://api.github.com/repos/${GITHUB_REPOSITORY}/actions/runs/${GITHUB_RUN_ID}/jobs"
        # tricky: we are searching job with name that contains build_preset
        check_url=$(curl -s $jobs_url | jq --arg n "$BUILD_PRESET" -r '.jobs[] | select(.name | contains($n)) | .html_url')

        platform_name="$(echo "$(uname -s)-$(uname -p)" | tr '[:upper:]' '[:lower:]')-$BUILD_PRESET"
        echo "Pre-commit [check]($check_url) **$platform_name** for $(git rev-parse HEAD) has started." | .github/scripts/tests/comment-pr.py --rewrite

        curl -L -X POST -H "Accept: application/vnd.github+json" -H "Authorization: Bearer ${{github.token}}" -H "X-GitHub-Api-Version: 2022-11-28" \
          https://api.github.com/repos/${{github.repository}}/statuses/${{github.event.pull_request.head.sha}} \
          -d '{"state":"pending","description":"The check has been started","context":"build_${{inputs.build_preset}}"}'

        if [[ "${{inputs.run_tests}}" == "true" ]]; then
          curl -L -X POST -H "Accept: application/vnd.github+json" -H "Authorization: Bearer ${{github.token}}" -H "X-GitHub-Api-Version: 2022-11-28" \
            https://api.github.com/repos/${{github.repository}}/statuses/${{github.event.pull_request.head.sha}} \
            -d '{"state":"pending","description":"The check has been started","context":"test_${{inputs.build_preset}}"}'
        fi

    - name: Clean ya cache
      shell: bash
      run: rm -rf ~/.ya

    - name: Init
      id: init
      shell: bash
      run: |
        set -x

        echo "$(pwd)/ydb/ci/scripts" >> $GITHUB_PATH

        export TMP_DIR=$(pwd)/tmp
        rm -rf $TMP_DIR
        mkdir -p $TMP_DIR
        echo "TMP_DIR=$TMP_DIR" >> $GITHUB_ENV

        # The whole dir will be uploaded to s3 with public (=wild internet) ACL
        export PUBLIC_DIR=$TMP_DIR/results
        echo "PUBLIC_DIR=$PUBLIC_DIR" >> $GITHUB_ENV
        export PUBLIC_DIR_URL=$S3_URL_PREFIX
        echo "PUBLIC_DIR_URL=$PUBLIC_DIR_URL" >> $GITHUB_ENV
        mkdir -p $PUBLIC_DIR

        echo "LAST_BUILD_RESULTS_REPORT=$PUBLIC_DIR/last_report.json" >> $GITHUB_ENV
        echo "SUMMARY_LINKS=$PUBLIC_DIR/summary_links.txt" >> $GITHUB_ENV
        echo "BUILD_PRESET=${{ inputs.build_preset }}" >> $GITHUB_ENV

        python3 -m pip install ydb ydb[yc] codeowners humanize plotly

    - name: Setup cache
      shell: bash
      run: |
        export BAZEL_REMOTE_PASSWORD_FILE=$(mktemp)
        echo -n "${{ inputs.bazel_remote_password }}" > $BAZEL_REMOTE_PASSWORD_FILE
        echo "BAZEL_REMOTE_PASSWORD_FILE=$BAZEL_REMOTE_PASSWORD_FILE" >> $GITHUB_ENV

    - name: ya build and test
      id: build
      shell: bash
      env:
        COLLECT_COREDUMPS: ${{ inputs.collect_coredumps }}
        TELEGRAM_BOT_TOKEN: ${{ inputs.telegram_ydbot_token }}
        GH_ALERTS_TG_LOGINS: ${{ inputs.telegram_alert_logins }}
        GH_ALERTS_TG_CHAT: ${{ inputs.telegram_alert_chat }}
        PR_NUMBER: ${{ inputs.pull_number }}
        GITHUB_REF_NAME: ${{ github.ref_name }}
        GITHUB_BASE_REF: ${{ github.base_ref }}
        GITHUB_EVENT_NAME: ${{ github.event_name }}
      run: |
        set -ex
        
        if [ "$COLLECT_COREDUMPS" = "true" ]; then
          sudo mkdir -p /coredumps
          sudo chmod 1777 /coredumps
          echo "/coredumps/%p.%s" | sudo tee /proc/sys/kernel/core_pattern
          ulimit -c unlimited
        else
          ulimit -c 0
        fi

        echo "Artifacts will be uploaded [here](${PUBLIC_DIR_URL}/index.html)" | GITHUB_TOKEN="${{ github.token }}" .github/scripts/tests/comment-pr.py

        # Save original HEAD before any git operations (checkout scripts, graph_compare, etc.)
        ORIGINAL_HEAD=$(git rev-parse HEAD)
        echo "ORIGINAL_HEAD=$ORIGINAL_HEAD" >> $GITHUB_ENV

        readarray -d ',' -t test_size < <(printf "%s" "${{ inputs.test_size }}")
        readarray -d ',' -t test_type < <(printf "%s" "${{ inputs.test_type }}")

        export TEST_ICRDMA=1

        params=(
          -T
          ${test_size[@]/#/--test-size=} ${test_type[@]/#/--test-type=}
          --stat
          --test-threads "${{ inputs.test_threads }}" --link-threads "${{ inputs.link_threads }}"
          -DUSE_EAT_MY_DATA
          --add-peerdirs-tests all
        )

        TEST_RETRY_COUNT=${{ inputs.test_retry_count }}
        IS_TEST_RESULT_IGNORED=0

        case "$BUILD_PRESET" in
          debug)
            params+=(--build "debug")
            ;;
          relwithdebinfo)
            params+=(--build "relwithdebinfo")
            ;;
          release)
            params+=(--build "release")
            ;;
          release-asan)
            params+=(
              --build "release" --sanitize="address"
            )
            if [ -z $TEST_RETRY_COUNT ]; then
              TEST_RETRY_COUNT=1
            fi
            IS_TEST_RESULT_IGNORED=1
            ;;
          release-tsan)
            params+=(
              --build "release" --sanitize="thread"
            )
            if [ -z $TEST_RETRY_COUNT ]; then
              TEST_RETRY_COUNT=1
            fi
            IS_TEST_RESULT_IGNORED=1
            ;;
          release-msan)
            params+=(
              --build "release" --sanitize="memory"
            )
            if [ -z $TEST_RETRY_COUNT ]; then
              TEST_RETRY_COUNT=1
            fi
            IS_TEST_RESULT_IGNORED=1
            ;;
          *)
            echo "Invalid preset: $BUILD_PRESET"
            exit 1
            ;;
        esac

        echo "IS_TEST_RESULT_IGNORED=$IS_TEST_RESULT_IGNORED" >> $GITHUB_ENV

        if [ -z $TEST_RETRY_COUNT ]; then
          # default is 3 for ordinary build and 1 for sanitizer builds
          TEST_RETRY_COUNT=3
        fi

        if [ ! -z "${{ inputs.additional_ya_make_args }}" ]; then
          params+=(${{ inputs.additional_ya_make_args }})
        fi

        params+=(
          --stat -DCONSISTENT_DEBUG --no-dir-outputs
          --test-failure-code 0 --build-all
          --cache-size 2TB --force-build-depends
        )

        echo "inputs.custom_branch_name = ${{ inputs.custom_branch_name }}"
        echo "GITHUB_REF_NAME = ${GITHUB_REF_NAME}"
        echo "GITHUB_BASE_REF = ${GITHUB_BASE_REF}"
        echo "GITHUB_EVENT_NAME = ${GITHUB_EVENT_NAME}"

        if [ -z "${{ inputs.custom_branch_name }}" ]; then
          # For pull requests, use the target branch (base_ref) - this ensures that:
          # - Test history is shown for the target branch (e.g., stable-25-3)
          # - Test results are uploaded for the target branch
          # For other events (push, workflow_dispatch), use ref_name (the branch that triggered the workflow)
          if [ "${GITHUB_EVENT_NAME}" = "pull_request" ] || [ "${GITHUB_EVENT_NAME}" = "pull_request_target" ]; then
            BRANCH_NAME="${GITHUB_BASE_REF}"
          else
            BRANCH_NAME="${GITHUB_REF_NAME}"
          fi
        else
          BRANCH_NAME="${{ inputs.custom_branch_name }}"
        fi

        if [[ "${{inputs.add_vcs_info}}" == "true" ]]; then
          params+=(
            -DGIT_BRANCH=$BRANCH_NAME
            -DGIT_COMMIT_SHA=$ORIGINAL_HEAD
          )
        fi

        echo "BRANCH_NAME=$BRANCH_NAME" >> $GITHUB_ENV
        echo "BRANCH_NAME is set to $BRANCH_NAME"

        echo "::debug::get version"
        ./ya --version

        if [ true = ${{ inputs.run_tests }} ]; then
            params+=(-A)
        fi
        YA_MAKE_COMMAND="./ya make ${params[@]}"
        GRAPH_PATH=$(realpath graph.json)
        CONTEXT_PATH=$(realpath context.json)
        if [ "${{ inputs.increment }}" = "true" ]; then
          GRAPH_COMPARE_OUTPUT="$PUBLIC_DIR/graph_compare_log.txt"
          GRAPH_COMPARE_OUTPUT_URL="$PUBLIC_DIR_URL/graph_compare_log.txt"

          set +e
          ./.github/scripts/graph_compare.py --ya-make-command="$YA_MAKE_COMMAND" --result-graph-path=$GRAPH_PATH --result-context-path=$CONTEXT_PATH $ORIGINAL_HEAD~1 $ORIGINAL_HEAD |& tee $GRAPH_COMPARE_OUTPUT
          RC=${PIPESTATUS[0]}
          set -e

          if [ $RC -ne 0 ]; then
            echo "graph_compare.py returned $RC, build failed"
            echo "status=failed" >> $GITHUB_OUTPUT
            BUILD_FAILED=1
            echo "Graph compare failed, see the [logs]($GRAPH_COMPARE_OUTPUT_URL)." | GITHUB_TOKEN="${{ github.token }}"  .github/scripts/tests/comment-pr.py --color red
            exit $RC
          fi

          git checkout $ORIGINAL_HEAD
          YA_MAKE_TARGET="ydb"
        else
          YA_MAKE_TARGET=""
          for TARGET in ${{ inputs.build_target }}; do
             if [ -e $TARGET ]; then
                YA_MAKE_TARGET="$YA_MAKE_TARGET $TARGET"
             fi
          done
          if [ true = ${{ inputs.run_tests }} ]; then
            YA_MAKE_COMMAND+=" --retest"
          fi
          $YA_MAKE_COMMAND -k --cache-tests \
            --save-graph-to $GRAPH_PATH --save-context-to $CONTEXT_PATH \
            $YA_MAKE_TARGET
        fi

        # Scripts to checkout from main
        MAIN_SCRIPTS=(
          ".github/scripts/config/ydb_qa_config.json"
          ".github/scripts/analytics/upload_tests_results.py"
          ".github/scripts/analytics/ydb_wrapper.py"
          ".github/scripts/send_build_stats.py"
          ".github/scripts/get_build_diff.py"
          ".github/scripts/get_current_build_size.py"
          ".github/scripts/get_main_build_size.py"
          ".github/scripts/check_ydb_qa_config.py"
          ".github/scripts/tests/generate-summary.py"
          ".github/scripts/tests/fail-checker.py"
          ".github/scripts/tests/transform_build_results.py"
        )
        
        # Ensure main is available (may be missing in shallow clone)
        if ! git rev-parse --verify main >/dev/null 2>&1; then
          git fetch origin main:main --depth=1 2>/dev/null || true
        fi
        
        # For each script: if unchanged in PR - use from main
        # git checkout main -- "$script" doesn't change HEAD, only files in working directory
        for script in "${MAIN_SCRIPTS[@]}"; do
          if git diff --quiet main HEAD -- "$script" 2>/dev/null; then
            git checkout main -- "$script" 2>/dev/null && echo "✅ $script"
          else
            echo "✅ $script (PR version)"
          fi
        done
        
        # Check YDB configuration (after checkout from main)
        python3 .github/scripts/check_ydb_qa_config.py || true

        if [ ! -z "${{ inputs.bazel_remote_uri }}" ]; then
          params+=(--bazel-remote-store)
          params+=(--bazel-remote-base-uri "${{ inputs.bazel_remote_uri }}")
        fi

        if [ "${{ inputs.put_build_results_to_cache }}" = "true" ]; then
          params+=(--bazel-remote-username "${{ inputs.bazel_remote_username }}")
          params+=(--bazel-remote-password-file "$BAZEL_REMOTE_PASSWORD_FILE")
          params+=(--bazel-remote-put --dist-cache-max-file-size=209715200 --dist-cache-evict-test-runs)
        fi

        if [ true = ${{ inputs.run_tests }} ]; then
          params+=(-A)
          params+=(--retest)
        fi

        YA_MAKE_OUT_DIR=$TMP_DIR/out

        YA_MAKE_OUTPUT="$PUBLIC_DIR/ya_make_output.txt"
        YA_MAKE_OUTPUT_URL="$PUBLIC_DIR_URL/ya_make_output.txt"
        echo "20 [Ya make output]($YA_MAKE_OUTPUT_URL)" >> $SUMMARY_LINKS

        BUILD_FAILED=0

        for RETRY in $(seq 1 $TEST_RETRY_COUNT)
        do
          if [ $RETRY != 1 ]; then
            IS_RETRY=1
          else
            IS_RETRY=0
          fi

          CURRENT_PUBLIC_DIR_RELATIVE=try_$RETRY
          # Can be used in tests in which you want to publish the results in s3 for each retry separately
          export CURRENT_PUBLIC_DIR=$PUBLIC_DIR/$CURRENT_PUBLIC_DIR_RELATIVE
          export CURRENT_PUBLIC_DIR_URL=$PUBLIC_DIR_URL/$CURRENT_PUBLIC_DIR_RELATIVE
          mkdir $CURRENT_PUBLIC_DIR
          export TEST_META_INFO=$CURRENT_PUBLIC_DIR/tests_meta
          mkdir $TEST_META_INFO

          CURRENT_MESSAGE="ya make is running..."
          if [ $IS_RETRY = 0 ]; then
            CURRENT_MESSAGE="$CURRENT_MESSAGE"
            RERUN_FAILED_OPT=""
          else
            CURRENT_MESSAGE="$CURRENT_MESSAGE (failed tests rerun, try $RETRY)"
            if [ -z "$GRAPH_PATH" ]; then
              RERUN_FAILED_OPT="-X --build-only-test-deps"
            else
              RERUN_FAILED_OPT=""
            fi
          fi

          echo $CURRENT_MESSAGE | GITHUB_TOKEN="${{ github.token }}" .github/scripts/tests/comment-pr.py

          CURRENT_REPORT=$CURRENT_PUBLIC_DIR/report.json

          monitor_memory() {
              set +x
              rm -f ram_usage.txt
              while true; do
                  used_kb=$(grep -E 'MemTotal|MemAvailable' /proc/meminfo | 
                            awk 'NR==1{t=$2} NR==2{a=$2} END{print t - a}')
                  echo "$(date +%s) $used_kb" >> ram_usage.txt
                  sleep 3
              done
          }

          monitor_memory &
          MONITOR_PID=$!
          if [ -n "$GRAPH_PATH" ] && [ -n "$CONTEXT_PATH" ]; then
            GRAPH_OPTS="--build-custom-json=$GRAPH_PATH --custom-context=$CONTEXT_PATH"
          else
            GRAPH_OPTS=""
          fi

          set +e
          (./ya make ${params[@]} $YA_MAKE_TARGET $GRAPH_OPTS \
            $RERUN_FAILED_OPT --log-file "$PUBLIC_DIR/ya_log.txt"  \
            --evlog-file "$CURRENT_PUBLIC_DIR/ya_evlog.jsonl" \
            --build-results-report "$CURRENT_REPORT" --output "$YA_MAKE_OUT_DIR"; echo $? > exit_code) |& cat >> $YA_MAKE_OUTPUT
          set -e
          RC=`cat exit_code`

          kill $MONITOR_PID

          .github/scripts/tests/report_analyzer.py --report_file "$CURRENT_REPORT" --summary_file $CURRENT_PUBLIC_DIR/summary_report.txt || true

          .github/scripts/report_ram_analyzer.py \
            --report-file "$CURRENT_REPORT" \
            --output-file $CURRENT_PUBLIC_DIR/ram_report.html \
            --output-file-url $CURRENT_PUBLIC_DIR_URL/ram_report.html \
            --ram-usage-file ram_usage.txt \
            --chat-id "$GH_ALERTS_TG_CHAT" \
            --memory-threshold 97 || true

          # convert to chromium trace
          # seems analyze-make don't have simple "output" parameter, so change cwd
          ya_dir=$(pwd)
          (cd $CURRENT_PUBLIC_DIR && $ya_dir/ya analyze-make timeline --evlog ya_evlog.jsonl)

          # generate test_bloat
          ./ydb/ci/build_bloat/test_bloat.py --build-results-report $CURRENT_REPORT --output_dir $CURRENT_PUBLIC_DIR/test_bloat || true
          echo "30 [Test bloat](${CURRENT_PUBLIC_DIR_URL}/test_bloat/tree_map.html)" >> $SUMMARY_LINKS

          if [ $RC -ne 0 ]; then
            echo "ya make returned $RC, build failed"
            echo "status=failed" >> $GITHUB_OUTPUT
            BUILD_FAILED=1
            # sed is to remove richness (tags like '[[rst]]')
            (( \
              cat $CURRENT_REPORT \
              | jq -r '.results[] | select((.status == "FAILED") and (.error_type == "REGULAR") and (.type = "build")) | "path: " + .path + "\n\n" + ."rich-snippet" + "\n\n\n"' \
              | sed 's/\[\[[^]]*]\]//g' \
            ) || true) > $CURRENT_PUBLIC_DIR/fail_summary.txt
            echo "Build failed, see the [logs]($YA_MAKE_OUTPUT_URL). Also see [fail summary]($CURRENT_PUBLIC_DIR_URL/fail_summary.txt)" | GITHUB_TOKEN="${{ github.token }}" .github/scripts/tests/comment-pr.py --color red
            break
          fi

          # archive build results report (orig)
          gzip -c $CURRENT_REPORT > $CURRENT_PUBLIC_DIR/orig_report.json.gz

          # postprocess build results report (add links, logs, mute tests etc)
          .github/scripts/tests/transform_build_results.py \
            --build-results-report "$CURRENT_REPORT" \
            --test_dir="$TEST_META_INFO" \
            -m .github/config/muted_ya.txt \
            --ya_out "$YA_MAKE_OUT_DIR" \
            --public_dir "$PUBLIC_DIR" \
            --public_dir_url "$PUBLIC_DIR_URL" \
            --log_out_dir "$CURRENT_PUBLIC_DIR_RELATIVE/artifacts/logs/" \
            --test_stuff_out "$CURRENT_PUBLIC_DIR_RELATIVE/test_artifacts/" || true
          cp $CURRENT_REPORT $LAST_BUILD_RESULTS_REPORT

          TESTS_RESULT=0
          .github/scripts/tests/fail-checker.py "$CURRENT_REPORT" --output_path $CURRENT_PUBLIC_DIR/failed_count.txt || TESTS_RESULT=$?
          FAILED_TESTS_COUNT=$(cat $CURRENT_PUBLIC_DIR/failed_count.txt)

          IS_LAST_RETRY=0

          if [ $TESTS_RESULT = 0 ] || [ $RETRY = $TEST_RETRY_COUNT ]; then
            IS_LAST_RETRY=1
          fi

          if [ $FAILED_TESTS_COUNT -gt 500 ]; then
            IS_LAST_RETRY=1
            TOO_MANY_FAILED="Too many tests failed, NOT going to retry"
            echo $TOO_MANY_FAILED | GITHUB_TOKEN="${{ github.token }}" .github/scripts/tests/comment-pr.py --color red
          fi

          if [ "${{ inputs.run_tests }}" = "true" ]; then
            # Set PR number only if it exists (for pull request events)
            PR_ARG=""
            if [ -n "${{ github.event.number }}" ]; then
              PR_ARG="--pr_number ${{ github.event.number }}"
            fi
            
            # Set the correct commit SHA - use original head for accurate version tracking
            export GITHUB_HEAD_SHA="$ORIGINAL_HEAD"
            
            GITHUB_TOKEN=${{ github.token }} .github/scripts/tests/generate-summary.py \
              --summary_links "$SUMMARY_LINKS" \
              --public_dir "$PUBLIC_DIR" \
              --public_dir_url "$PUBLIC_DIR_URL" \
              --build_preset "$BUILD_PRESET" \
              --branch "$BRANCH_NAME" \
              --status_report_file statusrep.txt \
              --is_retry $IS_RETRY \
              --is_last_retry $IS_LAST_RETRY \
              --is_test_result_ignored $IS_TEST_RESULT_IGNORED \
              --comment_color_file summary_color.txt \
              --comment_text_file summary_text.txt \
              $PR_ARG \
              --workflow_run_id "${{ github.run_id }}" \
              "Tests" $CURRENT_PUBLIC_DIR/ya-test.html "$CURRENT_REPORT"
          fi

          s3cmd sync --follow-symlinks --acl-public --no-progress --stats --no-mime-magic --guess-mime-type --no-check-md5 "$PUBLIC_DIR/" "$S3_BUCKET_PATH/"

          if [ "${{ inputs.run_tests }}" = "true" ]; then
            cat summary_text.txt | GITHUB_TOKEN="${{ github.token }}" .github/scripts/tests/comment-pr.py --color `cat summary_color.txt`
          fi

          # upload tests results to YDB
          # Create run name based on event type and retry number
          case "$GITHUB_EVENT_NAME" in
            workflow_dispatch)
              run_name="${{ github.run_id }}_manual"
              ;;
            pull_request | pull_request_target)
              pr_number="${{ github.event.number }}"
              if [ -n "$pr_number" ]; then
                run_name="${{ github.run_id }}_PR_${pr_number}"
              else
                run_name="${{ github.run_id }}_PR"
              fi
              ;;
            schedule)
              run_name="${{ github.run_id }}_schedule"
              ;;
            push)
              run_name="${{ github.run_id }}_POST"
              ;;
            *)
              run_name="${{ github.run_id }}"
              ;;
          esac
          run_name="${run_name}_attempt_${RETRY}"
          result=`.github/scripts/analytics/upload_tests_results.py --test-results-file ${CURRENT_REPORT} --run-timestamp $(date +%s) --commit $ORIGINAL_HEAD --build-type ${BUILD_PRESET} --pull ${run_name} --job-name "${{ github.workflow }}" --job-id "${{ github.run_id }}" --branch "${BRANCH_NAME}"`

          if [ $IS_LAST_RETRY = 1 ]; then
            break
          fi
          if [ -n "$GRAPH_PATH" ] && [ -n "$CONTEXT_PATH" ]; then
              GRAPH_PATH=""
              CONTEXT_PATH=""
          fi
        done;

        if [ $BUILD_FAILED = 0 ]; then
          echo "status=true" >> $GITHUB_OUTPUT
          echo "Build successful." |  GITHUB_TOKEN="${{ github.token }}" .github/scripts/tests/comment-pr.py --color green
        fi

    - name: comment-build-status
      if: github.event_name == 'pull_request' || github.event_name == 'pull_request_target'
      shell: bash
      env:
        GITHUB_TOKEN: ${{ github.token }}
      run: |
        set -x

        if [ "${{ steps.build.outputs.status }}" == "failed" ]; then
          curl -L -X POST -H "Accept: application/vnd.github+json" -H "Authorization: Bearer ${{github.token}}" -H "X-GitHub-Api-Version: 2022-11-28" \
            https://api.github.com/repos/${{github.repository}}/statuses/${{github.event.pull_request.head.sha}} \
            -d '{"state":"failure","description":"The check has been failed","context":"build_${{inputs.build_preset}}"}'
        else
          curl -L -X POST -H "Accept: application/vnd.github+json" -H "Authorization: Bearer ${{github.token}}" -H "X-GitHub-Api-Version: 2022-11-28" \
            https://api.github.com/repos/${{github.repository}}/statuses/${{github.event.pull_request.head.sha}} \
            -d '{"state":"success","description":"The check has been completed successfully","context":"build_${{inputs.build_preset}}"}'
        fi

    - name: analyze tests results
      shell: bash
      env:
        GITHUB_TOKEN: ${{ github.token }}
      run: |
        set -x
        if [ true = ${{ inputs.run_tests }} ]; then
          teststatus=$(cat statusrep.txt)
          if [[ $teststatus == "success" ]]; then
            testmessage="The check has been completed successfully"
          else
            testmessage="The check has been failed"
          fi
          curl -L -X POST -H "Accept: application/vnd.github+json" -H "Authorization: Bearer ${{github.token}}" -H "X-GitHub-Api-Version: 2022-11-28" \
              https://api.github.com/repos/${{github.repository}}/statuses/${{github.event.pull_request.head.sha}} \
              -d '{"state":"'$teststatus'","description":"'"$testmessage"'","context":"test_${{inputs.build_preset}}"}'

          if [[ $teststatus != "success" ]]; then
            echo "status=failed" >> $GITHUB_OUTPUT
          fi
        fi

    - name: check test results
      if: inputs.run_tests
      shell: bash
      run: |
        if [ $IS_TEST_RESULT_IGNORED == 0 ]; then
          .github/scripts/tests/fail-checker.py "$LAST_BUILD_RESULTS_REPORT"
        fi

    - name: show diff mute_ya.txt
      if: inputs.build_preset == 'relwithdebinfo' && (github.event_name == 'pull_request' || github.event_name == 'pull_request_target')
      shell: bash
      continue-on-error: true
      env:
        GITHUB_TOKEN: ${{ github.token }}
      run: |
        # Use ORIGINAL_HEAD from build step (saved before any git operations)
        get_file_diff_script=.github/scripts/tests/get_diff_lines_of_file.py
        file_to_check=.github/config/muted_ya.txt
        check_result=`$get_file_diff_script --base_sha $ORIGINAL_HEAD~1 --head_sha $ORIGINAL_HEAD --file_path $file_to_check`
        if [[ ${check_result} == *"not changed" ]];then
            echo file ${file_to_check} NOT changed
        else
            echo file ${file_to_check} changed
            .github/scripts/tests/get_muted_tests.py --output_folder "$PUBLIC_DIR/mute_info/" get_mute_diff --base_sha $ORIGINAL_HEAD~1 --head_sha $ORIGINAL_HEAD --job-id "${{ github.run_id }}" --branch "${BRANCH_NAME}"
            FILE_PATH=$PUBLIC_DIR/mute_info/2_new_muted_tests.txt
            SEPARATOR=""
            if [ -f "$FILE_PATH" ]; then
              LINE_COUNT=$(wc -l < "$FILE_PATH")
              if [ "$LINE_COUNT" -gt 0 ]; then
                SEPARATOR=', '
                MESSAGE="Muted new $LINE_COUNT [tests](${PUBLIC_DIR_URL}/mute_info/2_new_muted_tests.txt)"
              fi
            fi
            FILE_PATH=$PUBLIC_DIR/mute_info/3_unmuted_tests.txt
            if [ -f "$FILE_PATH" ]; then
              LINE_COUNT_unmute=$(wc -l < "$FILE_PATH")
              if [ "$LINE_COUNT_unmute" -gt 0 ]; then
                MESSAGE="${MESSAGE}${SEPARATOR}Unmuted $LINE_COUNT_unmute [tests](${PUBLIC_DIR_URL}/mute_info/3_unmuted_tests.txt)"
              fi
            fi
            if [ -n "$MESSAGE" ]; then
              printf "$MESSAGE" | .github/scripts/tests/comment-pr.py --color orange
            fi
          fi


    - name: sync results to s3 and publish links
      if: always()
      shell: bash
      run: |
        set -x
        echo "::group::s3-sync"
        .github/scripts/Indexer/indexer.py -r "$PUBLIC_DIR/"
        echo "00 [Artifacts](${PUBLIC_DIR_URL}/index.html)" >> $SUMMARY_LINKS
        s3cmd sync --follow-symlinks --acl-public --no-progress --stats --no-mime-magic --guess-mime-type --no-check-md5 "$PUBLIC_DIR/" "$S3_BUCKET_PATH/"
        cat $SUMMARY_LINKS | python3 -c 'import sys; print(" | ".join([v for _, v in sorted([l.strip().split(" ", 1) for l in sys.stdin], key=lambda a: (int(a[0]), a))]))' >> $GITHUB_STEP_SUMMARY
        echo "::endgroup::"

    - name: show free space
      if: always()
      shell: bash
      run: df -h

    - name: build_stats
      shell: bash
      continue-on-error: true
      if: always()
      run: |
        set -x
        export build_preset="${{ inputs.build_preset }}"
        export commit_git_sha="$ORIGINAL_HEAD"

        python3 .github/scripts/send_build_stats.py

    - name: show_build_size_diff
      shell: bash
      continue-on-error: true
      if: always()
      env:
        GITHUB_TOKEN: ${{ github.token }}
      run: |
        set -x
        export build_preset="${{ inputs.build_preset }}"
        export branch_to_compare="$BRANCH_NAME"
        export yellow_treshold=102400
        export red_treshold=2097152
        export commit_git_sha="$ORIGINAL_HEAD"

        get_sizes_comment_script=.github/scripts/get_build_diff.py
        comment_raw=`$get_sizes_comment_script`

        IFS=';;;'
        read -ra comment_arr <<< "$comment_raw"

        printf "$comment"
        if [[ ${comment_raw} != "Error"* ]]; then
          color=${comment_arr[0]}
          replace=$color";;;"
          comment=${comment_raw/$replace/""}

          printf "$comment" | .github/scripts/tests/comment-pr.py --color $color

        else
          echo "Skipped build size difference, comment_raw = ${comment_raw}"
        fi

    - name: comment-if-cancel
      shell: bash
      if: cancelled() && (github.event_name == 'pull_request' || github.event_name == 'pull_request_target')
      env:
        BUILD_PRESET: ${{ inputs.build_preset }}
        GITHUB_TOKEN: ${{ github.token }}
      run:  echo "Check cancelled" | .github/scripts/tests/comment-pr.py --color black
