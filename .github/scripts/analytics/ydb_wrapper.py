#!/usr/bin/env python3

import configparser
import datetime
import os
import time
import uuid
import ydb
import threading
import queue
from typing import List, Dict, Any, Optional, Callable
from contextlib import contextmanager

class YDBWrapper:
    """–û–±–µ—Ä—Ç–∫–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å YDB —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
    
    def __init__(self, config_path: str = None, enable_statistics: bool = None, connection_timeout: int = 10):
        if config_path is None:
            dir = os.path.dirname(__file__)
            config_path = f"{dir}/../../config/ydb_qa_db.ini"
        
        self.config = configparser.ConfigParser()
        self.config.read(config_path)
        
        # –û—Å–Ω–æ–≤–Ω–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö
        self.database_endpoint = self.config["QA_DB"]["DATABASE_ENDPOINT"]
        self.database_path = self.config["QA_DB"]["DATABASE_PATH"]
        
        # –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        self.stats_endpoint = self.config["STATISTICS_DB"]["DATABASE_ENDPOINT"]
        self.stats_path = self.config["STATISTICS_DB"]["DATABASE_PATH"]
        self.stats_table = self.config["STATISTICS_DB"]["STATISTICS_TABLE"]
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        if enable_statistics is None:
            enable_statistics = os.environ.get("YDB_ENABLE_STATISTICS", "true").lower() in ("true", "1", "yes")
        
        self._enable_statistics = enable_statistics
        self._cluster_version = None
        self._stats_available = None
        self._session_id = str(uuid.uuid4())  # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –¥–ª—è —Å–µ—Å—Å–∏–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Å–∫—Ä–∏–ø—Ç–∞
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ç–∞–π–º–∞—É—Ç–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
        if connection_timeout == 10:  # –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            env_timeout = os.environ.get("YDB_CONNECTION_TIMEOUT")
            if env_timeout:
                try:
                    self._connection_timeout = int(env_timeout)
                except ValueError:
                    self._connection_timeout = 10
            else:
                self._connection_timeout = 10
        else:
            self._connection_timeout = connection_timeout
        
        # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ—á–µ—Ä–µ–¥—å –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        self._stats_queue = queue.Queue()
        self._stats_thread = None
        self._stats_thread_running = False
    
    def _start_stats_thread(self):
        """–ó–∞–ø—É—Å–∫ –ø–æ—Ç–æ–∫–∞ –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –∑–∞–ø–∏—Å–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        if self._stats_thread is None or not self._stats_thread.is_alive():
            self._stats_thread_running = True
            self._stats_thread = threading.Thread(target=self._stats_worker, daemon=True)
            self._stats_thread.start()
            self._log("info", "Statistics thread started")
    
    def _stop_stats_thread(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–æ—Ç–æ–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        if self._stats_thread and self._stats_thread.is_alive():
            self._stats_thread_running = False
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–∏–≥–Ω–∞–ª –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤ –æ—á–µ—Ä–µ–¥—å
            self._stats_queue.put(None)
            self._stats_thread.join(timeout=5)
            self._log("info", "Statistics thread stopped")
    
    def _stats_worker(self):
        """–†–∞–±–æ—á–∏–π –ø–æ—Ç–æ–∫ –¥–ª—è –∑–∞–ø–∏—Å–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        while self._stats_thread_running:
            try:
                # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏–∑ –æ—á–µ—Ä–µ–¥–∏ —Å —Ç–∞–π–º–∞—É—Ç–æ–º
                stats_data = self._stats_queue.get(timeout=1)
                if stats_data is None:  # –°–∏–≥–Ω–∞–ª –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
                    break
                
                # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                self._write_stats_sync(stats_data)
                self._stats_queue.task_done()
                
            except queue.Empty:
                continue
            except Exception as e:
                self._log("warning", f"Error in stats worker: {e}")
    
    def _log(self, level: str, message: str, details: str = ""):
        """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ"""
        timestamp = datetime.datetime.now().strftime("%H:%M:%S")
        icons = {"start": "üöÄ", "progress": "‚è≥", "success": "‚úÖ", "error": "‚ùå", "info": "‚ÑπÔ∏è", "warning": "‚ö†Ô∏è"}
        if details:
            print(f"üïê [{timestamp}] {icons.get(level, 'üìù')} {message} | {details}")
        else:
            print(f"üïê [{timestamp}] {icons.get(level, 'üìù')} {message}")
    
    def _setup_credentials(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —É—á–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö YDB"""
        if "CI_YDB_SERVICE_ACCOUNT_KEY_FILE_CREDENTIALS" not in os.environ:
            raise RuntimeError("Env variable CI_YDB_SERVICE_ACCOUNT_KEY_FILE_CREDENTIALS is missing")
        
        os.environ["YDB_SERVICE_ACCOUNT_KEY_FILE_CREDENTIALS"] = os.environ[
            "CI_YDB_SERVICE_ACCOUNT_KEY_FILE_CREDENTIALS"
        ]
    
    def check_credentials(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —É—á–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö YDB"""
        if "CI_YDB_SERVICE_ACCOUNT_KEY_FILE_CREDENTIALS" not in os.environ:
            print("Error: Env variable CI_YDB_SERVICE_ACCOUNT_KEY_FILE_CREDENTIALS is missing, skipping")
            return False
        
        # Do not set up 'real' variable from gh workflows because it interfere with ydb tests
        # So, set up it locally
        os.environ["YDB_SERVICE_ACCOUNT_KEY_FILE_CREDENTIALS"] = os.environ[
            "CI_YDB_SERVICE_ACCOUNT_KEY_FILE_CREDENTIALS"
        ]
        return True
    
    def __enter__(self):
        """–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä - –≤—Ö–æ–¥"""
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä - –≤—ã—Ö–æ–¥ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –∑–∞–∫—Ä—ã—Ç–∏–µ–º"""
        self.close()
    
    def close(self):
        """–ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã —Å –æ—Å—Ç–∞–Ω–æ–≤–∫–æ–π –ø–æ—Ç–æ–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        self._stop_stats_thread()
    
    def _get_cluster_version(self, driver) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –≤–µ—Ä—Å–∏–∏ –∫–ª–∞—Å—Ç–µ—Ä–∞ YDB"""
        if self._cluster_version is not None:
            return self._cluster_version
            
        try:
            tc_settings = ydb.TableClientSettings().with_native_date_in_result_sets(enabled=True)
            table_client = ydb.TableClient(driver, tc_settings)
            scan_query = ydb.ScanQuery("SELECT Version() as version", {})
            it = table_client.scan_query(scan_query)
            result = next(it)
            
            if result.result_set.rows:
                self._cluster_version = result.result_set.rows[0]['version']
                return self._cluster_version
            else:
                raise RuntimeError("No version data returned from cluster")
                
        except Exception as e:
            raise RuntimeError(f"Failed to get cluster version: {e}")
    
    @contextmanager
    def get_driver(self):
        """–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥—Ä–∞–π–≤–µ—Ä–∞ YDB"""
        self._setup_credentials()
        
        with ydb.Driver(
            endpoint=self.database_endpoint,
            database=self.database_path,
            credentials=ydb.credentials_from_env_variables(),
        ) as driver:
            try:
                driver.wait(timeout=self._connection_timeout, fail_fast=True)
            except TimeoutError as e:
                self._log("error", f"Failed to connect to YDB: {e}")
                self._log("error", f"Endpoint: {self.database_endpoint}")
                self._log("error", f"Database: {self.database_path}")
                self._log("error", f"Timeout: {self._connection_timeout} seconds")
                self._log("error", "Possible causes: network issues, YDB service unavailable, or invalid credentials")
                self._log("error", f"Try increasing timeout with: export YDB_CONNECTION_TIMEOUT=30")
                raise RuntimeError(f"YDB connection timeout after {self._connection_timeout}s: {e}") from e
            except Exception as e:
                self._log("error", f"Failed to connect to YDB: {e}")
                self._log("error", f"Endpoint: {self.database_endpoint}")
                self._log("error", f"Database: {self.database_path}")
                self._log("error", f"Timeout: {self._connection_timeout} seconds")
                self._log("error", "Check your YDB credentials and network connectivity")
                raise RuntimeError(f"YDB connection failed: {e}") from e
            
            # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä—Å–∏—é –∫–ª–∞—Å—Ç–µ—Ä–∞ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–∏
            if self._cluster_version is None:
                self._get_cluster_version(driver)
            
            yield driver
    
    def _check_stats_availability(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        try:
            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º credentials
            self._setup_credentials()
            
            # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –±–∞–∑–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Å —Ç–µ–º –∂–µ —Ç–∞–π–º–∞—É—Ç–æ–º, —á—Ç–æ –∏ –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–π –±–∞–∑—ã
            driver = ydb.Driver(
                endpoint=self.stats_endpoint,
                database=self.stats_path,
                credentials=ydb.credentials_from_env_variables()
            )
            try:
                driver.wait(timeout=self._connection_timeout, fail_fast=True)
                tc_settings = ydb.TableClientSettings().with_native_date_in_result_sets(enabled=True)
                table_client = ydb.TableClient(driver, tc_settings)
                scan_query = ydb.ScanQuery("SELECT 1 as test", {})
                it = table_client.scan_query(scan_query)
                next(it)
                return True
            finally:
                driver.stop()
        except Exception:
            return False
    
    def _log_statistics(self, operation_type: str, query: str, duration: float, 
                       status: str, error: str = None, rows_affected: int = None,
                       script_name: str = None, cluster_version: str = None,
                       table_path: str = None):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –æ–ø–µ—Ä–∞—Ü–∏–π (–∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ)"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        if not self._enable_statistics:
            # –õ–æ–≥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–∞–∑ –≤ –Ω–∞—á–∞–ª–µ —Å–µ—Å—Å–∏–∏, —á—Ç–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∞
            if not hasattr(self, '_stats_disabled_logged'):
                self._log("info", "Statistics logging disabled")
                self._stats_disabled_logged = True
            return
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –µ—Å–ª–∏ –µ—â–µ –Ω–µ –∑–∞–ø—É—â–µ–Ω
        if not self._stats_thread_running:
            self._start_stats_thread()
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –∑–∞–ø–∏—Å–∏
        stats_data = {
            'timestamp': datetime.datetime.now(),
            'session_id': self._session_id,
            'operation_type': operation_type,
            'query': query,
            'duration_ms': int(duration * 1000),
            'status': status,
            'error': error,
            'rows_affected': rows_affected,
            'script_name': script_name,
            'cluster_version': cluster_version,
            'database_endpoint': self.database_endpoint,
            'database_path': self.database_path,
            'table_path': self._normalize_table_path(table_path),
            'github_workflow_name': self._get_github_action_info()['workflow_name'],
            'github_run_id': self._get_github_action_info()['run_id'],
            'github_run_url': self._get_github_action_info()['run_url']
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ—á–µ—Ä–µ–¥—å –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        try:
            self._stats_queue.put(stats_data, timeout=1)
        except queue.Full:
            self._log("warning", "Statistics queue is full, dropping stats entry")
    
    def _write_stats_sync(self, stats_data):
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –∑–∞–ø–∏—Å—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ (–≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –∏–∑ –ø–æ—Ç–æ–∫–∞)"""
        if self._stats_available is None:
            self._stats_available = self._check_stats_availability()
        
        if not self._stats_available:
            # –ü–æ–ø—Ä–æ–±—É–µ–º –µ—â–µ —Ä–∞–∑ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –±–∞–∑—ã —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            self._stats_available = self._check_stats_availability()
            if not self._stats_available:
                return
        
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—Ç –∂–µ —Ç–∞–π–º–∞—É—Ç –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏, —á—Ç–æ –∏ –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–π –±–∞–∑—ã
            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º credentials –¥–ª—è –±–∞–∑—ã —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            self._setup_credentials()
            
            driver = ydb.Driver(
                endpoint=self.stats_endpoint,
                database=self.stats_path,
                credentials=ydb.credentials_from_env_variables()
            )
            try:
                driver.wait(timeout=self._connection_timeout, fail_fast=True)
                # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
                self._ensure_stats_table_exists(driver)
                
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏
                stats_data_list = [stats_data]
                
                # –í—Å—Ç–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                table_client = ydb.TableClient(driver)
                column_types = (
                    ydb.BulkUpsertColumns()
                    .add_column("timestamp", ydb.OptionalType(ydb.PrimitiveType.Timestamp))
                    .add_column("session_id", ydb.OptionalType(ydb.PrimitiveType.Utf8))
                    .add_column("operation_type", ydb.OptionalType(ydb.PrimitiveType.Utf8))
                    .add_column("query", ydb.OptionalType(ydb.PrimitiveType.Utf8))
                    .add_column("duration_ms", ydb.OptionalType(ydb.PrimitiveType.Uint64))
                    .add_column("status", ydb.OptionalType(ydb.PrimitiveType.Utf8))
                    .add_column("error", ydb.OptionalType(ydb.PrimitiveType.Utf8))
                    .add_column("rows_affected", ydb.OptionalType(ydb.PrimitiveType.Uint64))
                    .add_column("script_name", ydb.OptionalType(ydb.PrimitiveType.Utf8))
                    .add_column("cluster_version", ydb.OptionalType(ydb.PrimitiveType.Utf8))
                    .add_column("database_endpoint", ydb.OptionalType(ydb.PrimitiveType.Utf8))
                    .add_column("database_path", ydb.OptionalType(ydb.PrimitiveType.Utf8))
                    .add_column("table_path", ydb.OptionalType(ydb.PrimitiveType.Utf8))
                    .add_column("github_workflow_name", ydb.OptionalType(ydb.PrimitiveType.Utf8))
                    .add_column("github_run_id", ydb.OptionalType(ydb.PrimitiveType.Utf8))
                    .add_column("github_run_url", ydb.OptionalType(ydb.PrimitiveType.Utf8))
                )
                
                full_path = f"{self.stats_path}/{self.stats_table}"
                table_client.bulk_upsert(full_path, stats_data_list, column_types)
                
                # –õ–æ–≥–∏—Ä—É–µ–º —É—Å–ø–µ—à–Ω—É—é –∑–∞–ø–∏—Å—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ (—Ç–æ–ª—å–∫–æ –¥–ª—è –ø–µ—Ä–≤–æ–π –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤ —Å–µ—Å—Å–∏–∏)
                if not hasattr(self, '_stats_logged'):
                    self._log("info", f"Statistics logging enabled - session_id: {self._session_id}")
                    self._stats_logged = True
            finally:
                driver.stop()
                
        except TimeoutError as e:
            # –û—Ç–∫–ª—é—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–∏ —Ç–∞–π–º–∞—É—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
            self._log("warning", f"Statistics disabled due to connection timeout (timeout={self._connection_timeout}s)")
            self._stats_available = False
        except Exception as e:
            # –õ–æ–≥–∏—Ä—É–µ–º –±–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ—à–∏–±–∫–µ
            error_type = type(e).__name__
            error_msg = str(e)
            self._log("warning", f"Failed to log statistics ({error_type}): {error_msg}")
            
            # –ï—Å–ª–∏ —ç—Ç–æ –æ—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è, –ø–æ–ø—Ä–æ–±—É–µ–º —Å–±—Ä–æ—Å–∏—Ç—å —Å—Ç–∞—Ç—É—Å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏
            if "timeout" in error_msg.lower() or "connection" in error_msg.lower() or "endpoint" in error_msg.lower():
                self._stats_available = None  # –°–±—Ä–æ—Å–∏–º —Å—Ç–∞—Ç—É—Å –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
    
    def _ensure_stats_table_exists(self, driver):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"""
        def create_stats_table(session):
            create_sql = f"""
                CREATE TABLE IF NOT EXISTS `{self.stats_table}` (
                    `timestamp` Timestamp NOT NULL,
                    `session_id` Utf8 NOT NULL,
                    `operation_type` Utf8 NOT NULL,
                    `query` Utf8,
                    `duration_ms` Uint64 NOT NULL,
                    `status` Utf8 NOT NULL,
                    `error` Utf8,
                    `rows_affected` Uint64,
                    `script_name` Utf8 NOT NULL,
                    `cluster_version` Utf8,
                    `database_endpoint` Utf8,
                    `database_path` Utf8,
                    `table_path` Utf8,
                    `github_workflow_name` Utf8,
                    `github_run_id` Utf8,
                    `github_run_url` Utf8,
                    PRIMARY KEY (`timestamp`, `session_id`, `operation_type`, `script_name`)
                )
                PARTITION BY HASH(`session_id`)
                WITH (STORE = COLUMN)
            """
            session.execute_scheme(create_sql)
        
        with ydb.SessionPool(driver) as pool:
            pool.retry_operation_sync(create_stats_table)
    
    def _execute_with_logging(self, operation_type: str, operation_func: Callable, 
                             query: str = None, script_name: str = None, table_path: str = None) -> Any:
        """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –æ–ø–µ—Ä–∞—Ü–∏–π —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        start_time = time.time()
        
        # –õ–æ–≥–∏—Ä—É–µ–º –Ω–∞—á–∞–ª–æ –æ–ø–µ—Ä–∞—Ü–∏–∏
        self._log("start", f"Executing {operation_type}")
        
        if query:
            # –î–ª—è bulk_upsert –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–µ—Ç–∞–ª–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ batch'–∞
            if operation_type != "bulk_upsert":
                self._log("info", f"Query details:\n{query}")
        
        status = "success"
        error = None
        rows_affected = 0
        cluster_version = None
        
        try:
            with self.get_driver() as driver:
                cluster_version = self._cluster_version
                
                if operation_type == "scan_query":
                    tc_settings = ydb.TableClientSettings().with_native_date_in_result_sets(enabled=True)
                    table_client = ydb.TableClient(driver, tc_settings)
                    scan_query = ydb.ScanQuery(query, {})
                    it = table_client.scan_query(scan_query)
                    
                    results = []
                    batch_count = 0
                    
                    while True:
                        try:
                            result = next(it)
                            batch_count += 1
                            batch_size = len(result.result_set.rows) if result.result_set.rows else 0
                            results = results + result.result_set.rows
                            rows_affected += batch_size
                            
                            # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å —Ç–æ–ª—å–∫–æ –∫–∞–∂–¥—ã–µ 50 –±–∞—Ç—á–µ–π –∏–ª–∏ –∫–∞–∂–¥—ã–µ 10000 —Å—Ç—Ä–æ–∫
                            if batch_count % 50 == 0 or rows_affected % 10000 == 0:
                                elapsed = time.time() - start_time
                                self._log("progress", f"Batch {batch_count}: {batch_size} rows (total: {rows_affected})", f"{elapsed:.2f}s")
                            
                        except StopIteration:
                            break
                    
                    end_time = time.time()
                    duration = end_time - start_time
                    
                    self._log("success", f"Scan query completed", f"Total results: {rows_affected} rows, Duration: {duration:.2f}s")
                    
                    # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                    self._log_statistics(
                        operation_type=operation_type,
                        query=query,
                        duration=duration,
                        status=status,
                        rows_affected=rows_affected,
                        script_name=script_name,
                        cluster_version=cluster_version,
                        table_path=table_path  # scan_query –º–æ–∂–µ—Ç –Ω–µ –∏–º–µ—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã
                    )
                    
                    return results
                
                else:
                    # –î–ª—è –¥—Ä—É–≥–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
                    result = operation_func(driver)
                    
                    # –ï—Å–ª–∏ –æ–ø–µ—Ä–∞—Ü–∏—è –≤–µ—Ä–Ω—É–ª–∞ —á–∏—Å–ª–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –∫–∞–∫ rows_affected
                    if isinstance(result, (int, float)) and operation_type in ["bulk_upsert", "create_table"]:
                        rows_affected = int(result)
                    # –ï—Å–ª–∏ –æ–ø–µ—Ä–∞—Ü–∏—è –≤–µ—Ä–Ω—É–ª–∞ –∫–æ—Ä—Ç–µ–∂ (–¥–∞–Ω–Ω—ã–µ + –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ), –∏–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫
                    elif isinstance(result, tuple) and len(result) == 2 and operation_type == "scan_query":
                        data, metadata = result
                        rows_affected = len(data) if isinstance(data, list) else 0
                    # –ï—Å–ª–∏ scan_query –≤–µ—Ä–Ω—É–ª –ø—Ä–æ—Å—Ç–æ —Å–ø–∏—Å–æ–∫, —Å—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫
                    elif isinstance(result, list) and operation_type == "scan_query":
                        rows_affected = len(result)
                    
                    end_time = time.time()
                    duration = end_time - start_time
                    
                    self._log("success", f"{operation_type} completed", f"Duration: {duration:.2f}s")
                    
                    # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                    self._log_statistics(
                        operation_type=operation_type,
                        query=query or f"{operation_type} operation",
                        duration=duration,
                        status=status,
                        rows_affected=rows_affected,
                        script_name=script_name,
                        cluster_version=cluster_version,
                        table_path=table_path
                    )
                    
                    return result
                
        except Exception as e:
            end_time = time.time()
            duration = end_time - start_time
            status = "error"
            error = str(e)
            
            self._log("error", f"{operation_type} failed", f"Error: {error}, Duration: {duration:.2f}s")
            
            # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ—à–∏–±–∫–∏
            self._log_statistics(
                operation_type=operation_type,
                query=query or f"{operation_type} operation",
                duration=duration,
                status=status,
                error=error,
                script_name=script_name,
                cluster_version=cluster_version,
                table_path=table_path if operation_type == "bulk_upsert" else None
            )
            
            raise
    
    
    def execute_scan_query(self, query: str, script_name: str = None) -> List[Dict[str, Any]]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ scan query —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        return self._execute_with_logging("scan_query", None, query, script_name, None)
    
    def execute_scan_query_with_metadata(self, query: str, script_name: str = None) -> tuple[List[Dict[str, Any]], List[tuple[str, Any]]]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ scan query —Å –≤–æ–∑–≤—Ä–∞—Ç–æ–º –¥–∞–Ω–Ω—ã—Ö –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫"""
        def operation(driver):
            tc_settings = ydb.TableClientSettings().with_native_date_in_result_sets(enabled=True)
            table_client = ydb.TableClient(driver, tc_settings)
            scan_query = ydb.ScanQuery(query, {})
            it = table_client.scan_query(scan_query)
            
            results = []
            column_types = None
            
            while True:
                try:
                    result = next(it)
                    if column_types is None:
                        column_types = [(col.name, col.type) for col in result.result_set.columns]
                    
                    results.extend(result.result_set.rows)
                
                except StopIteration:
                    break
            
            # –ï—Å–ª–∏ –Ω–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, column_types –º–æ–∂–µ—Ç –±—ã—Ç—å None
            if column_types is None:
                column_types = []
            
            return results, column_types
        
        return self._execute_with_logging("scan_query", operation, query, script_name, None)
    
    def create_table(self, table_path: str, create_sql: str, script_name: str = None):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        def operation(driver):
            def callee(session):
                session.execute_scheme(create_sql)
            
            with ydb.SessionPool(driver) as pool:
                pool.retry_operation_sync(callee)
            return 1  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º 1 –¥–ª—è –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏—è —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã
        
        return self._execute_with_logging("create_table", operation, create_sql, script_name, table_path)
    
    def bulk_upsert(self, table_path: str, rows: List[Dict[str, Any]], 
                   column_types: ydb.BulkUpsertColumns, script_name: str = None):
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ bulk upsert —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        rows_count = len(rows) if rows else 0
        
        def operation(driver):
            table_client = ydb.TableClient(driver)
            table_client.bulk_upsert(table_path, rows, column_types)
            return rows_count  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        
        # –í—Å–µ–≥–¥–∞ –≤—ã–ø–æ–ª–Ω—è–µ–º –æ–ø–µ—Ä–∞—Ü–∏—é —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        return self._execute_with_logging("bulk_upsert", operation, f"BULK_UPSERT to {table_path}", script_name, table_path)
    
    def get_session_id(self) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ ID —Ç–µ–∫—É—â–µ–π —Å–µ—Å—Å–∏–∏"""
        return self._session_id
    
    def _get_github_action_info(self) -> dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ GitHub Action –µ—Å–ª–∏ —Å–∫—Ä–∏–ø—Ç –∑–∞–ø—É—â–µ–Ω –≤ GitHub Actions"""
        github_info = {
            "workflow_name": None,
            "run_id": None,
            "run_url": None
        }
        
        try:
            # GitHub Actions —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —ç—Ç–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
            workflow_name = os.environ.get("GITHUB_WORKFLOW")
            run_id = os.environ.get("GITHUB_RUN_ID")
            repository = os.environ.get("GITHUB_REPOSITORY")
            
            if workflow_name:
                github_info["workflow_name"] = workflow_name
            
            if run_id and repository:
                github_info["run_id"] = run_id
                github_info["run_url"] = f"https://github.com/{repository}/actions/runs/{run_id}"
                
        except Exception:
            # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –ø–æ–ª—É—á–µ–Ω–∏—è GitHub –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
            pass
            
        return github_info
    
    def _normalize_table_path(self, table_path: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—É—Ç–∏ –∫ —Ç–∞–±–ª–∏—Ü–µ - –∏—Å–∫–ª—é—á–∞–µ–º database_path –¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏"""
        if not table_path:
            return None
            
        # –ï—Å–ª–∏ –ø—É—Ç—å –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å database_path, —É–±–∏—Ä–∞–µ–º –µ–≥–æ
        if self.database_path and table_path.startswith(self.database_path):
            normalized = table_path[len(self.database_path):]
            # –£–±–∏—Ä–∞–µ–º –≤–µ–¥—É—â–∏–π —Å–ª–µ—à –µ—Å–ª–∏ –µ—Å—Ç—å
            if normalized.startswith('/'):
                normalized = normalized[1:]
            return normalized
            
        return table_path
    
    def get_cluster_info(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–ª–∞—Å—Ç–µ—Ä–µ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–µ"""
        try:
            with self.get_driver() as driver:
                version = self._cluster_version
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                stats_status = "disabled"
                if self._enable_statistics:
                    if self._stats_available is None:
                        self._stats_available = self._check_stats_availability()
                    
                    stats_status = "enabled_and_available" if self._stats_available else "enabled_but_unavailable"
                
                # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ GitHub Action
                github_info = self._get_github_action_info()
                
                return {
                    'session_id': self._session_id,
                    'version': version,
                    'endpoint': self.database_endpoint,
                    'database': self.database_path,
                    'statistics_enabled': self._enable_statistics,
                    'statistics_status': stats_status,
                    'statistics_endpoint': self.stats_endpoint,
                    'statistics_database': self.stats_path,
                    'statistics_table': self.stats_table,
                    'github_workflow': github_info['workflow_name'],
                    'github_run_id': github_info['run_id'],
                    'github_run_url': github_info['run_url']
                }
                
        except Exception as e:
            return {
                'session_id': self._session_id,
                'version': None,
                'endpoint': self.database_endpoint,
                'database': self.database_path,
                'error': str(e),
                'statistics_enabled': self._enable_statistics,
                'statistics_status': "disabled",
                'statistics_endpoint': self.stats_endpoint,
                'statistics_database': self.stats_path,
                'statistics_table': self.stats_table
            }
