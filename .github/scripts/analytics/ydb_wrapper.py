#!/usr/bin/env python3

import configparser
import datetime
import os
import time
import uuid
import ydb
from typing import List, Dict, Any, Optional, Callable
from contextlib import contextmanager

class YDBWrapper:
    """–û–±–µ—Ä—Ç–∫–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å YDB —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
    
    def __init__(self, config_path: str = None, enable_statistics: bool = None):
        if config_path is None:
            dir = os.path.dirname(__file__)
            config_path = f"{dir}/../../config/ydb_qa_db.ini"
        
        self.config = configparser.ConfigParser()
        self.config.read(config_path)
        
        # –û—Å–Ω–æ–≤–Ω–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö
        self.database_endpoint = self.config["QA_DB"]["DATABASE_ENDPOINT"]
        self.database_path = self.config["QA_DB"]["DATABASE_PATH"]
        
        # –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        self.stats_endpoint = self.config["STATISTICS_DB"]["DATABASE_ENDPOINT"]
        self.stats_path = self.config["STATISTICS_DB"]["DATABASE_PATH"]
        self.stats_table = self.config["STATISTICS_DB"]["STATISTICS_TABLE"]
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        if enable_statistics is None:
            enable_statistics = os.environ.get("YDB_ENABLE_STATISTICS", "true").lower() in ("true", "1", "yes")
        
        self._enable_statistics = enable_statistics
        self._cluster_version = None
        self._stats_available = None
        self._session_id = str(uuid.uuid4())  # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –¥–ª—è —Å–µ—Å—Å–∏–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Å–∫—Ä–∏–ø—Ç–∞
    
    def _log(self, level: str, message: str, details: str = ""):
        """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ"""
        timestamp = datetime.datetime.now().strftime("%H:%M:%S")
        icons = {"start": "üöÄ", "progress": "‚è≥", "success": "‚úÖ", "error": "‚ùå", "info": "‚ÑπÔ∏è", "warning": "‚ö†Ô∏è"}
        print(f"üïê [{timestamp}] {icons.get(level, 'üìù')} {message}")
        if details:
            print(f"   üìã {details}")
    
    def _setup_credentials(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —É—á–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö YDB"""
        if "CI_YDB_SERVICE_ACCOUNT_KEY_FILE_CREDENTIALS" not in os.environ:
            raise RuntimeError("Env variable CI_YDB_SERVICE_ACCOUNT_KEY_FILE_CREDENTIALS is missing")
        
        os.environ["YDB_SERVICE_ACCOUNT_KEY_FILE_CREDENTIALS"] = os.environ[
            "CI_YDB_SERVICE_ACCOUNT_KEY_FILE_CREDENTIALS"
        ]
    
    def check_credentials(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —É—á–µ—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö YDB"""
        if "CI_YDB_SERVICE_ACCOUNT_KEY_FILE_CREDENTIALS" not in os.environ:
            print("Error: Env variable CI_YDB_SERVICE_ACCOUNT_KEY_FILE_CREDENTIALS is missing, skipping")
            return False
        
        # Do not set up 'real' variable from gh workflows because it interfere with ydb tests
        # So, set up it locally
        os.environ["YDB_SERVICE_ACCOUNT_KEY_FILE_CREDENTIALS"] = os.environ[
            "CI_YDB_SERVICE_ACCOUNT_KEY_FILE_CREDENTIALS"
        ]
        return True
    
    def _get_cluster_version(self, driver) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –≤–µ—Ä—Å–∏–∏ –∫–ª–∞—Å—Ç–µ—Ä–∞ YDB"""
        if self._cluster_version is not None:
            return self._cluster_version
            
        try:
            tc_settings = ydb.TableClientSettings().with_native_date_in_result_sets(enabled=True)
            table_client = ydb.TableClient(driver, tc_settings)
            scan_query = ydb.ScanQuery("SELECT Version() as version", {})
            it = table_client.scan_query(scan_query)
            result = next(it)
            
            if result.result_set.rows:
                self._cluster_version = result.result_set.rows[0]['version']
                return self._cluster_version
            else:
                raise RuntimeError("No version data returned from cluster")
                
        except Exception as e:
            raise RuntimeError(f"Failed to get cluster version: {e}")
    
    @contextmanager
    def get_driver(self):
        """–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥—Ä–∞–π–≤–µ—Ä–∞ YDB"""
        self._setup_credentials()
        
        with ydb.Driver(
            endpoint=self.database_endpoint,
            database=self.database_path,
            credentials=ydb.credentials_from_env_variables(),
        ) as driver:
            driver.wait(timeout=10, fail_fast=True)
            
            # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä—Å–∏—é –∫–ª–∞—Å—Ç–µ—Ä–∞ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–∏
            if self._cluster_version is None:
                self._get_cluster_version(driver)
            
            yield driver
    
    def _check_stats_availability(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        try:
            with self.get_driver() as driver:
                tc_settings = ydb.TableClientSettings().with_native_date_in_result_sets(enabled=True)
                table_client = ydb.TableClient(driver, tc_settings)
                scan_query = ydb.ScanQuery("SELECT 1 as test", {})
                it = table_client.scan_query(scan_query)
                next(it)
                return True
        except Exception:
            return False
    
    def _log_statistics(self, operation_type: str, query: str, duration: float, 
                       status: str, error: str = None, rows_affected: int = None,
                       script_name: str = None, cluster_version: str = None,
                       table_name: str = None):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –æ–ø–µ—Ä–∞—Ü–∏–π"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        if not self._enable_statistics:
            return
        
        if self._stats_available is None:
            self._stats_available = self._check_stats_availability()
        
        if not self._stats_available:
            self._log("warning", "Skipping statistics logging - database not available")
            return
        
        try:
            with self.get_driver() as driver:
                # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
                self._ensure_stats_table_exists(driver)
                
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏
                stats_data = [{
                    'timestamp': datetime.datetime.now(),
                    'session_id': self._session_id,
                    'operation_type': operation_type,
                    'query': query,
                    'duration_ms': int(duration * 1000),
                    'status': status,
                    'error': error,
                    'rows_affected': rows_affected,
                    'script_name': script_name,
                    'cluster_version': cluster_version,
                    'database_endpoint': self.database_endpoint,
                    'database_path': self.database_path,
                    'table_name': table_name
                }]
                
                # –í—Å—Ç–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                table_client = ydb.TableClient(driver)
                column_types = (
                    ydb.BulkUpsertColumns()
                    .add_column("timestamp", ydb.OptionalType(ydb.PrimitiveType.Timestamp))
                    .add_column("session_id", ydb.OptionalType(ydb.PrimitiveType.Utf8))
                    .add_column("operation_type", ydb.OptionalType(ydb.PrimitiveType.Utf8))
                    .add_column("query", ydb.OptionalType(ydb.PrimitiveType.Utf8))
                    .add_column("duration_ms", ydb.OptionalType(ydb.PrimitiveType.Uint64))
                    .add_column("status", ydb.OptionalType(ydb.PrimitiveType.Utf8))
                    .add_column("error", ydb.OptionalType(ydb.PrimitiveType.Utf8))
                    .add_column("rows_affected", ydb.OptionalType(ydb.PrimitiveType.Uint64))
                    .add_column("script_name", ydb.OptionalType(ydb.PrimitiveType.Utf8))
                    .add_column("cluster_version", ydb.OptionalType(ydb.PrimitiveType.Utf8))
                    .add_column("database_endpoint", ydb.OptionalType(ydb.PrimitiveType.Utf8))
                    .add_column("database_path", ydb.OptionalType(ydb.PrimitiveType.Utf8))
                    .add_column("table_name", ydb.OptionalType(ydb.PrimitiveType.Utf8))
                )
                
                full_path = f"{self.stats_path}/{self.stats_table}"
                table_client.bulk_upsert(full_path, stats_data, column_types)
                
        except Exception as e:
            self._log("warning", f"Failed to log statistics: {e}")
            self._stats_available = False
    
    def _ensure_stats_table_exists(self, driver):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"""
        def create_stats_table(session):
            create_sql = f"""
                CREATE TABLE IF NOT EXISTS `{self.stats_table}` (
                    `timestamp` Timestamp NOT NULL,
                    `session_id` Utf8 NOT NULL,
                    `operation_type` Utf8 NOT NULL,
                    `query` Utf8,
                    `duration_ms` Uint64 NOT NULL,
                    `status` Utf8 NOT NULL,
                    `error` Utf8,
                    `rows_affected` Uint64,
                    `script_name` Utf8 NOT NULL,
                    `cluster_version` Utf8,
                    `database_endpoint` Utf8,
                    `database_path` Utf8,
                    `table_name` Utf8,
                    PRIMARY KEY (`timestamp`, `session_id`, `operation_type`, `script_name`)
                )
                PARTITION BY HASH(`session_id`)
                WITH (STORE = COLUMN)
            """
            session.execute_scheme(create_sql)
        
        with ydb.SessionPool(driver) as pool:
            pool.retry_operation_sync(create_stats_table)
    
    def _execute_with_logging(self, operation_type: str, operation_func: Callable, 
                             query: str = None, script_name: str = None) -> Any:
        """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –æ–ø–µ—Ä–∞—Ü–∏–π —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        start_time = time.time()
        self._log("start", f"Executing {operation_type}")
        
        if query:
            self._log("info", f"Query details:\n{query}")
        
        status = "success"
        error = None
        rows_affected = 0
        cluster_version = None
        
        try:
            with self.get_driver() as driver:
                cluster_version = self._cluster_version
                
                if operation_type == "scan_query":
                    tc_settings = ydb.TableClientSettings().with_native_date_in_result_sets(enabled=True)
                    table_client = ydb.TableClient(driver, tc_settings)
                    scan_query = ydb.ScanQuery(query, {})
                    it = table_client.scan_query(scan_query)
                    
                    results = []
                    batch_count = 0
                    
                    while True:
                        try:
                            result = next(it)
                            batch_count += 1
                            batch_size = len(result.result_set.rows) if result.result_set.rows else 0
                            results = results + result.result_set.rows
                            rows_affected += batch_size
                            
                            # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å —Ç–æ–ª—å–∫–æ –∫–∞–∂–¥—ã–µ 50 –±–∞—Ç—á–µ–π –∏–ª–∏ –∫–∞–∂–¥—ã–µ 10000 —Å—Ç—Ä–æ–∫
                            if batch_count % 50 == 0 or rows_affected % 10000 == 0:
                                elapsed = time.time() - start_time
                                self._log("progress", f"Batch {batch_count}: {batch_size} rows (total: {rows_affected})", f"{elapsed:.2f}s")
                            
                        except StopIteration:
                            break
                    
                    end_time = time.time()
                    duration = end_time - start_time
                    
                    self._log("success", f"Scan query completed", f"Total results: {rows_affected} rows, Version: {cluster_version}, Duration: {duration:.2f}s")
                    
                    # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                    self._log_statistics(
                        operation_type=operation_type,
                        query=query,
                        duration=duration,
                        status=status,
                        rows_affected=rows_affected,
                        script_name=script_name,
                        cluster_version=cluster_version,
                        table_name=None  # scan_query –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Ç–∞–±–ª–∏—Ü–µ–π
                    )
                    
                    return results
                
                else:
                    # –î–ª—è –¥—Ä—É–≥–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
                    result = operation_func(driver)
                    
                    # –ï—Å–ª–∏ –æ–ø–µ—Ä–∞—Ü–∏—è –≤–µ—Ä–Ω—É–ª–∞ —á–∏—Å–ª–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –∫–∞–∫ rows_affected
                    if isinstance(result, (int, float)) and operation_type in ["bulk_upsert", "create_table"]:
                        rows_affected = int(result)
                    
                    end_time = time.time()
                    duration = end_time - start_time
                    
                    self._log("success", f"{operation_type} completed", f"Version: {cluster_version}, Duration: {duration:.2f}s")
                    
                    # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                    self._log_statistics(
                        operation_type=operation_type,
                        query=query or f"{operation_type} operation",
                        duration=duration,
                        status=status,
                        rows_affected=rows_affected,
                        script_name=script_name,
                        cluster_version=cluster_version,
                        table_name=self._extract_table_name_from_query(query) if operation_type == "bulk_upsert" else None
                    )
                    
                    return result
                
        except Exception as e:
            end_time = time.time()
            duration = end_time - start_time
            status = "error"
            error = str(e)
            
            self._log("error", f"{operation_type} failed", f"Error: {error}, Duration: {duration:.2f}s")
            
            # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ—à–∏–±–∫–∏
            self._log_statistics(
                operation_type=operation_type,
                query=query or f"{operation_type} operation",
                duration=duration,
                status=status,
                error=error,
                script_name=script_name,
                cluster_version=cluster_version,
                table_name=self._extract_table_name_from_query(query) if operation_type == "bulk_upsert" else None
            )
            
            raise
    
    def _extract_table_name_from_query(self, query: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–º–µ–Ω–∏ —Ç–∞–±–ª–∏—Ü—ã –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ bulk_upsert"""
        if not query or "BULK_UPSERT to" not in query:
            return None
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è —Ç–∞–±–ª–∏—Ü—ã –∏–∑ —Å—Ç—Ä–æ–∫–∏ "BULK_UPSERT to table_name"
        try:
            parts = query.split("BULK_UPSERT to ")
            if len(parts) > 1:
                table_name = parts[1].strip()
                # –£–±–∏—Ä–∞–µ–º –ø—É—Ç—å –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö, –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –∏–º—è —Ç–∞–±–ª–∏—Ü—ã
                if "/" in table_name:
                    table_name = table_name.split("/")[-1]
                return table_name
        except Exception:
            pass
        
        return None
    
    def execute_scan_query(self, query: str, script_name: str = None) -> List[Dict[str, Any]]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ scan query —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        return self._execute_with_logging("scan_query", None, query, script_name)
    
    def create_table(self, table_path: str, create_sql: str, script_name: str = None):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        def operation(driver):
            def callee(session):
                session.execute_scheme(create_sql)
            
            with ydb.SessionPool(driver) as pool:
                pool.retry_operation_sync(callee)
            return 1  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º 1 –¥–ª—è –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏—è —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã
        
        return self._execute_with_logging("create_table", operation, create_sql, script_name)
    
    def bulk_upsert(self, table_path: str, rows: List[Dict[str, Any]], 
                   column_types: ydb.BulkUpsertColumns, script_name: str = None):
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ bulk upsert —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        rows_count = len(rows) if rows else 0
        
        def operation(driver):
            table_client = ydb.TableClient(driver)
            table_client.bulk_upsert(table_path, rows, column_types)
            return rows_count  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        
        return self._execute_with_logging("bulk_upsert", operation, f"BULK_UPSERT to {table_path}", script_name)
    
    def get_session_id(self) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ ID —Ç–µ–∫—É—â–µ–π —Å–µ—Å—Å–∏–∏"""
        return self._session_id
    
    def get_cluster_info(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–ª–∞—Å—Ç–µ—Ä–µ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–µ"""
        try:
            with self.get_driver() as driver:
                version = self._cluster_version
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                stats_status = "disabled"
                if self._enable_statistics:
                    if self._stats_available is None:
                        self._stats_available = self._check_stats_availability()
                    
                    stats_status = "enabled_and_available" if self._stats_available else "enabled_but_unavailable"
                
                return {
                    'session_id': self._session_id,
                    'version': version,
                    'endpoint': self.database_endpoint,
                    'database': self.database_path,
                    'statistics_enabled': self._enable_statistics,
                    'statistics_status': stats_status,
                    'statistics_endpoint': self.stats_endpoint,
                    'statistics_database': self.stats_path,
                    'statistics_table': self.stats_table
                }
                
        except Exception as e:
            return {
                'session_id': self._session_id,
                'version': None,
                'endpoint': self.database_endpoint,
                'database': self.database_path,
                'error': str(e),
                'statistics_enabled': self._enable_statistics,
                'statistics_status': "disabled",
                'statistics_endpoint': self.stats_endpoint,
                'statistics_database': self.stats_path,
                'statistics_table': self.stats_table
            }
