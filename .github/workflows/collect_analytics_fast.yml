name: Collect-analytics-fast-run
on:
  schedule:
    - cron: "*/30 * * * *"  # Every 30 min
  workflow_dispatch:
    inputs:
      commit_sha:
        type: string
        default: ""
        
defaults:
  run:
    shell: bash
jobs:
  main:
    name: Checkout and setup
    runs-on: [ self-hosted, auto-provisioned, build-preset-analytic-node]
    steps:
    - name: Checkout
      uses: actions/checkout@v4
      with:
        ref: ${{ inputs.commit_sha }}
    - name: Setup ydb access
      uses: ./.github/actions/setup_ci_ydb_service_account_key_file_credentials
      with:
        ci_ydb_service_account_key_file_credentials: ${{ secrets.CI_YDB_SERVICE_ACCOUNT_KEY_FILE_CREDENTIALS }}
    - name: Install dependencies
      run: |
        python3 -m pip install ydb ydb[yc] codeowners pandas
    - name: Upload new test history to fast table
      continue-on-error: true
      run: python3 .github/scripts/analytics/test_history_fast.py
    - name: Upload olap perfomance suites data mart
      continue-on-error: true
      run: python3 .github/scripts/analytics/data_mart_executor.py --query_path .github/scripts/analytics/data_mart_queries/perfomance_olap_suites_mart.sql --table_path perfomance/olap/fast_results_siutes --store_type column --partition_keys RunTs --primary_keys RunTs Db Suite --ttl_min 43200 --ttl_key RunTs
    - name: Upload olap perfomance data mart
      continue-on-error: true
      run: python3 .github/scripts/analytics/data_mart_executor.py --query_path .github/scripts/analytics/data_mart_queries/perfomance_olap_mart.sql --table_path perfomance/olap/fast_results --store_type column --partition_keys Run_start_timestamp --primary_keys Run_start_timestamp Db Suite Test Branch --ttl_min 43200 --ttl_key Run_start_timestamp
    - name: Export GitHub issues
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      continue-on-error: true
      run: python3 .github/scripts/analytics/export_issues_to_ydb.py
    - name: Export GitHub pull_requests
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      continue-on-error: true
      run: python3 .github/scripts/analytics/export_pull_requests_to_ydb.py
    - name: Upload GitHub issue mapping table
      continue-on-error: true
      run: python3 .github/scripts/analytics/github_issue_mapping.py
    - name: Upload MUTED test monitor data mart with GitHub issue links
      continue-on-error: true
      run: python3 .github/scripts/analytics/data_mart_executor.py --query_path .github/scripts/analytics/data_mart_queries/test_muted_monitor_mart_with_issue.sql --table_path test_results/analytics/test_muted_monitor_mart --store_type column --partition_keys date_window branch build_type owner_team suite_folder --primary_keys date_window owner_team branch build_type suite_folder full_name --ttl_min 43200 --ttl_key date_window
    - name: Upload FULL test monitor data mart
      continue-on-error: true
      run: python3 .github/scripts/analytics/data_mart_executor.py --query_path .github/scripts/analytics/data_mart_queries/test_monitor_mart.sql --table_path test_results/analytics/test_monitor_mart --store_type column --partition_keys date_window branch build_type owner_team suite_folder --primary_keys date_window owner_team branch build_type suite_folder full_name --ttl_min 43200 --ttl_key date_window
    - name: Upload muted tests statistic data mart
      continue-on-error: true
      run: python3 .github/scripts/analytics/data_mart_executor.py --query_path .github/scripts/analytics/data_mart_queries/muted_tests_statistic.sql --table_path test_results/analytics/muted_tests_statistic --store_type column --partition_keys month_point_date branch build_type owner --primary_keys ym branch build_type owner
    - name: Upload postcommit retry data mart
      continue-on-error: true
      run: python3 .github/scripts/analytics/data_mart_executor.py --query_path .github/scripts/analytics/data_mart_queries/datamart_postcommit_retry.sql --table_path test_results/test_results/analytics/postcommit_retry --store_type column --partition_keys postcommit_start_run_timestamp --primary_keys postcommit_start_run_timestamp commit --ttl_min 259200 --ttl_key postcommit_start_run_timestamp
    - name: Upload PR blocked by failed tests data mart
      continue-on-error: true
      run: python3 .github/scripts/analytics/data_mart_executor.py --query_path .github/scripts/analytics/data_mart_queries/pr_blocked_by_failed_tests_rich.sql --table_path test_results/analytics/pr_blocked_by_failed_tests_rich --store_type column --partition_keys last_run_timestamp --primary_keys last_run_timestamp full_name pr_number job_id
    - name: Upload PR blocked by failed tests with PR info data mart
      continue-on-error: true
      run: python3 .github/scripts/analytics/data_mart_executor.py --query_path .github/scripts/analytics/data_mart_queries/pr_blocked_by_failed_tests_rich_with_pr_and_mute.sql --table_path test_results/analytics/pr_blocked_by_failed_tests_rich_with_pr_and_mute --store_type column --partition_keys last_run_timestamp --primary_keys last_run_timestamp full_name pr_number job_id
    - name: Upload PR with test failures (any failures, 1 day)
      continue-on-error: true
      run: python3 .github/scripts/analytics/data_mart_executor.py --query_path .github/scripts/analytics/data_mart_queries/pr_with_test_failures.sql --table_path test_results/analytics/pr_blocked_by_tests --store_type column --partition_keys last_run_timestamp --primary_keys last_run_timestamp full_name pr_number job_id
    - name: Upload Nemesis aggregate data mart
      continue-on-error: true
      run: python3 .github/scripts/analytics/data_mart_executor.py --query_path .github/scripts/analytics/data_mart_queries/stability_aggregate_mart.sql --table_path nemesis/aggregated_mart --store_type column --partition_keys RunTs --primary_keys RunTs Db Suite Test --ttl_min 43200 --ttl_key RunTs