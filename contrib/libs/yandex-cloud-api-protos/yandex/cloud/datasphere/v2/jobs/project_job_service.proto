syntax = "proto3";

package yandex.cloud.datasphere.v2.jobs;

import "google/protobuf/duration.proto";
import "google/protobuf/empty.proto";
import "google/protobuf/timestamp.proto";
import "yandex/cloud/api/operation.proto";
import "yandex/cloud/validation.proto";
import "yandex/cloud/operation/operation.proto";
import "yandex/cloud/datasphere/v2/jobs/jobs.proto";

option go_package = "github.com/yandex-cloud/go-genproto/yandex/cloud/datasphere/v2/jobs;datasphere";
option java_outer_classname = "DSPJS";
option java_package = "yandex.cloud.api.datasphere.v2.jobs";

// A set of methods for managing Project Jobs. Do not use these methods manually.
// For working with DataSphere Jobs, install DataSphere CLI via `pip install datasphere`.
service ProjectJobService {
  // Creates job.
  rpc Create (CreateProjectJobRequest) returns (operation.Operation) {
    option (yandex.cloud.api.operation) = {
      metadata: "CreateProjectJobMetadata"
      response: "CreateProjectJobResponse"
    };
  }

  // Clone job.
  rpc Clone (CloneProjectJobRequest) returns (operation.Operation) {
    option (yandex.cloud.api.operation) = {
      metadata: "CloneProjectJobMetadata"
      response: "CloneProjectJobResponse"
    };
  }

  // Runs job execution.
  rpc Execute (ExecuteProjectJobRequest) returns (operation.Operation) {
    option (yandex.cloud.api.operation) = {
      metadata: "ExecuteProjectJobMetadata"
      response: "ExecuteProjectJobResponse"
    };
  }

  // Cancels running job.
  rpc Cancel (CancelProjectJobRequest) returns (google.protobuf.Empty);

  // Returns stream of job logs.
  rpc ReadStdLogs (ReadProjectJobStdLogsRequest) returns (stream ReadProjectJobStdLogsResponse) {
    option deprecated = true;
  };

  // Returns stream of job logs.
  rpc ReadLogs (ReadProjectJobLogsRequest) returns (stream ReadProjectJobLogsResponse);

  // Returns download urls for job files.
  rpc DownloadJobFiles (DownloadProjectJobFilesRequest) returns (DownloadProjectJobFilesResponse);

  // Lists jobs.
  rpc List (ListProjectJobRequest) returns (ListProjectJobResponse);

  // Returns job by id.
  rpc Get (GetProjectJobRequest) returns (Job);

  // Deletes specified job.
  rpc Delete (DeleteProjectJobRequest) returns (operation.Operation) {
    option (yandex.cloud.api.operation) = {
      metadata: "DeleteProjectJobMetadata"
      response: "google.protobuf.Empty"
    };
  }

  // Delete job data.
  rpc DeleteData (DeleteProjectJobDataRequest) returns (operation.Operation) {
    option (yandex.cloud.api.operation) = {
      metadata: "DeleteProjectJobDataMetadata"
      response: "DeleteProjectJobDataResponse"
    };
  }

  // Delete all jobs data.
  rpc DeleteAllData (DeleteAllProjectJobDataRequest) returns (operation.Operation) {
    option (yandex.cloud.api.operation) = {
      metadata: "DeleteAllProjectJobDataMetadata"
      response: "DeleteAllProjectJobDataResponse"
    };
  }

  // Update job data ttl.
  rpc SetDataTtl (SetProjectJobDataTtlRequest) returns (SetProjectJobDataTtlResponse);
}

message CreateProjectJobRequest {
  // ID of the project.
  string project_id = 1;

  // Parameters of the job.
  JobParameters job_parameters = 2;

  // Config of the job.
  string config = 3;

  // Name of the job.
  string name = 4;

  // Description of the job.
  string desc = 5;

  // Job data TTL.
  google.protobuf.Duration data_ttl = 6;
}

message CreateProjectJobMetadata {
  // ID of the project.
  string project_id = 1;
  // Job ID.
  string job_id = 2;
}

message CreateProjectJobResponse {
  // ID of the job.
  string job_id = 1;

  // Files to upload with their presigned URLs for upload.
  repeated StorageFile upload_files = 2;
}

message CloneProjectJobRequest {
  // ID of job to be cloned.
  string source_job_id = 1;
  // Parameters overrides.
  JobParameters job_parameters_overrides = 2;
  // New job name.
  string name = 3;
  // New job description
  string desc = 4;
  // Data ttl.
  google.protobuf.Duration data_ttl = 5;
}

message CloneProjectJobResponse {
  // Job ID.
  string job_id = 1;
  // Files with presigned URLs generated by server to upload them to storage. Order is arbitrary.
  //
  // Upload files include input files, executable file (python main script or binary executable) and local modules
  // in case of python.
  //
  // If file was already uploaded, there will be no element for it.
  repeated StorageFile upload_files = 2;
}

message CloneProjectJobMetadata {
  string project_id = 1;
  string job_id = 2;
}

message ExecuteProjectJobRequest {
  // ID of the job.
  string job_id = 1;
}

message ExecuteProjectJobResponse {
  // Uploaded output files with URLs.
  repeated StorageFile output_files = 1;

  // Result of the job.
  JobResult result = 2;
}

message ExecuteProjectJobMetadata {
  // Instance of the job.
  Job job = 1;
}

message CancelProjectJobRequest {
  // ID of the job.
  string job_id = 1;

  // Optional cancellation reason.
  string reason = 2;
}

message ReadProjectJobStdLogsRequest {
  // ID of the job.
  string job_id = 1;

  // Log offset.
  int64 offset = 2;
}

message ReadProjectJobStdLogsResponse {
  repeated StdLog logs = 1;

  // Log offset.
  int64 offset = 2;
}

message ReadProjectJobLogsRequest {
  // ID of the job.
  string job_id = 1;

  // Log offset.
  int64 offset = 2;
}

message ReadProjectJobLogsResponse {
  repeated LogMessage logs = 1;

  // Log offset.
  int64 offset = 2;
}

message DownloadProjectJobFilesRequest {
  string job_id = 1 [(required) = true];
  repeated File files = 2 [(size) = ">=1"];
}

message DownloadProjectJobFilesResponse {
  repeated StorageFile download_files = 1;
}

message ListProjectJobRequest {
  // ID of the project.
  string project_id = 1;

  // The maximum number of results per page to return. If the number of available
  // results is larger than [page_size],
  // the service returns a [ListProjectJobResponse.page_token]
  // that can be used to get the next page of results in subsequent list requests.
  int64 page_size = 2;

  // Page token. To get the next page of results, set [page_token] to the
  // [ListProjectJobResponse.page_token] returned by a previous list request.
  string page_token = 3;
}

message ListProjectJobResponse {
  // Instances of the jobs.
  repeated Job jobs = 1;

  // This token allows you to get the next page of results for list requests. If the number of results
  // is larger than [ListProjectJobRequest.page_size], use
  // the [next_page_token] as the value
  // for the [ListProjectJobRequest.page_token] query parameter
  // in the next list request. Each subsequent list request will have its own
  // [page_token] to continue paging through the results.
  string page_token = 2;
}

message GetProjectJobRequest {
  // ID of the job.
  string job_id = 1;
}

message DeleteProjectJobRequest {
  // ID of the job.
  string job_id = 1;
}

message DeleteProjectJobMetadata {
  // ID of the job.
  string job_id = 1;
}

message DeleteProjectJobDataRequest {
  // ID of the job.
  string job_id = 1;
}

message DeleteProjectJobDataMetadata {
  // ID of the job.
  string job_id = 1;
}

message DeleteProjectJobDataResponse {
}

message DeleteAllProjectJobDataRequest {
  string project_id = 1;
}

message DeleteAllProjectJobDataMetadata {
  string project_id = 1;
}

message DeleteAllProjectJobDataResponse {
}

message SetProjectJobDataTtlRequest {
  string job_id = 1;
  google.protobuf.Duration ttl = 2;
}

message SetProjectJobDataTtlResponse {
}

message StdLog {
  enum Type {
    TYPE_UNSPECIFIED = 0;
    // stdout.
    OUT = 1;
    // stderr.
    ERR = 2;
  }

  // Log contents.
  bytes content = 1;

  // Log type.
  Type type = 2;
}

enum StandardStream {
  STANDARD_STREAM_UNSPECIFIED = 0;
  // Stdout.
  OUT = 1;
  // Stderr.
  ERR = 2;
}

message LogMessage {
  // Log message contents.
  bytes content = 1;
  // Log message creation timestamp.
  google.protobuf.Timestamp created_at = 2;

  oneof source {
    // Program standard streams.
    StandardStream standard_stream = 3;
    // System debug log files.
    string file_path = 4;
  }
}
