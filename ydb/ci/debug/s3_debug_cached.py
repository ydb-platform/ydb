#!/usr/bin/env python3
import subprocess
import json
import pickle
import sys
import os
import time
import argparse
from datetime import datetime
import concurrent.futures
from threading import Lock

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
bucket_name = "ydb-gh-logs"
default_prefix = "ydb-platform/ydb/"
max_keys = 10000
cache_file = "s3_cache.pkl"

def human_readable_size(size_bytes):
    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
        if size_bytes < 1024.0:
            return f"{size_bytes:.2f} {unit}"
        size_bytes /= 1024.0
    return f"{size_bytes:.2f} PB"

def run_yc_command(continuation_token=None, prefix=None, delimiter=None):
    command = [
        "yc", "storage", "s3api", "list-objects",
        "--bucket", bucket_name,
        "--prefix", prefix or default_prefix,
        "--max-keys", str(max_keys),
        "--format", "json"
    ]
    
    if continuation_token:
        command.extend(["--continuation-token", continuation_token])
    
    if delimiter:
        command.extend(["--delimiter", delimiter])
    
    result = subprocess.run(command, capture_output=True, text=True)
    
    if result.returncode != 0:
        print(f"–û—à–∏–±–∫–∞ –¥–ª—è –ø—Ä–µ—Ñ–∏–∫—Å–∞ {prefix}: {result.stderr}", file=sys.stderr)
        return None
    
    return json.loads(result.stdout)

def get_first_level_folders(prefix=None):
    """–ü–æ–ª—É—á–∞–µ—Ç –ø–∞–ø–∫–∏ –ø–µ—Ä–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è –∏—Å–ø–æ–ª—å–∑—É—è delimiter"""
    print(f"üîç –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–∞–ø–æ–∫ –ø–µ—Ä–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è –¥–ª—è –ø—Ä–µ—Ñ–∏–∫—Å–∞: {prefix or default_prefix}", file=sys.stderr)
    
    result = run_yc_command(prefix=prefix, delimiter='/')
    if not result:
        return []
    
    # –ü–æ–ª—É—á–∞–µ–º common prefixes (–ø–∞–ø–∫–∏)
    common_prefixes = result.get("common_prefixes", [])
    folders = [cp.get("prefix", "") for cp in common_prefixes]
    
    print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ –ø–∞–ø–æ–∫ –ø–µ—Ä–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è: {len(folders)}", file=sys.stderr)
    for folder in folders:
        print(f"   üìÇ {folder}", file=sys.stderr)
    
    return folders

def get_build_types_from_pr_folders(prefix="ydb-platform/ydb/PR-check/"):
    """–ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ –ø–∞–ø–∫–∏ –∏–∑ prefix –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø—ã –±–∏–ª–¥–æ–≤"""
    print(f"üîç –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–∞–ø–æ–∫ –∏–∑ {prefix}...", file=sys.stderr)
    
    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –ø–∞–ø–∫–∏
    pr_folders = []
    continuation_token = None
    
    while True:
        result = run_yc_command(continuation_token, prefix, delimiter='/')
        if not result:
            break
            
        common_prefixes = result.get("common_prefixes", [])
        if not common_prefixes:
            break
            
        pr_folders.extend([cp.get("prefix", "") for cp in common_prefixes])
        
        continuation_token = result.get("next_continuation_token")
        if not continuation_token:
            break
    
    print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ {len(pr_folders)} –ø–∞–ø–æ–∫ –≤ {prefix}", file=sys.stderr)
    
    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø—ã –±–∏–ª–¥–æ–≤ –∏–∑ –ø–µ—Ä–≤—ã—Ö –ø–∞–ø–æ–∫
    build_types = set()
    sample_size = min(20, len(pr_folders))  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤—ã–±–æ—Ä–∫—É –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–∫—Ä—ã—Ç–∏—è
    
    print(f"üîç –ê–Ω–∞–ª–∏–∑ —Ç–∏–ø–æ–≤ –±–∏–ª–¥–æ–≤ –≤ {sample_size} –ø–∞–ø–∫–∞—Ö...", file=sys.stderr)
    
    for i, pr_folder in enumerate(pr_folders[:sample_size]):
        if i % 5 == 0:
            print(f"   üìÇ –ê–Ω–∞–ª–∏–∑ –ø–∞–ø–∫–∏ {i+1}/{sample_size}: {pr_folder.split('/')[-2]}", file=sys.stderr)
        
        result = run_yc_command(prefix=pr_folder, delimiter='/')
        if result:
            common_prefixes = result.get("common_prefixes", [])
            for cp in common_prefixes:
                build_type = cp.get("prefix", "").split('/')[-2]
                if build_type:
                    build_types.add(build_type)
    
    build_types = sorted(list(build_types))
    print(f"üèóÔ∏è  –ù–∞–π–¥–µ–Ω–æ —Ç–∏–ø–æ–≤ –±–∏–ª–¥–æ–≤: {build_types}", file=sys.stderr)
    
    return pr_folders, build_types

def collect_folder_data_simple(folder_prefix):
    """–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–¥–Ω–æ–π –ø–∞–ø–∫–∏ (–±–µ–∑ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã)"""
    folder_files = []
    folder_total_files = 0
    folder_total_size = 0
    oldest_date = None
    
    continuation_token = None
    
    while True:
        result = run_yc_command(continuation_token, folder_prefix)
        
        if not result:
            break
            
        contents = result.get("contents", [])
        if not contents:
            break
        
        for obj in contents:
            key = obj.get("key", "")
            size = int(obj.get("size", 0))
            last_modified = obj.get("last_modified", "")
            
            if not key.startswith(folder_prefix):
                continue
            
            folder_total_files += 1
            folder_total_size += size
            
            # –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º —Å–∞–º—É—é —Å—Ç–∞—Ä—É—é –¥–∞—Ç—É
            if last_modified:
                try:
                    file_date = datetime.fromisoformat(last_modified.replace('Z', '+00:00'))
                    if oldest_date is None or file_date < oldest_date:
                        oldest_date = file_date
                except (ValueError, TypeError):
                    pass  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –¥–∞—Ç—ã
            
            file_info = {
                'key': key,
                'size': size,
                'last_modified': last_modified
            }
            folder_files.append(file_info)
        
        continuation_token = result.get("next_continuation_token")
        if not continuation_token:
            break
    
    return {
        'folder_prefix': folder_prefix,
        'files': folder_files,
        'total_files': folder_total_files,
        'total_size': folder_total_size,
        'oldest_date': oldest_date.isoformat() if oldest_date else None
    }

def collect_pr_folder_build_types(pr_folder, known_build_types):
    """–°–æ–±–∏—Ä–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø–æ —Ç–∏–ø–∞–º –±–∏–ª–¥–æ–≤ –¥–ª—è –æ–¥–Ω–æ–π –ø–∞–ø–∫–∏ PR-check"""
    folder_build_data = {}
    
    # –ü–æ–ª—É—á–∞–µ–º —Ç–∏–ø—ã –±–∏–ª–¥–æ–≤ –≤ —ç—Ç–æ–π –ø–∞–ø–∫–µ
    result = run_yc_command(prefix=pr_folder, delimiter='/')
    if not result:
        return folder_build_data
        
    common_prefixes = result.get("common_prefixes", [])
    
    for cp in common_prefixes:
        build_folder = cp.get("prefix", "")
        build_type = build_folder.split('/')[-2]
        
        if build_type not in known_build_types:
            continue
        
        # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç—Ç–æ–≥–æ —Ç–∏–ø–∞ –±–∏–ª–¥–∞
        folder_data = collect_folder_data_simple(build_folder)
        if folder_data:
            folder_build_data[build_type] = {
                'size': folder_data['total_size'],
                'files': folder_data['total_files'],
                'folder_path': build_folder,
                'oldest_date': folder_data['oldest_date']
            }
    
    return folder_build_data

def collect_build_types_data(prefix="ydb-platform/ydb/PR-check/"):
    """–°–æ–±–∏—Ä–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ —Ç–∏–ø–∞–º –±–∏–ª–¥–æ–≤ —Å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π"""
    start_time = time.time()
    
    print(f"üöÄ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –ø–æ —Ç–∏–ø–∞–º –±–∏–ª–¥–æ–≤ –∏–∑ {prefix}...", file=sys.stderr)
    
    # –ü–æ–ª—É—á–∞–µ–º –ø–∞–ø–∫–∏ –∏ —Ç–∏–ø—ã –±–∏–ª–¥–æ–≤
    pr_folders, build_types = get_build_types_from_pr_folders(prefix)
    
    if not pr_folders or not build_types:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–∞–ø–æ–∫ –∏–ª–∏ —Ç–∏–ø–æ–≤ –±–∏–ª–¥–æ–≤", file=sys.stderr)
        return None
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–≥—Ä–µ–≥–∞—Ü–∏–∏
    build_type_stats = {build_type: {'size': 0, 'files': 0, 'folders': 0, 'oldest_date': None} for build_type in build_types}
    build_type_files = {build_type: [] for build_type in build_types}
    
    total_processed = 0
    completed_folders = 0
    processed_lock = Lock()
    
    # –£–º–µ–Ω—å—à–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
    max_workers = min(15, len(pr_folders))
    print(f"üîÑ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ {len(pr_folders)} –ø–∞–ø–æ–∫ (–º–∞–∫—Å. {max_workers} –ø–æ—Ç–æ–∫–æ–≤)...", file=sys.stderr)
    
    def print_progress():
        """–í—ã–≤–æ–¥–∏—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä"""
        if len(pr_folders) == 0:
            return
            
        progress = completed_folders / len(pr_folders) * 100
        bar_length = 50
        filled_length = int(bar_length * completed_folders // len(pr_folders))
        bar = '‚ñà' * filled_length + '-' * (bar_length - filled_length)
        
        elapsed = time.time() - start_time
        if completed_folders > 0:
            eta = elapsed * (len(pr_folders) - completed_folders) / completed_folders
            eta_str = f"ETA: {eta:.0f}s"
        else:
            eta_str = "ETA: --"
        
        print(f"\rüìä [{bar}] {progress:.1f}% ({completed_folders}/{len(pr_folders)}) | {eta_str} | –ë–∏–ª–¥—ã: {total_processed}", 
              end='', file=sys.stderr, flush=True)
    
    def process_pr_folder(pr_folder):
        nonlocal total_processed, completed_folders
        try:
            folder_build_data = collect_pr_folder_build_types(pr_folder, build_types)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ
            with processed_lock:
                folder_processed = 0
                for build_type, data in folder_build_data.items():
                    build_type_stats[build_type]['size'] += data['size']
                    build_type_stats[build_type]['files'] += data['files']
                    build_type_stats[build_type]['folders'] += 1
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å–∞–º—É—é —Å—Ç–∞—Ä—É—é –¥–∞—Ç—É
                    if data['oldest_date']:
                        try:
                            file_date = datetime.fromisoformat(data['oldest_date'])
                            current_oldest = build_type_stats[build_type]['oldest_date']
                            if current_oldest is None:
                                build_type_stats[build_type]['oldest_date'] = data['oldest_date']
                            else:
                                current_oldest_date = datetime.fromisoformat(current_oldest)
                                if file_date < current_oldest_date:
                                    build_type_stats[build_type]['oldest_date'] = data['oldest_date']
                        except (ValueError, TypeError):
                            pass  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –¥–∞—Ç—ã
                    
                    folder_processed += 1
                
                total_processed += folder_processed
                completed_folders += 1
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å —á–∞—â–µ –¥–ª—è –ª—É—á—à–µ–π –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏
                if completed_folders % 1 == 0:  # –ö–∞–∂–¥—É—é –ø–∞–ø–∫—É
                    print_progress()
            
            return folder_build_data
            
        except Exception as e:
            with processed_lock:
                completed_folders += 1
                pr_name = pr_folder.split('/')[-2] if '/' in pr_folder else pr_folder
                print(f"\n‚ùå –û—à–∏–±–∫–∞ –≤ –ø–∞–ø–∫–µ {pr_name}: {str(e)[:100]}", file=sys.stderr)
                print_progress()
            return {}
    
    # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å —É–º–µ–Ω—å—à–µ–Ω–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø–æ—Ç–æ–∫–æ–≤
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∑–∞–¥–∞—á–∏
        future_to_folder = {
            executor.submit(process_pr_folder, pr_folder): pr_folder 
            for pr_folder in pr_folders
        }
        
        # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å —Ç–∞–π–º–∞—É—Ç–æ–º
        try:
            for future in concurrent.futures.as_completed(future_to_folder, timeout=300):  # 5 –º–∏–Ω—É—Ç —Ç–∞–π–º–∞—É—Ç
                pr_folder = future_to_folder[future]
                try:
                    folder_build_data = future.result(timeout=60)  # 1 –º–∏–Ω—É—Ç–∞ –Ω–∞ –ø–∞–ø–∫—É
                    # –†–µ–∑—É–ª—å—Ç–∞—Ç —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –≤ process_pr_folder
                except concurrent.futures.TimeoutError:
                    pr_name = pr_folder.split('/')[-2] if '/' in pr_folder else pr_folder
                    with processed_lock:
                        completed_folders += 1
                        print(f"\n‚è∞ –¢–∞–π–º–∞—É—Ç –¥–ª—è –ø–∞–ø–∫–∏ {pr_name}", file=sys.stderr)
                        print_progress()
                except Exception as exc:
                    pr_name = pr_folder.split('/')[-2] if '/' in pr_folder else pr_folder
                    with processed_lock:
                        completed_folders += 1
                        print(f"\n‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–∞–ø–∫–∏ {pr_name}: {str(exc)[:100]}", file=sys.stderr)
                        print_progress()
        except concurrent.futures.TimeoutError:
            print(f"\n‚è∞ –û–±—â–∏–π —Ç–∞–π–º–∞—É—Ç –¥–æ—Å—Ç–∏–≥–Ω—É—Ç, –∑–∞–≤–µ—Ä—à–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É...", file=sys.stderr)
    
    # –§–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å
    print_progress()
    print("", file=sys.stderr)  # –ù–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –ø–æ—Å–ª–µ –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞
    
    collection_time = time.time() - start_time
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    cache_data = {
        'timestamp': datetime.now().isoformat(),
        'prefix': prefix,
        'build_type_stats': build_type_stats,
        'build_type_files': build_type_files,
        'build_types': build_types,
        'total_pr_folders': len(pr_folders),
        'total_processed_folders': total_processed,
        'collection_time': collection_time,
        'collection_method': 'build_types_parallel_aggregation'
    }
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
    build_types_cache_file = "s3_build_types_cache.pkl"
    with open(build_types_cache_file, 'wb') as f:
        pickle.dump(cache_data, f)
    
    print(f"üíæ –î–∞–Ω–Ω—ã–µ –ø–æ —Ç–∏–ø–∞–º –±–∏–ª–¥–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {build_types_cache_file}", file=sys.stderr)
    print(f"‚ö° –í—Ä–µ–º—è —Å–±–æ—Ä–∞: {collection_time:.1f}—Å", file=sys.stderr)
    print(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {total_processed} –ø–∞–ø–æ–∫ —Å –±–∏–ª–¥–∞–º–∏ –∏–∑ {len(pr_folders)} –ø–∞–ø–æ–∫", file=sys.stderr)
    
    return cache_data

def analyze_build_types_data(data):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏ –≤—ã–≤–æ–¥–∏—Ç –¥–∞–Ω–Ω—ã–µ –ø–æ —Ç–∏–ø–∞–º –±–∏–ª–¥–æ–≤"""
    build_type_stats = data['build_type_stats']
    build_types = data['build_types']
    
    print("\n" + "="*80)
    print("–ê–ì–†–ï–ì–ê–¶–ò–Ø –ü–û –¢–ò–ü–ê–ú –ë–ò–õ–î–û–í")
    print("="*80)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–∞–∑–º–µ—Ä—É
    sorted_build_types = sorted(
        build_types, 
        key=lambda bt: build_type_stats[bt]['size'], 
        reverse=True
    )
    
    print(f"{'–¢–∏–ø –±–∏–ª–¥–∞':<35} | {'–†–∞–∑–º–µ—Ä':>12} | {'–§–∞–π–ª–æ–≤':>10} | {'–ü–∞–ø–æ–∫':>8} | {'–°–∞–º—ã–π —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª':>16}")
    print("-" * 95)
    
    total_size = 0
    total_files = 0
    total_folders = 0
    
    for build_type in sorted_build_types:
        stats = build_type_stats[build_type]
        size = stats['size']
        files = stats['files']
        folders = stats['folders']
        oldest_date = stats.get('oldest_date')
        
        if oldest_date:
            try:
                oldest_dt = datetime.fromisoformat(oldest_date)
                oldest_str = oldest_dt.strftime('%Y-%m-%d')
            except (ValueError, TypeError):
                oldest_str = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
        else:
            oldest_str = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
        
        total_size += size
        total_files += files
        total_folders += folders
        
        print(f"{build_type:<35} | {human_readable_size(size):>12} | {files:>10} | {folders:>8} | {oldest_str:>16}")
    
    print("-" * 95)
    print(f"{'–ò–¢–û–ì–û':<35} | {human_readable_size(total_size):>12} | {total_files:>10} | {total_folders:>8} | {'--':>16}")
    
    print(f"\n" + "="*80)
    print("–°–¢–ê–¢–ò–°–¢–ò–ö–ê –°–ë–û–†–ê")
    print("="*80)
    print(f"üìÅ –í—Å–µ–≥–æ –ø–∞–ø–æ–∫: {data['total_pr_folders']}")
    print(f"üèóÔ∏è  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –ø–∞–ø–æ–∫ —Å –±–∏–ª–¥–∞–º–∏: {data['total_processed_folders']}")
    print(f"‚è±Ô∏è  –í—Ä–µ–º—è —Å–±–æ—Ä–∞: {data['collection_time']:.1f} —Å–µ–∫—É–Ω–¥")
    print(f"üìÖ –î–∞—Ç–∞ —Å–±–æ—Ä–∞: {datetime.fromisoformat(data['timestamp']).strftime('%Y-%m-%d %H:%M:%S')}")

def load_build_types_cache():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø–æ —Ç–∏–ø–∞–º –±–∏–ª–¥–æ–≤ –∏–∑ –∫—ç—à–∞"""
    build_types_cache_file = "s3_build_types_cache.pkl"
    
    if not os.path.exists(build_types_cache_file):
        print(f"‚ùå –§–∞–π–ª –∫—ç—à–∞ {build_types_cache_file} –Ω–µ –Ω–∞–π–¥–µ–Ω. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –ø–æ —Ç–∏–ø–∞–º –±–∏–ª–¥–æ–≤.", file=sys.stderr)
        return None
    
    try:
        with open(build_types_cache_file, 'rb') as f:
            data = pickle.load(f)
        
        cache_time = datetime.fromisoformat(data['timestamp'])
        print(f"üìÇ –ó–∞–≥—Ä—É–∂–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –ø–æ —Ç–∏–ø–∞–º –±–∏–ª–¥–æ–≤ –∏–∑ –∫—ç—à–∞ (—Å–æ–±—Ä–∞–Ω—ã: {cache_time.strftime('%Y-%m-%d %H:%M:%S')})", file=sys.stderr)
        return data
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫—ç—à–∞ —Ç–∏–ø–æ–≤ –±–∏–ª–¥–æ–≤: {e}", file=sys.stderr)
        return None

def collect_all_folders_build_types(prefix="ydb-platform/ydb/"):
    """–°–æ–±–∏—Ä–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø–æ —Ç–∏–ø–∞–º –±–∏–ª–¥–æ–≤ –¥–ª—è –≤—Å–µ—Ö –ø–∞–ø–æ–∫ –ø–µ—Ä–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è"""
    start_time = time.time()
    
    print(f"üöÄ –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –ø–æ —Ç–∏–ø–∞–º –±–∏–ª–¥–æ–≤ –¥–ª—è –≤—Å–µ—Ö –ø–∞–ø–æ–∫ –≤ {prefix}...", file=sys.stderr)
    
    # –ü–æ–ª—É—á–∞–µ–º –ø–∞–ø–∫–∏ –ø–µ—Ä–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è
    first_level_folders = get_first_level_folders(prefix)
    
    if not first_level_folders:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–∞–ø–æ–∫ –ø–µ—Ä–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è", file=sys.stderr)
        return None
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–±—â—É—é –∞–≥—Ä–µ–≥–∞—Ü–∏—é
    all_build_type_stats = {}
    all_build_types = set()
    folder_results = {}
    
    total_folders_processed = 0
    total_build_folders = 0
    total_size_all = 0
    total_files_all = 0
    
    print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ {len(first_level_folders)} –ø–∞–ø–æ–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏", file=sys.stderr)
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é –ø–∞–ø–∫—É –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ
    for i, folder in enumerate(first_level_folders):
        folder_name = folder.split('/')[-2]
        print(f"\n" + "="*80, file=sys.stderr)
        print(f"üìÇ –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞–ø–∫–∏ {i+1}/{len(first_level_folders)}: {folder_name}", file=sys.stderr)
        print("="*80, file=sys.stderr)
        
        # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç—Ç–æ–π –ø–∞–ø–∫–∏
        folder_data = collect_build_types_data(folder)
        
        if folder_data and folder_data['build_type_stats']:
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –∞–Ω–∞–ª–∏—Ç–∏–∫—É –ø–æ —ç—Ç–æ–π –ø–∞–ø–∫–µ
            print(f"\nüîç –î–ï–¢–ê–õ–¨–ù–ê–Ø –ê–ù–ê–õ–ò–¢–ò–ö–ê –ü–û –ü–ê–ü–ö–ï: {folder_name}", file=sys.stderr)
            print("="*80, file=sys.stderr)
            analyze_build_types_data(folder_data)
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–∏–ø—ã –±–∏–ª–¥–æ–≤ –≤ –æ–±—â–∏–π —Å–ø–∏—Å–æ–∫
            all_build_types.update(folder_data['build_types'])
            
            # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            for build_type, stats in folder_data['build_type_stats'].items():
                if build_type not in all_build_type_stats:
                    all_build_type_stats[build_type] = {'size': 0, 'files': 0, 'folders': 0, 'source_folders': [], 'oldest_date': None}
                
                all_build_type_stats[build_type]['size'] += stats['size']
                all_build_type_stats[build_type]['files'] += stats['files']
                all_build_type_stats[build_type]['folders'] += stats['folders']
                all_build_type_stats[build_type]['source_folders'].append(folder_name)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å–∞–º—É—é —Å—Ç–∞—Ä—É—é –¥–∞—Ç—É
                if stats.get('oldest_date'):
                    try:
                        file_date = datetime.fromisoformat(stats['oldest_date'])
                        current_oldest = all_build_type_stats[build_type]['oldest_date']
                        if current_oldest is None:
                            all_build_type_stats[build_type]['oldest_date'] = stats['oldest_date']
                        else:
                            current_oldest_date = datetime.fromisoformat(current_oldest)
                            if file_date < current_oldest_date:
                                all_build_type_stats[build_type]['oldest_date'] = stats['oldest_date']
                    except (ValueError, TypeError):
                        pass  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –¥–∞—Ç—ã
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–∞–ø–∫–∏
            folder_results[folder_name] = folder_data
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –æ–±—â–∏–µ —Å—á–µ—Ç—á–∏–∫–∏
            total_build_folders += folder_data['total_processed_folders']
            folder_total_size = sum(stats['size'] for stats in folder_data['build_type_stats'].values())
            folder_total_files = sum(stats['files'] for stats in folder_data['build_type_stats'].values())
            total_size_all += folder_total_size
            total_files_all += folder_total_files
            total_folders_processed += 1
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É –ø–æ —Ç–µ–∫—É—â–µ–π –ø–∞–ø–∫–µ
            print(f"\n‚úÖ –°–í–û–î–ö–ê –ü–û –ü–ê–ü–ö–ï {folder_name}:", file=sys.stderr)
            print(f"   üèóÔ∏è  –¢–∏–ø–æ–≤ –±–∏–ª–¥–æ–≤: {len(folder_data['build_type_stats'])}", file=sys.stderr)
            print(f"   üìä –ü–∞–ø–æ–∫ —Å –±–∏–ª–¥–∞–º–∏: {folder_data['total_processed_folders']}", file=sys.stderr)
            print(f"   üíæ –†–∞–∑–º–µ—Ä: {human_readable_size(folder_total_size)}", file=sys.stderr)
            print(f"   üìÑ –§–∞–π–ª–æ–≤: {folder_total_files:,}", file=sys.stderr)
            print(f"   ‚è±Ô∏è  –í—Ä–µ–º—è: {folder_data['collection_time']:.1f}—Å", file=sys.stderr)
        else:
            print(f"‚ö†Ô∏è  –ü–∞–ø–∫–∞ {folder_name}: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ —Ç–∏–ø–∞–º –±–∏–ª–¥–æ–≤", file=sys.stderr)
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ–±—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å
        elapsed = time.time() - start_time
        remaining = len(first_level_folders) - (i + 1)
        if i > 0:
            avg_time = elapsed / (i + 1)
            eta = avg_time * remaining
            eta_str = f"ETA: {eta:.0f}s"
        else:
            eta_str = "ETA: --"
        
        print(f"\nüîÑ –û–ë–©–ò–ô –ü–†–û–ì–†–ï–°–°: {i+1}/{len(first_level_folders)} –ø–∞–ø–æ–∫ | {eta_str}", file=sys.stderr)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –º–µ–∂–¥—É –ø–∞–ø–∫–∞–º–∏
        if i < len(first_level_folders) - 1:  # –ù–µ –¥–æ–±–∞–≤–ª—è–µ–º –≤ –∫–æ–Ω—Ü–µ
            print(f"\n{'='*80}", file=sys.stderr)
            print(f"–ü–ï–†–ï–•–û–î–ò–ú –ö –°–õ–ï–î–£–Æ–©–ï–ô –ü–ê–ü–ö–ï...", file=sys.stderr)
            print(f"{'='*80}", file=sys.stderr)
    
    collection_time = time.time() - start_time
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    all_build_types = sorted(list(all_build_types))
    
    cache_data = {
        'timestamp': datetime.now().isoformat(),
        'prefix': prefix,
        'all_build_type_stats': all_build_type_stats,
        'all_build_types': all_build_types,
        'folder_results': folder_results,
        'total_first_level_folders': len(first_level_folders),
        'total_folders_with_builds': total_folders_processed,
        'total_build_folders': total_build_folders,
        'total_size': total_size_all,
        'total_files': total_files_all,
        'collection_time': collection_time,
        'collection_method': 'all_folders_build_types_aggregation'
    }
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π –∫—ç—à
    all_build_types_cache_file = "s3_all_build_types_cache.pkl"
    with open(all_build_types_cache_file, 'wb') as f:
        pickle.dump(cache_data, f)
    
    print(f"\n" + "="*80, file=sys.stderr)
    print("üéâ –í–°–ï –ü–ê–ü–ö–ò –û–ë–†–ê–ë–û–¢–ê–ù–´!", file=sys.stderr)
    print("="*80, file=sys.stderr)
    print(f"üíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {all_build_types_cache_file}", file=sys.stderr)
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    analyze_all_build_types_data(cache_data)
    
    return cache_data

def analyze_all_build_types_data(data):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏ –≤—ã–≤–æ–¥–∏—Ç –∏—Ç–æ–≥–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –≤—Å–µ–º –ø–∞–ø–∫–∞–º"""
    all_build_type_stats = data['all_build_type_stats']
    all_build_types = data['all_build_types']
    folder_results = data['folder_results']
    
    print("\n" + "="*110)
    print("–ò–¢–û–ì–û–í–ê–Ø –ê–ì–†–ï–ì–ê–¶–ò–Ø –ü–û –í–°–ï–ú –¢–ò–ü–ê–ú –ë–ò–õ–î–û–í")
    print("="*110)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–∞–∑–º–µ—Ä—É
    sorted_build_types = sorted(
        all_build_types, 
        key=lambda bt: all_build_type_stats.get(bt, {}).get('size', 0), 
        reverse=True
    )
    
    print(f"{'–¢–∏–ø –±–∏–ª–¥–∞':<70} | {'–†–∞–∑–º–µ—Ä':>12} | {'–§–∞–π–ª–æ–≤':>10} | {'–ü–∞–ø–æ–∫':>8} | {'–ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤':>12} | {'–°–∞–º—ã–π —Å—Ç–∞—Ä—ã–π':>16}")
    print("-" * 110)
    
    total_size = 0
    total_files = 0
    total_folders = 0
    
    for build_type in sorted_build_types:
        if build_type not in all_build_type_stats:
            continue
            
        stats = all_build_type_stats[build_type]
        size = stats['size']
        files = stats['files']
        folders = stats['folders']
        sources = len(set(stats['source_folders']))
        oldest_date = stats.get('oldest_date')
        
        if oldest_date:
            try:
                oldest_dt = datetime.fromisoformat(oldest_date)
                oldest_str = oldest_dt.strftime('%Y-%m-%d')
            except (ValueError, TypeError):
                oldest_str = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
        else:
            oldest_str = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
        
        total_size += size
        total_files += files
        total_folders += folders
        
        print(f"{build_type:<70} | {human_readable_size(size):>12} | {files:>10} | {folders:>8} | {sources:>12} | {oldest_str:>16}")
    
    print("-" * 110)
    print(f"{'–ò–¢–û–ì–û':<70} | {human_readable_size(total_size):>12} | {total_files:>10} | {total_folders:>8} | {'--':>12} | {'--':>16}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–∞–ø–∫–∞–º –ø–µ—Ä–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è
    print(f"\n" + "="*120)
    print("–°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –ü–ê–ü–ö–ê–ú –ü–ï–†–í–û–ì–û –£–†–û–í–ù–Ø")
    print("="*120)
    
    folder_stats = []
    for folder_name, folder_data in folder_results.items():
        folder_total_size = sum(stats['size'] for stats in folder_data['build_type_stats'].values())
        folder_total_files = sum(stats['files'] for stats in folder_data['build_type_stats'].values())
        
        # –ù–∞—Ö–æ–¥–∏–º —Å–∞–º—É—é —Å—Ç–∞—Ä—É—é –¥–∞—Ç—É –≤ —ç—Ç–æ–π –ø–∞–ø–∫–µ
        folder_oldest_date = None
        for build_type, stats in folder_data['build_type_stats'].items():
            if stats.get('oldest_date'):
                try:
                    file_date = datetime.fromisoformat(stats['oldest_date'])
                    if folder_oldest_date is None or file_date < folder_oldest_date:
                        folder_oldest_date = file_date
                except (ValueError, TypeError):
                    pass
        
        if folder_oldest_date:
            oldest_str = folder_oldest_date.strftime('%Y-%m-%d')
        else:
            oldest_str = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
        
        folder_stats.append((folder_name, folder_total_size, folder_total_files, len(folder_data['build_type_stats']), oldest_str))
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–∞–∑–º–µ—Ä—É
    folder_stats.sort(key=lambda x: x[1], reverse=True)
    
    print(f"{'–ü–∞–ø–∫–∞':<40} | {'–†–∞–∑–º–µ—Ä':>12} | {'–§–∞–π–ª–æ–≤':>10} | {'–¢–∏–ø–æ–≤ –±–∏–ª–¥–æ–≤':>15} | {'–°–∞–º—ã–π —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª':>16}")
    print("-" * 90)
    
    for folder_name, size, files, build_types_count, oldest_str in folder_stats:
        print(f"{folder_name:<40} | {human_readable_size(size):>12} | {files:>10} | {build_types_count:>15} | {oldest_str:>16}")
    
    print(f"\n" + "="*100)
    print("–û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    print("="*100)
    print(f"üìÅ –ü–∞–ø–æ–∫ –ø–µ—Ä–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è: {data['total_first_level_folders']}")
    print(f"üèóÔ∏è  –ü–∞–ø–æ–∫ —Å —Ç–∏–ø–∞–º–∏ –±–∏–ª–¥–æ–≤: {data['total_folders_with_builds']}")
    print(f"üìä –í—Å–µ–≥–æ –ø–∞–ø–æ–∫ —Å –±–∏–ª–¥–∞–º–∏: {data['total_build_folders']}")
    print(f"üéØ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–∏–ø–æ–≤ –±–∏–ª–¥–æ–≤: {len(all_build_types)}")
    print(f"üíæ –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {human_readable_size(data['total_size'])}")
    print(f"üìÑ –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤: {data['total_files']:,}")
    print(f"‚è±Ô∏è  –û–±—â–µ–µ –≤—Ä–µ–º—è —Å–±–æ—Ä–∞: {data['collection_time']:.1f} —Å–µ–∫—É–Ω–¥")
    print(f"üìÖ –î–∞—Ç–∞ —Å–±–æ—Ä–∞: {datetime.fromisoformat(data['timestamp']).strftime('%Y-%m-%d %H:%M:%S')}")

def load_all_build_types_cache():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø–æ –≤—Å–µ–º —Ç–∏–ø–∞–º –±–∏–ª–¥–æ–≤ –∏–∑ –∫—ç—à–∞"""
    all_build_types_cache_file = "s3_all_build_types_cache.pkl"
    
    if not os.path.exists(all_build_types_cache_file):
        print(f"‚ùå –§–∞–π–ª –∫—ç—à–∞ {all_build_types_cache_file} –Ω–µ –Ω–∞–π–¥–µ–Ω. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤—Å–µ–º —Ç–∏–ø–∞–º –±–∏–ª–¥–æ–≤.", file=sys.stderr)
        return None
    
    try:
        with open(all_build_types_cache_file, 'rb') as f:
            data = pickle.load(f)
        
        cache_time = datetime.fromisoformat(data['timestamp'])
        print(f"üìÇ –ó–∞–≥—Ä—É–∂–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –ø–æ –≤—Å–µ–º —Ç–∏–ø–∞–º –±–∏–ª–¥–æ–≤ –∏–∑ –∫—ç—à–∞ (—Å–æ–±—Ä–∞–Ω—ã: {cache_time.strftime('%Y-%m-%d %H:%M:%S')})", file=sys.stderr)
        return data
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫—ç—à–∞ –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –±–∏–ª–¥–æ–≤: {e}", file=sys.stderr)
        return None

def main():
    parser = argparse.ArgumentParser(description='–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã S3 —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –ø–æ —Ç–∏–ø–∞–º –±–∏–ª–¥–æ–≤')
    parser.add_argument('--collect-build-types', action='store_true', help='–°–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ —Ç–∏–ø–∞–º –±–∏–ª–¥–æ–≤')
    parser.add_argument('--collect-all-build-types', action='store_true', help='–°–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –ø–æ —Ç–∏–ø–∞–º –±–∏–ª–¥–æ–≤ –¥–ª—è –≤—Å–µ—Ö –ø–∞–ø–æ–∫ –ø–µ—Ä–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è')
    parser.add_argument('--analyze-build-types', action='store_true', help='–ü–æ–∫–∞–∑–∞—Ç—å –∞–Ω–∞–ª–∏–∑ –ø–æ —Ç–∏–ø–∞–º –±–∏–ª–¥–æ–≤')
    parser.add_argument('--analyze-all-build-types', action='store_true', help='–ü–æ–∫–∞–∑–∞—Ç—å –∞–Ω–∞–ª–∏–∑ –ø–æ –≤—Å–µ–º —Ç–∏–ø–∞–º –±–∏–ª–¥–æ–≤')
    parser.add_argument('--prefix', type=str, help='–§–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –ø–æ —É–∫–∞–∑–∞–Ω–Ω–æ–º—É –ø—Ä–µ—Ñ–∏–∫—Å—É')
    parser.add_argument('--cache-info', action='store_true', help='–ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫—ç—à–µ')
    
    args = parser.parse_args()
    
    if args.cache_info:
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫—ç—à–µ —Ç–∏–ø–æ–≤ –±–∏–ª–¥–æ–≤
        build_types_cache_file = "s3_build_types_cache.pkl"
        if os.path.exists(build_types_cache_file):
            print(f"üìÇ –§–∞–π–ª –∫—ç—à–∞ —Ç–∏–ø–æ–≤ –±–∏–ª–¥–æ–≤: {build_types_cache_file}")
            data = load_build_types_cache()
            if data:
                cache_time = datetime.fromisoformat(data['timestamp'])
                print(f"üìÖ –î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è: {cache_time.strftime('%Y-%m-%d %H:%M:%S')}")
                print(f"üîç –ü—Ä–µ—Ñ–∏–∫—Å: {data['prefix']}")
                print(f"üèóÔ∏è  –¢–∏–ø–æ–≤ –±–∏–ª–¥–æ–≤: {len(data['build_types'])}")
                print(f"üìÅ –ü–∞–ø–æ–∫: {data['total_pr_folders']}")
                print(f"üîÑ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –ø–∞–ø–æ–∫: {data['total_processed_folders']}")
        else:
            print(f"‚ùå –§–∞–π–ª –∫—ç—à–∞ {build_types_cache_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫—ç—à–µ –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –±–∏–ª–¥–æ–≤
        all_build_types_cache_file = "s3_all_build_types_cache.pkl"
        if os.path.exists(all_build_types_cache_file):
            print(f"\nüìÇ –§–∞–π–ª –∫—ç—à–∞ –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –±–∏–ª–¥–æ–≤: {all_build_types_cache_file}")
            data = load_all_build_types_cache()
            if data:
                cache_time = datetime.fromisoformat(data['timestamp'])
                print(f"üìÖ –î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è: {cache_time.strftime('%Y-%m-%d %H:%M:%S')}")
                print(f"üîç –ü—Ä–µ—Ñ–∏–∫—Å: {data['prefix']}")
                print(f"üèóÔ∏è  –¢–∏–ø–æ–≤ –±–∏–ª–¥–æ–≤: {len(data['all_build_types'])}")
                print(f"üìÅ –ü–∞–ø–æ–∫ –ø–µ—Ä–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è: {data['total_first_level_folders']}")
                print(f"üîÑ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –ø–∞–ø–æ–∫ —Å –±–∏–ª–¥–∞–º–∏: {data['total_build_folders']}")
                print(f"üíæ –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {human_readable_size(data['total_size'])}")
        else:
            print(f"‚ùå –§–∞–π–ª –∫—ç—à–∞ {all_build_types_cache_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    if args.collect_all_build_types:
        # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ —Ç–∏–ø–∞–º –±–∏–ª–¥–æ–≤ –¥–ª—è –≤—Å–µ—Ö –ø–∞–ø–æ–∫
        data = collect_all_folders_build_types(args.prefix or "ydb-platform/ydb/")
        return
    
    if args.analyze_all_build_types:
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –≤—Å–µ–º —Ç–∏–ø–∞–º –±–∏–ª–¥–æ–≤ –∏–∑ –∫—ç—à–∞
        data = load_all_build_types_cache()
        if data:
            analyze_all_build_types_data(data)
        return
    
    if args.collect_build_types:
        # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ —Ç–∏–ø–∞–º –±–∏–ª–¥–æ–≤
        data = collect_build_types_data(args.prefix or "ydb-platform/ydb/PR-check/")
        if data:
            analyze_build_types_data(data)
        return
    
    if args.analyze_build_types:
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ —Ç–∏–ø–∞–º –±–∏–ª–¥–æ–≤ –∏–∑ –∫—ç—à–∞
        data = load_build_types_cache()
        if data:
            analyze_build_types_data(data)
        return
    
    # –ï—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ –Ω–∏–∫–∞–∫–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–ø—Ä–∞–≤–∫—É
    print("üí° –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:")
    print("  --collect-build-types        - –°–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –ø–æ —Ç–∏–ø–∞–º –±–∏–ª–¥–æ–≤ –¥–ª—è –æ–¥–Ω–æ–π –ø–∞–ø–∫–∏")
    print("  --collect-all-build-types    - –°–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –ø–æ —Ç–∏–ø–∞–º –±–∏–ª–¥–æ–≤ –¥–ª—è –≤—Å–µ—Ö –ø–∞–ø–æ–∫")
    print("  --analyze-build-types        - –ü–æ–∫–∞–∑–∞—Ç—å –∞–Ω–∞–ª–∏–∑ –ø–æ —Ç–∏–ø–∞–º –±–∏–ª–¥–æ–≤ –∏–∑ –∫—ç—à–∞")
    print("  --analyze-all-build-types    - –ü–æ–∫–∞–∑–∞—Ç—å –∞–Ω–∞–ª–∏–∑ –ø–æ –≤—Å–µ–º —Ç–∏–ø–∞–º –±–∏–ª–¥–æ–≤")
    print("  --cache-info                 - –ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–∞—Ö –∫—ç—à–∞")
    print("  --prefix <–ø—É—Ç—å>              - –£–∫–∞–∑–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø—Ä–µ—Ñ–∏–∫—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")

if __name__ == "__main__":
    main() 