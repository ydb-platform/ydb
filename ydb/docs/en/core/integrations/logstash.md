# Using {{ ydb-short-name }} plugins in a Logstash

This section presents the description of plugins which may be used for connect {{ ydb-short-name }} and Logstash - a free and open server-side data processing pipeline.

## Introduction

[Logstash](https://www.elastic.co/logstash) dynamically ingests, transforms, and ships your data regardless of format or complexity. A Logstash pipeline can contains different types of plugins - input, output и filter. The {{ ydb-short-name }} Logstash plugins repository are hosted on [GitHub](https://github.com/ydb-platform/ydb-logstash-plugins) and contains the following plugins:

* Storage Plugin for storing Logstash events in [row-oriented](../concepts/datamodel/table.md#row-orineted_table) or [column-oriented](../concepts/datamodel/table.md#olap-data-types) tables {{ ydb-short-name }};
* Input Topic Plugin for reading Logstash events from {{ ydb-short-name }} [topic](../concepts/topic.md);
* Output Topic Plugin for sending Logstash events tp {{ ydb-short-name }} [topic](../concepts/topic.md).

 You can [build](https://github.com/ydb-platform/ydb-logstash-plugins/blob/main/BUILD.md) plugins yourself from sources or download pre-builded [artifacts](https://github.com/ydb-platform/ydb-logstash-plugins/releases) for two last version of Logstash.

{% note info %}

Further code snippets use a placeholder `<path-to-logstash>`, which must be replaced by the path to installed Logstash.

{% endnote %}

Any Logstash plugin may be installed by execution of command
```bash
<path-to-logstash>/bin/logstash-plugin install </path/to/logstash-plugin.gem>
```

Check that the plugin is installed
```bash
<path-to-logstash>/bin/logstash-plugin list
```
The command will return a list of all installed plugins and this list must contain the name of installed plugin.

## Configure {{ ydb-short-name }} connection

All plugins use the same set of parameters for configure connection to {{ ydb-short-name }}. This set contains only one required parameter `connection_string`, others parameters are optional and allow to configure [an authentication mode](../concepts/auth.md). If config doesn't contain any of them will be used anonymous mode.

```ruby
# This example demonstrates configuration for ydb_storage plugin.
# The plugins ydb_topics_output and ydb_topics_input configure the same way.
ydb_storage {
    # Database connection string contains schema, hostname, port and database path
    connection_string => "grpc://localhost:2136/local"
    # Authentication token (for using Access Token mode)
    token_auth => "<token_value>"
    # Authentication token file path (for using Access Token mode)
    token_file => "</path/to/token/file>"
    # Service account key file path (for using Service Account Key mode)
    sa_key_file => "</path/to/key.json>"
    # Flag to use metadata authentication service (for using Metadata mode)
    use_metadata => true
}
```

## {{ ydb-short-name }} Storage Plugin

This plugin allows to store the Logstash events stream in {{ ydb-short-name }} tables for further analysis. This is especially useful with [column tables](../concepts/datamodel/table.md#column-tables) optimized for handling Online Analytical Processing (OLAP) requests. Every [field](https://www.elastic.co/guide/en/logstash/current/event-dependent-configuration.html) of Logstash event will be stored in a column with a corresponding name. Those fields that do not match any column will be ignored.

### Configuration

The plugin configuration is making by adding `ydb_storage` block in `output` section of Logstash pipeline [config file](https://www.elastic.co/guide/en/logstash/current/configuration.html). The plugin supports standard set of [connection parameters](#configure-ydb-connection) and a few additional options:

* `table_name` - required name of a destination table
* `uuid_column` - optional name of column which the plugin will use for storing of auto generated identifier
* `timestamp_column` - optional name of column which the plugin will use for storing the timestamp of event

{% note warning %}

The Storage plugin doesn't check if the logstash event has correct and unique values for the table primary keys. It uses [bulk upsert method](../dev/batch-upload.md) for storing in {{ ydb-short-name }} and if various events have the same primary keys they will rewrite each other. It is recommended to use those events field that will be present in every event and uniquely identity it. If there is no such set of fields you can add a special column for the primary key and fill it with a random value using parameter `uuid_column`

{% endnote %}

### Example of usage

#### Creating a table
Let's create a new column-based table in any existing {{ ydb-short-name }} database with the columns we need. For a primary key we will use a random value generated by the plugin.

```sql
CREATE TABLE `logstash_demo` (
    `uuid`     Text NOT NULL,      -- identifier
    `ts`       Timestamp NOT NULL, -- timestamp of event creation
    `message`  Text,           
    `user`     Text,           
    `level`    Int32,

    PRIMARY KEY (
         `uuid`
    )
)
WITH (STORE = COLUMN);
```

#### Setup plugin in Logstash pipeline config

For activation of plugin we can add `ydb_storage` block in `output` section of Logstash pipeline [config](https://www.elastic.co/guide/en/logstash/current/configuration.html). Additionally let's add `http` block in `input` section for the creation of test messages by http requests:

```ruby
output {
  ydb_storage {
    connection_string => "..."    # connection string to  {{ ydb-short-name }}
    table_name => "logstash_demo" # the table name
    uuid_column => "uuid"         # the primary key column with random uuid
    timestamp_column => "ts"      # the key for storing the event timestamp
  }
}

input {
  http {
    port => 9876 # You can specify any free port
  }
}
```
For applying the changes we need to restart `Logstash`.

#### Sent test messages
Then we can sent a few test messages:
```bash
curl -H "content-type: application/json" -XPUT 'http://127.0.0.1:9876/http/ping' -d '{ "user" : "demo_user", "message" : "demo message", "level": 4}'
curl -H "content-type: application/json" -XPUT 'http://127.0.0.1:9876/http/ping' -d '{ "user" : "test1", "level": 1}'
curl -H "content-type: application/json" -XPUT 'http://127.0.0.1:9876/http/ping' -d '{ "message" : "error", "level": -3}'
```
All commands return `ok` if the messages are sent.

#### Check that the messages are stored in {{ ydb-short-name }} 
Now we can check that all sent messages are written in the table. Let's execute query (for work with the column-based table we must use [ScanQuery mode](../reference/ydb-cli/commands/scan-query.md)):
```sql
SELECT * FROM `logstash_demo`;
```
and we will get a list of written events:
```
┌───────┬────────────────┬───────────────────────────────┬─────────────┬────────────────────────────────────────┐
│ level │ message        │ ts                            │  user       │ uuid                                   │
├───────┼────────────────┼───────────────────────────────┼─────────────┼────────────────────────────────────────┤
│ -3    │ "error"        │ "2024-05-22T13:16:06.491000Z" │  null       │ "74cd4048-0b61-4fb9-9385-308714e21881" │
│  1    │ null           │ "2024-05-22T13:15:56.591000Z" │ "test1"     │ "1df27d0a-9aa0-42c7-9ea2-ab69bc1f5d87" │
│  4    │ "demo message" │ "2024-05-22T13:15:38.760000Z" │ "demo_user" │ "b7468cb1-e1e3-46fa-965d-83e604e80a31" │
└───────┴────────────────┴───────────────────────────────┴─────────────┴────────────────────────────────────────┘
```


## {{ ydb-short-name }} Topic Input Plugin

This plugin allows to read events from the {{ ydb-short-name }} [topic](../concepts/topic.md) and transform them to  the `Logstash` events.

### Configuration

The plugin configuration is making by adding `ydb_topic` block to the `input` section of Logstash pipeline [config](https://www.elastic.co/guide/en/logstash/current/configuration.html).The plugin supports standard set of [connection parameters](#configure-ydb-connection) and a few additional options:

* `topic_path` - required the full path of the topic for reading;
* `consumer_name` - required the name of the topic [consumer](../concepts/topic.md#consumer);
* `schema` - optional mode of the processing of the {{ ydb-short-name }} events. By default the plugin reads and sent the message as binary data, but if you specify `JSON` mode - every message will be parsed as JSON object.

### Example of usage

#### Creating a topic
Let's create a topic and a consumer in any existing {{ ydb-short-name }} database:

```bash
ydb -e grpc://localhost:2136 -d /local topic create /local/logstash_demo_topic
ydb -e grpc://localhost:2136 -d /local topic consumer add --consumer logstash-consumer /local/logstash_demo_topic
```

#### Setup plugin in Logstash pipeline config

For the plugin activation we can add `ydb_topic` block in `input` section of Logstash pipeline [config](https://www.elastic.co/guide/en/logstash/current/configuration.html). Additionally let's add `stdout` plugin in `output` section for logging all `Logstash` events:

```ruby
input {
  ydb_topic {
    connection_string => "grpc://localhost:2136/local" # Connection string to {{ ydb-short-name }}
    topic_path => "/local/logstash_demo_topic"         # The full path of the topic to read
    consumer_name => "logstash-consumer"               # The name of the consumer
    schema => "JSON"                                   # Use JSON mode
  }
}

output {
  stdout {
    codec => rubydebug
  }
}
```
For applying the changes we need to restart `Logstash`.

#### Write a test message to the topic
Then we can send a few test messages:
```bash
echo '{"message":"test"}' | ydb -e grpc://localhost:2136 -d /local topic write /local/logstash_demo_topic
echo '{"user":123}' | ydb -e grpc://localhost:2136 -d /local topic write /local/logstash_demo_topic
```

#### Check if the message was processed by Logstash

The plugin `stdout` allows to see the messages in `Logstash` logs:
```
{
       "message" => "test",
    "@timestamp" => 2024-05-23T10:31:47.712896899Z,
      "@version" => "1"
}
{
          "user" => 123.0,
    "@timestamp" => 2024-05-23T10:34:08.574599108Z,
      "@version" => "1"
}
```


## {{ ydb-short-name }} Topic Output Plugin

This plugin allows to write `Logstash` event to the {{ ydb-short-name }} [topic](../concepts/topic.md).

### Configuration

The plugin configuration is making by adding `ydb_topic` block to the `output` section of Logstash pipeline [config](https://www.elastic.co/guide/en/logstash/current/configuration.html).The plugin supports standard set of [connection parameters](#configure-ydb-connection) and a few additional options:

* `topic_path` - required the full path of the topic for writing.

### Example of usage

#### Creation a topic
Let's create a topic in any existing {{ ydb-short-name }} database:

```bash
ydb -e grpc://localhost:2136 -d /local topic create /local/logstash_demo_topic
```

#### Setup plugin in Logstash pipeline config

For the plugin activation we can add `ydb_topic` block in `output` section of Logstash pipeline [config](https://www.elastic.co/guide/en/logstash/current/configuration.html). Additionally let's add `http` block in `input` section for the creation of test messages by http requests:

```ruby
output {
  ydb_topic {
    connection_string => "grpc://localhost:2136/local" # Connection string to {{ ydb-short-name }}
    topic_path => "/local/logstash_demo_topic"         # The topic name for writing
  }
}

input {
  http {
    port => 9876 # You can specify any free port
  }
}
```
For applying the changes we need to restart `Logstash`.

#### Send a test message
Let's send a test message via `http` plugin:
```bash
curl -H "content-type: application/json" -XPUT 'http://127.0.0.1:9876/http/ping' -d '{ "user" : "demo_user", "message" : "demo message", "level": 4}'
```
We get `ok` if the message sending is successful.

#### Reading the message from the topic
We can check that the plugin wrote the message to the topic successful with reading this message by CLI:
```bash
ydb -e grpc://localhost:2136 -d /local topic consumer add --consumer logstash-consumer /local/logstash_demo_topic
ydb -e grpc://localhost:2136 -d /local topic read /local/logstash_demo_topic --consumer logstash-consumer --commit true
```
And there will be a content of the message:
```json
{"level":4,"message":"demo message","timestamp":1716470292640,"user":"demo_user"}
```
