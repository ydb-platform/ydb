# Оптимизация чтения потоковых данных несколькими запросами (Shared Reading)

## Описание проблемы (без использования оптимизации)

Клиент может запускать одновременно несколько [стриминговых запросов](./streaming), которые читают и обрабатывают данные из одного и того же  [топика](./concepts/topic). При этом запросы могут использовать разные схемы данных (разный набор колонок) и различные предикаты.

При этом часть обработки дублируется в процессе выполнения в каждом запросе:
- чтение данных из топика (сетевой трафик),
- декомпрессия данных (если используется),
- парсинг данных (в случае использования формата json),
- фильтрация данных по предикатам.

Для устранения лишней работы (уменьшения потребления CPU) предназначена оптимизация Shared Reading.

## Синтаксис

Для включения оптимизации необходимо при создании [внешнего источника данных](concepts/datamodel/external_data_source) указать 
флаг SHARED_READING=True. По умолчанию отключено (False).

```sql

CREATE EXTERNAL DATA SOURCE my_source WITH (
    SOURCE_TYPE = "YDB",
    ...
    SHARED_READING = TRUE
);

CREATE OR REPLACE STREAMING QUERY `my_queries/shared_reading` 
    WITH (
        STREAMING_DISPOSITION = FRESH
    ) AS
BEGIN
    INSERT INTO `my_source`.`output_topic_name` SELECT * FROM `my_source`.`input_topic_name`;
END;
```

## Архитектура

![Архитектура](_assets/shared_reading.png "Архитектура" =640x)

Оптимизация заключается в выполнении обработки, которая является одинаковой для всех запросов, единожды.

Для этого на кластере запускаются:
- читатели - отвечает за чтение/обработку одной партиции конкретного топика. 
- координатор - отвечает за распределение читателей по нодам кластера, следит за их доступностью. Координатором выбирается одна из нод (через сервис координации).

Читатели распределяются координатором равномерно по нодам. Для каждой партиции топика на кластере будет будет только один читатель на всем кластере. Читатель читает данные из топика, выполняет декомпрессию, парсит (в случае json формата), фильтрует данные для каждого запроса.

Каждый стриминговый запрос  узнает (на старте) где располагается необходимые ему читатели (через координатор), передает читателю свои параметры (список колонок, предикат и пр.). Запрос получает данные от читателя уже обработанные данные.

Необходимо отметить, что единственность читателя будет обеспечиваться только в рамках одной *Группы* (одного внешнего источника). Если создать несколько внешних источников на одну и ту же БД, то для каждого такого источника будут независимые читатели. Как пример можно создать два внешних источника (две группы) и использовать их в разных запросах, в этом случае данные из топика будут читаться/обрабатываться дважды (независимо двумя группами запросов).

## Ограничения
- все запросы будут читать данные с скоростью самого медленного (в одной группе),
- оптимизация фильтрации в случае одинаковых предикатов у разных запросов в текущей реализации не реализована,
- если запрос запускается после долгой остановки (при фейле запроса), сессия откатывается на старые оффсеты (может быть откат вплоть до ttl топика),
- нельзя остановить и продолжить запрос без влияния на другие,
- при чтении с ипользованием [consumer](/concepts/topic#consumer) все запросы (одной группы) должны указывать один и тот же consumer,
- у всех запросов в группе типы полей в схеме должны совпадать (количество полей может не совпадать). 

## Проблемы и пути их решения

- из-за медленного запроса (или постоянно падающего) происходит влияние (отставание чтения) на другие запросы в группе
  - необходимо остановить/пофиксить запрос или перенести запрос в другую группу (создать новый внешний источник).
 

## Как перезапускать запросы


## Настройки

| Параметр | Назначение | Значение по умолчаню |
|----------|------------|----------------------|
| `shared_reading.enabled` | Включение поддержки оптимизации | false |
| `shared_reading.timeout_before_start_session_sec` | Задержка между приходом запроса к читателю и установкой новой сессии к топику  | 0 |
| `shared_reading.send_status_period_sec` | Период отправки статистики от читателя (влияет на обновление смещений в чекпойнтах ) | 3 (???) |
| `shared_reading.without_consumer` | Не использовать consumer при установке сессии к топику | false | 
| `shared_reading.max_session_used_memory` | Макс. размер буфера в читателе | 16MB (???) |
| `shared_reading.json_parser.batch_size_bytes` |  | |
| `shared_reading.json_parser.batch_creation_timeout_ms` |  |  |
| `shared_reading.json_parser.buffer_cell_count` |  |  |
| `shared_reading.compile_service.parallel_compilation_limit` |  |  |
| `shared_reading.coordinator.local_mode` | Локальный режим (не используется сервис координации). При этом чтение из топика будет дублироваться на каждой ноде  | false |
| `shared_reading.coordinator.database.endpoint` | endpoint бд для сервиса координации |  |
| `shared_reading.coordinator.database.database` | имя бд для сервиса координации |  |


### Алгоритм работы TopicSession (чтение одной партиции)
- если сессия еще не запущена, то стартуем сессию с указанным оффсетом (первого клиента),
- если сессия уже запущена и оффсет менее текущего, то рестартим сессию (и читаем заново данные). 
   - при этом для запросов, которые уже прочитали/обработали данные, данные не будут повторно обрабатываться.    
- парсим/фильтруем.

## Особенности работы чекпойтов / смещений

Каждый запрос во время работы (как и без shared reading) записывает в чекпойнт текущие [смещения](concepts/topic#consumer-offset). Смещения для всех запросов будут примерно одинаковыми (в пределах задержки обработки / единицы секунд).

При одновмеренном старте нескольких запросов у разных запросов в чекпойнте могут быть разные смещения. При этом сессия к топику (конкретной партиции) будет установлена с данным указанием меньшего смещения (из всех запросов).

Если у одного запроса при старте будет очень старое смещение (например запрос был длительное время остановлен, а другие запросы работали нормально), то сессия будет переустановлена с смещением из стартованного запроса (мешьшего смещения). При этом некоторое время данные будут читаться/обрабатываться только одним запросом; остальные запросы будут ждать когда смещение дойдет до нужного им (это может занять минуты/часы, вплоть до ttl топика). 

## Примечание

Оптимизация работает только при чтении. Запись в топик без изменений. 


