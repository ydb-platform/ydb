# DataShard: локи и видимость изменений в транзакциях

Когда YQL транзакции пишут данные в таблицу, в дальнейшем может понадобиться прочитать эти данные до коммита. Для поддержки консистентной видимости данных с учётом сделанных изменений [DataShard](https://github.com/ydb-platform/ydb/tree/main/ydb/core/tx/datashard) поддерживает запись [незакомиченных изменений](localdb-uncommitted-txs.md) в рамках транзакции, включает эти данные в последующих чтениях в рамках той же транзакции, а также позволяет атомарно коммитить все накопленные изменения с учётом ограничений [изоляции serializable](../concepts/transactions.md#modes).

Нижестоящая поддержка в LocalDB также позволяет делать транзакции с очень большим количеством изменений, не ограниченных размером одного сообщения между акторами в распределённой системе.

## Высокоуровневая схема работы

Сложные YQL транзакции (либо интерактивные, т.е. такие где клиент начинает транзакцию и выполняет запросы без коммита, либо состоящие из нескольких подзапросов) разбирваются на несколько "фаз" в [KQP](https://github.com/ydb-platform/ydb/tree/main/ydb/core/kqp), используя результат одной фазы в качестве входя для следующей фазы. Например, если YQL запрос содержит `JOIN`, первая фаза может прочитать левую таблицу, а затем использовать этот результат для выполнения точечных чтений по правой таблице.

Для читающих запросов KQP использует глобальный [MVCC](https://ru.wikipedia.org/wiki/MVCC) снимок для обеспечения консистентности между подзапросами. Однако, в случае если транзакция пишет, нужно также убедиться, что [serializable](https://en.wikipedia.org/wiki/Serializability) изоляция не нарушается во время коммита. Сейчас это обеспечивается с помощью [Оптимистического управления параллелизмом](https://en.wikipedia.org/wiki/Optimistic_concurrency_control), где чтения добавляют оптимистические "лок" для прочитанных диапазонов, а запись в других транзакциях "ломает" эти локи во время их коммита. Транзакция может успешно закоммититься только если ни один из её локов не был сломан до момента коммита, в противном случае она завершится с ошибкой "transaction locks invalidated".

На оптимистические локи важно посмотреть и с другой стороны. Транзакция может сделать несколько чтения используя временные метки чтения (это может быть как один глобальный MVCC снимок, так и несколько временных меток, разные для каждого чтения), пока другие транзакции параллельно пишут в те же таблицы и шарды. Когда транзакция коммитится ей назначается единое время коммита в глобальном порядке выполнения. Если все чтения можно повторить в точке времени коммита, без изменения видимых результатов, такая транзакция могла бы целиком выполниться в точке с временем коммита. Оптимистический лок, пока он не сломан, как раз и показывает транзакции, что эти чтения можно переместить в более позднюю точку с временем коммита.

Незакомиченные изменения немногим отличаются от чтений с лочки зрения сериализации. Если DataShard может запомнить эти изменения и затем "переместить" их в финальную точки с временем коммита, такая транзакция может быть закоммичена, иначе она должна быть отменена. Основное отличие, что в отличие от локов чтения (которые хранятся в памяти), незакомиченные изменения персистентны, и их нужно правильно удалять когда в них больше нет необходимости.

## Как локи используются во время чтений

Операциям, которые подготавливаются на DataShard'ах, обычно назначают глобально уникальный 64-битный `TxId`, которые выделяются достаточно большими батчами с помощью глобальных таблеток TxAllocator. Когда KQP начинает первое чтение в многофазной транзакции, он также использует этот `TxId` в качестве идентификатора лока (исторически называется `LockTxId`), который в дальнейшем используется во всех запросах в той же YQL транзакции. DataShard добавляет новые локи, если в операции указан ненулевой `LockTxId`:

* См. [LockTxId](https://github.com/ydb-platform/ydb/blob/3444af692d32224288c41ba8c21e416d5fd4996c/ydb/core/protos/tx_datashard.proto#L1612) поле в читающих `TEvRead` запросах
* См. [LockTxId](https://github.com/ydb-platform/ydb/blob/3444af692d32224288c41ba8c21e416d5fd4996c/ydb/core/protos/tx_datashard.proto#L282) поле в сообщениях `TDataTransaction` (используется для кодирования транзакций с манипулированием данными)

Там же можно заметить поле `LockNodeId`, в котором указывается идентификатор ноды с источником лока. Это используется для подписки на статус лока, и их зачистки когда они перестают использоваться.

Важно помнить, что `LockTxId` это просто уникальное число, которое используется множеством операций в одной и той же YQL транзакции, в то время как `TxId` уникальный для каждой операции на одном DataShard'е. Использование первого `TxId` в качестве `LockTxId` не обязательно, но т.к. KQP уже получается глобально уникальное число с выделением `TxId`, и `LockTxId` не пересекается с `TxId`, это экономит аллокацию.

Таблица локов (см. [datashard_locks.h](https://github.com/ydb-platform/ydb/blob/main/ydb/core/tx/datashard/datashard_locks.h) и [datashard_locks.cpp](https://github.com/ydb-platform/ydb/blob/main/ydb/core/tx/datashard/datashard_locks.cpp)) индексирует их по диапазонам PK через дереве регионов, позволяя находить и "ломать" их по точечным ключам. В простейших случаях читающие операции добавляют диапазон с помощью метода [SetLock](https://github.com/ydb-platform/ydb/blob/207ac81618e05ade724a8a8193bc9125d466bd06/ydb/core/tx/datashard/datashard_locks.h#L831), а пишущие операции ломают другие локи по записанному ключу используя метод [BreakLocks](https://github.com/ydb-platform/ydb/blob/207ac81618e05ade724a8a8193bc9125d466bd06/ydb/core/tx/datashard/datashard_locks.h#L834).

Когда лок добавляется впервые, ему назначается `Counter` в текущем `Generation` таблетки (см. сообщение [TLock](https://github.com/ydb-platform/ydb/blob/207ac81618e05ade724a8a8193bc9125d466bd06/ydb/core/protos/data_events.proto#L8)), к тому же строка с этими числами появляется в виртуальной таблице `/sys/locks` (сама таблица больше не используется). Информация об этих локах возвращается в результирующих сообщениях (например см. [TEvReadResult](https://github.com/ydb-platform/ydb/blob/b07264456a2e8b5929901f258ad60399bb64678a/ydb/core/protos/tx_datashard.proto#L1702)). Пока лок существует и не сломан, поля `Generation` и `Counter` не меняются, в противном случае как-минимум `Counter` гарантированно меняется (либо явно сигнализируя об ошибке, либо потому что лок с таким `LockTxId` был потерян и позже пересоздан). Первые `Generation` и `Counter` для каждого шарда запоминаются в KQP, и в случае их изменения во время жизни транзакции сигнализируют о неконсистентности и нарушении serializable изоляции. Пишущие транзакции, либо транзакции которые не используют глобальный MVCC снимок для эффективности, выполняют финальный коммит проверяющий значения `Generation` и `Counter` локов, и который может завершиться успехом только если все числа совпадают.

При использовании глобального MVCC снимка все чтения с этим снимком гарантированно консистентны, но тем не менее происходят со взятием локов на случай, если транзакция в дальнейшем окажется пишущей. DataShard при этом делает дополнительные проверки, проверяя есть ли новые закомиченные данные поверх читаемого снимка. При обнаружении конфликта, чтение не завершается с ошибкой, однако поле `Counter` лока выставляется равным [ErrorAlreadyBroken](https://github.com/ydb-platform/ydb/blob/b07264456a2e8b5929901f258ad60399bb64678a/ydb/core/tx/datashard/sys_tables.h#L107), сигнализируя о том, что несмотря на консистентность чтения лок взять не удалось, и записать что-то в этой транзакции не получится. Транзакции после этого могут перестать брать новые локи, и даже завершиться успехом, если окажется, что вся транзакция целиком выполняла только чтения. Однако, если такая транзакция попытается что-то записать, то она завершится с ошибкой не дожидаясь коммита (который гарантированно завершился бы с ошибкой).

## Как локи используются для записи изменений

Когда KQP необходимо сделать незакомиченные изменения в рамках YQL транзакции, в операции записи на DataShard'е также указывается ненулевой `LockTxId`. Кроме установки лока DataShard воспользуется этим `LockTxId` в качестве `TxId` для записи незакомиченных изменений, и эти изменения будут храниться пока лок остаётся валидным. В коде локи с незакомиченными изменениями называются пишущими локами (write locks), а информация по ним сохраняется в специальных таблицах (см. таблицу [Locks](https://github.com/ydb-platform/ydb/blob/5aecdb67595db1a47c933b7d8da2cb662a50e185/ydb/core/tx/datashard/datashard_impl.h#L879) и связанные таблицы ниже), что позволяет им переживать рестарты DataShard'а.

При использовании операций записи незакомиченных изменений есть несколько ограничений:

* `LockedWrites` должны быть включены (в настоящее время включено по умолчению)
* Операция должны выполняться в режиме immediate (т.е. нельзя записать незакомиченные изменения распределённой транзакцией)
* В операции должен быть указан `LockNodeId` с нодой, через которую DataShard подписывается на статус лока и автоматически удаляет изменения если лок пропадает (например, если транзакция отменяется нештатно, или нода с состоянием транзакции не отвечает)
* У операции должен быть указан правильный MVCC сником, который используется для чтений и поиска конфликтов. Ожидается, что один и тот же MVCC снимок будет использоваться во всех чтениях и записях в этой YQL транзакции.
* Существующий лок должен быть валидным и не сломанным, в противном случае для указанного `LockTxId` не должно быть нескомпакченных данных в LocalDB. Это защищает от нештатных ситуаций, когда транзакция отменяется на шарде (например на основе статуса лока), а KQP пытается продолжить в ней писать.

При чтениях YQL транзакция должна указывать тот же `LockTxId`, при этом чтения через LocalDB будут использовать особую карту транзакций, в которой `LockTxId` как бы уже закоммичен, позволяя транзакции видеть собственные изменения, но не изменения других незакомиченных транзакций. Так как чтения производятся через MVCC снимок, в карте транзакций добавляется особая запись `[LockTxId] => v{min}`, позволяя видеть собственные изменения независимо от значения конкретного снепшота.

Незакомиченные записи требуют дополнительного анализа конфликтов (см. [CheckWriteConflicts](https://github.com/ydb-platform/ydb/blob/efe5b5f8d2da503eda4d172f6f2e85aac64ba6a6/ydb/core/tx/datashard/datashard__engine_host.cpp#L802) в реализации minikql engine host). Когда несколько незакомиченных транзакций пытаются писать в один и тот же ключ, DataShard должен убедиться, что в случае коммита соответствующие им конфликтующие локи будут сломаны. Объекты для отслеживания транзакций (например [TLockedWriteTxObserver](https://github.com/ydb-platform/ydb/blob/efe5b5f8d2da503eda4d172f6f2e85aac64ba6a6/ydb/core/tx/datashard/datashard__engine_host.cpp#L872)) используются для обнаружения таких конфликтов, у которых LocalDB вызывает соответствующие методы перед пропуском или применением изменений, при этом перед записью DataShard выполняет чтение в специальном режиме для поиска всех незакомиченных изменений по ключу. В случае обнаружения конфликта они добавляются в граф конфликтов между локами, таким образом каждый лок знает какие локи должны быть сломаны в случае коммита.

Если на шарде есть незакомиченные изменения, то чтения также должны дополнительно проверять конфликты, так как чтения в транзакциях должны быть не только консистентными в рамках транзакций, но и учитывать согласованность состояния с будущей точкой времени коммита. Здесь также используются объекты для отслеживания, чтобы собирать списки незакомиченных транзакций пропущенных во время чтения, добавляя связи в графе между пишущими и читающими локами.

Особенно сложная ситуация возникает, когда транзакция делает чтение с учётом собственных незакомиченных изменений, которые были поверх ранее закомиченных изменений, но сделанных уже после получения MVCC снимка в транзакции. Пример подобной ситуации:

1. Ключ K изначально имеет `A = 1` в версии `v4000/100` (два числа здесь - это `Step` (4000) и `TxId` (100) времени коммита)
2. Tx1 открывается и получает MVCC снимок `v5000/max`
3. Tx2 коммитит слепую запись `UPSERT` с `B = 2` в версии `v6000/102`
4. Tx1 делает слепую запись `UPSERT` с `C = 3` и `TxId` 101
5. В этот момент Tx1 ещё могла бы закоммититься успешно, потому что она не читала ключ K и изменения с `C = 3` всё ещё может переместиться в будущее время коммита
6. Tx1 выполняет чтение по ключу K, которое выполняется с использованием снимка `v5000/max`:
    * На время чтения будет использоваться временная запись `[101] => v{min}` в карте транзакций
    * Итерация спозиционируется на первой дельте с изменением `C = 3` (т.к. `v{min} <= v5000/max`), которое будет добавлено в состояние строки
    * Все прочие закомиченные дельты будут также добавлены, т.е. состояние строки будет включать `B = 2` которое в этот момент уже закоммичено
    * Однако, здесь возникает конфликт, т.к. `B = 2` было закоммичено уже после MVCC снимка (`v6000/102 > v5000/max`)
    * Это обнаружится в методе [OnApplyCommitted](https://github.com/ydb-platform/ydb/blob/efe5b5f8d2da503eda4d172f6f2e85aac64ba6a6/ydb/core/tx/datashard/datashard__engine_host.cpp#L698), который вызывает [CheckReadConflict](https://github.com/ydb-platform/ydb/blob/efe5b5f8d2da503eda4d172f6f2e85aac64ba6a6/ydb/core/tx/datashard/datashard__engine_host.cpp#L751)
    * Так как подобное состояние строки не соответствует изоляции, лок транзакции будет автоматически сломан, и взведён флаг неконсистентности чтения
7. Данное чтение не только завершится с ошибкой, но также Tx1 не сможет быть закоммичена, т.к. произошло нарушение изоляции
8. Приложение получит ошибку "transaction locks invalidated", и повторит транзакцию сначала

## Взаимодействие с накоплением изменений

У DataShard'ов есть так называемые накопители изменений (change collectors), которые логируют происходящие изменения и поково отправляют в другие подсистемы. Это в частности используется для поддержки [Change Data Capture](https://en.wikipedia.org/wiki/Change_data_capture) и [Асинхронных вторичных индексов](../concepts/secondary_indexes.md#async). В зависимости от режима, накопителям изменений может потребоваться знать предыдущее состояние строки, и для этого они выполняют чтение строки перед её записью.

В случае записи незакомиченных изменений, накопителям изменений также нужно их обрабатывать, однако эти записи нельзя отправлять в другие системы до коммита, а кроме того отправленные изменения должны совпадать с финальным порядком этих изменений. Для поддержки этого изменения сначала аккумулируются в отдельной таблице [LockChangeRecords](https://github.com/ydb-platform/ydb/blob/c5284478af104d82c4d84a5d99bf0a51ecd2ca63/ydb/core/tx/datashard/datashard_impl.h#L911), а с случае успешного коммита транзакций они атомарно добавляются в выходной поток с помощью добавления одной строки в таблице [ChangeRecordCommits](https://github.com/ydb-platform/ydb/blob/c5284478af104d82c4d84a5d99bf0a51ecd2ca63/ydb/core/tx/datashard/datashard_impl.h#L947). Таким образом обработка изменений происходит постепенно, и сопоставима с размером каждой отдельной операции записи, избавляя от дорогостоящей массовой обработки во время коммита.

## Взаимодействие с распределёнными транзакциями

Когда распределённая транзакция начинает выполнения, она валидирует участвующие на текущем шарде локи, и рассылает результат на других участников. Если все результаты получены и оказались успешными, то тело транзакции может продолжить выполнения и применить эффекты. Другими словами, если все чтения со всех участвующих шардов удалётся переместить на время коммита без нарушения изоляции, то транзакция может применить все накопленные изменения, иначе она будет вынужена отмениться. Результаты валидации запоминаются персистентно, а корректность выполнения обеспечивается с помощью анализа конфликта между транзакциями. Незакомиченные изменения добавляют сложность, т.к. в отличие от обычных транзакций, коммит лока с незакомиченными изменениями может затрагивать произвольные ключи, которые не хранятся в памяти DataShard'а, соответственно проанализировать конфликты по пересечению ключей нельзя. Если ничего не предпринимать, DataShard мог бы провалидировать пишущий лок, отправить успешный результат проверки на других участников, в то время как другая транзакция сломает этот лок с отменой изменений. Конфликтов обычно немного, и полностью останавливать пайплайн при появлении незакомиченных изменений было бы слишком дорого.

Вместо этого, после валидации пишущего лока, он "замораживается" и больше не может сломаться. Если конфликтующая транзакции попытается сломать замороженный лок, она вместо этого ставится на паузу, и дожидается пока транзакций с замороженным локом завершится. DataShard следит коммит каких локов может сломать другие локи, и для защиты от дедлоков проверяет может ли коммит транзакции А изменить результат валидации транзакции Б и наоборот. Если транзакция А должна выполниться до транзакции Б в глобальном порядке транзакций, DataShard не будет начинать валидацию транзакции Б пока транзакция А не завершится. Пока транзакции не конфликтуют они могут выполняться в любом порядке.

## Коммит изменений

Для коммита ранее записанных изменений, KQP запускает на шардах транзакцию, которая коммитит ранее захваченные локи. У такой транзакции не указывается `LockTxId` (коммит не захватывает новые локи), должна включать все ранее установленные локи в поле [Locks](https://github.com/ydb-platform/ydb/blob/b07264456a2e8b5929901f258ad60399bb64678a/ydb/core/protos/tx_datashard.proto#L219) транзакции, и с полем `Op` установленным в [Commit](https://github.com/ydb-platform/ydb/blob/d31477e5ed13679dd3b409b100623cc81a5e0964/ydb/core/protos/data_events.proto#L26). Сама транзакция коммита на шардах может быть либо immediate (например, если YQL транзакция затрагивала только один шард, независимо от кол-ва фаз), либо подготовлена как распределённая транзакция на нескольких участниках.

Для поддержки распределённых транзакций все шарды, которые проверяют локи, включаются в списке [SendingShards](https://github.com/ydb-platform/ydb/blob/d31477e5ed13679dd3b409b100623cc81a5e0964/ydb/core/protos/data_events.proto#L20), а все шарды применяющие эффекты включаются в списке [ReceivingShards](https://github.com/ydb-platform/ydb/blob/d31477e5ed13679dd3b409b100623cc81a5e0964/ydb/core/protos/data_events.proto#L21). Во время валидации отправляющие шарды подготавливают персистентные readset'ы и отправляют их на все принимающие шарды. Принимающие же шарды после валидации ждут получения readset'ов перед тем как начинать выполнение транзакции. Во время выполнения, в случае если все результаты валидации были успешными, локи коммитятся через вызов [KqpCommitLocks](https://github.com/ydb-platform/ydb/blob/d31477e5ed13679dd3b409b100623cc81a5e0964/ydb/core/tx/datashard/execute_kqp_data_tx_unit.cpp#L228). В противном случае, тело транзакции не выполняется, а лок удаляется вместе с отменой всех незакомиченных изменений через вызов [KqpEraseLocks](https://github.com/ydb-platform/ydb/blob/d31477e5ed13679dd3b409b100623cc81a5e0964/ydb/core/tx/datashard/execute_kqp_data_tx_unit.cpp#L190). Так как в случае ошибки коммита изменения отменяются, отдельно коммит ретраить нельзя.

Важно, что все незакомиченные изменения с одинаковым `LockTxId` должны быть включены в транзакцию коммита, и транзакцию нельзя коммитить частично. Например, если транзакция сделала несколько записей, и одна и на одной из записей произошла ошибка (например в случае кратковременной недоступности шарда, когда нельзя однозначно понять была ли запись произведена), то будет некорректно пропустить эту запись и закоммитить транзакцию частично. Если в будущем произойдёт мерж шардов, то несовпадение статуса транзакции может приводить к аномалиям.

В транзакции коммита также могут быть дополнительные сайд-эффекты, которые атомарно применяются сразу после коммита лока. Для уменьшения латентности KQP старается аккумулировать сайд-эффекты в памяти либо до момента их коммита, либо до необходимости чтения этих изменений в той же транзакции, и отправляет накопленные изменения вместе с транзацией коммита. В случае, если удаётся накопить все изменения до момента коммита, незакомиченных изменений не происходит, а локи при необходимости берутся только на чтение.

Для явной отмены изменений YQL транзакция запускает пустую транзакцию на шардах с указаем [Rollback](https://github.com/ydb-platform/ydb/blob/d31477e5ed13679dd3b409b100623cc81a5e0964/ydb/core/protos/data_events.proto#L27) в качестве операции лока. Если по какой-то причине этого не происходит, при разрушении [TLockHandle](https://github.com/ydb-platform/ydb/blob/0db14d1168517ecacab106e7abfe7af663020829/ydb/core/tx/long_tx_service/public/lock_handle.h#L15) все подписанные даташарды автоматически чистят локи через внутреннюю транзакцию [TxRemoveLock](https://github.com/ydb-platform/ydb/blob/0db14d1168517ecacab106e7abfe7af663020829/ydb/core/tx/datashard/remove_locks.cpp#L24). Явная отмена впрочем предпочтительна, т.к. незакомиченные изменения потребляют ресурсы и в случае асинхронной очистки через `TLockHandle` нет гарантии, что эти ресурсы освободятся до того как новые транзакции попытаются записать ещё больше изменений.

## Ограничения

В текущей реализации наличие незакомиченных изменений приводят к тому, что всем новым попыткам записи на тот же шард приходится дополнительно проверять конфликты, из-за чего запись перестаёт быть слепой. Чтение перед каждой записью делает их дороже, увеличивает латентность и уменьшает пропускную способность.

Из-за ограничений LocalDB даташарды также вынуждены гарантировать, что не будет образовываться слишком много открытых транзакций. Сейчас таблица локов ограничена примерно 10 тысячами записей, что включает в себя пишущие локи. Даташарды также вынуждены подсчитывать кол-во уже имеющихся незакомиченных изменений перед каждой новой записью, что реализовано через подсчёт пропуском в объекте для отслеживания транзакций. В случае превышения лимита кидается исключение [TLockedWriteLimitException](https://github.com/ydb-platform/ydb/blob/d31477e5ed13679dd3b409b100623cc81a5e0964/ydb/core/tx/datashard/datashard__engine_host.cpp#L867).

Персистентные локи переживают рестарты даташардов и восстанавливают своё последнее состояние. Однако, хотя поддерживается возможность сохранения диапазонов, на практике это не используются (в противном случае даташард был бы вынужден записывать новые диапазоны во время каждого чтения, что слишком дорого). Вместо этого читающие локи (которые стали персистентными из-за наличия записи) восставливаются с диапазоном "весь шард", что лучше чем инвалидация на любом рестарте, но конфликтует с любой записью и увеличивает риск TLI.
