# Расширение кластера

Вы можете расширить кластер {{ ydb-short-name }}, добавив новые узлы в конфигурацию кластера. Ниже приведены необходимые действия по расширению кластера {{ ydb-short-name }}, установленного вручную на виртуальные машины или физические серверы. Расширение кластера в среде Kubernetes осуществляется путём корректировки настроек контроллера {{ ydb-short-name }} для Kubernetes.

Расширение кластера {{ ydb-short-name }} не требует приостановки доступа пользователей к базам данных. При расширении кластера выполняется перезапуск его компонентов для применения изменений в конфигурации, что, в свою очередь, может привести к необходимости повтора выполняемых на кластере транзакций. Повторы транзакций выполняются автоматически за счёт использования приложениями возможностей SDK {{ ydb-short-name }} по контролю ошибок и повтору операций.

## Подготовка новых серверов {#add-host}

В случае размещения новых статических или динамических узлов кластера на новых серверах, не входивших ранее в состав расширяемого кластера {{ ydb-short-name }}, на каждом новом сервере необходимо выполнить установку программного обеспечения {{ ydb-short-name }} в соответствии с процедурами, описанными в [инструкции по развёртыванию кластеров](../../deployment-options/manual/initial-deployment.md). В частности, необходимо:

1. создать учётную запись и группу в операционной системе для работы сервиса {{ ydb-short-name }};
2. установить программное обеспечение {{ ydb-short-name }};
3. подготовить и разместить на сервере соответствующий ему ключ и сертификат TLS;
4. скопировать на сервер актуальный конфигурационный файл кластера {{ ydb-short-name }}.

Используемые на новых серверах сертификаты TLS должны соответствовать [требованиям к заполнению полей](../../deployment-options/manual/initial-deployment.md#tls-certificates) и быть подписаны доверенным центром регистрации, используемым на уже существующих серверах расширяемого кластера {{ ydb-short-name }}.

## Добавление динамических узлов {#add-dynamic-node}

Добавление динамических узлов позволяет увеличить доступные вычислительные ресурсы (процессорные ядра и оперативную память) для выполнения пользовательских запросов кластером {{ ydb-short-name }}.

Для добавления динамического узла в кластер достаточно запустить процесс, обслуживающий этот узел, передав ему в параметрах командной строки путь к конфигурационному файлу кластера, имя обслуживаемой базы данных и адреса любых трёх статических узлов кластера {{ ydb-short-name }}, как показано в [инструкции по развёртыванию кластеров](../../deployment-options/manual/initial-deployment.md#start-dynnode).

После успешного добавления динамического узла в кластер информация о нём будет доступна на [странице мониторинга кластера во встроенном UI](../../../reference/embedded-ui/ydb-monitoring.md).

Для вывода динамического узла из кластера достаточно выполнить остановку процесса динамического узла.

## Добавление статических узлов {#add-static-node}

Добавление статических узлов позволяет увеличить пропускную способность при выполнении операций ввода-вывода и увеличить доступную ёмкость для хранения данных в кластере {{ ydb-short-name }}.

Для добавления статических узлов в кластер необходимо выполнить следующую последовательность действий:

1. Очистить диски, которые будут использоваться для хранения данных {{ ydb-short-name }}, с использованием [процедуры, описанной для этапа развёртывания кластера](../../deployment-options/manual/initial-deployment.md#prepare-disks).

1. Получить токен аутентификации для выполнения административных команд с помощью {{ ydb-short-name }} CLI, например:

    ```bash
    ydb -e grpcs://<node1.ydb.tech>:2135 -d /Root --ca-file ca.crt \
        --user root auth get-token --force > token-file
    ```

    В примере команды выше используются следующие параметры:
    * `node1.ydb.tech` — FQDN любого из серверов, на которых уже размещены статические узлы кластера;
    * `2135` — номер порта gRPCs сервиса статических узлов;
    * `ca.crt` — имя файла с сертификатом центра регистрации;
    * `root` — логин пользователя с административными правами;
    * `token-file` — имя файла, в который сохраняется токен аутентификации для последующего использования.

    При выполнении приведённой выше команды {{ ydb-short-name }} CLI запросит пароль для аутентификации указанного пользователя.

1. Получить текущую конфигурацию кластера, выполнив команду следующего вида на любом из узлов кластера:

    ```bash
    ydb --token-file token-file --ca-file ca.crt -e grpcs://<node1.ydb.tech>:2135 \
        admin storage fetch > config.yaml
    ```

1. Скорректировать [конфигурационный файл кластера](../../deployment-options/manual/initial-deployment.md#config), включив в конфигурацию описание добавляемых узлов (в секции `hosts`) и используемых на них дисков (в секции `host_configs`);

2. Разрешить кластеру {{ ydb-short-name }} использовать диски на новых статических узлах для хранения данных, выполнив следующую команду на любом из узлов кластера:

    ```bash
    export LD_LIBRARY_PATH=/opt/ydb/lib
    ydb --token-file ydbd-token-file --ca-file ca.crt -e grpcs://<node1.ydb.tech>:2135 \
        admin cluster config replace -f config.yaml
    echo $?
    ```

     В примере команды выше используются следующие параметры:

    * `ydbd-token-file` — имя файла ранее полученного токена аутентификации;
    * `2135` — номер порта gRPCs сервиса статических узлов;
    * `ca.crt` — имя файла с сертификатом центра регистрации.

    Если при выполнении приведённой выше команды возвращается ошибка сверки версии конфигурации, это означает, что версия текущего конфига устарела, и необходимо получить новый из кластера, повторив шаг 3. Пример сообщения об ошибке сверки версии конфигурации:

    ```proto
    ErrorDescription: "ConfigVersion mismatch ConfigVersionProvided# 0 ConfigVersionExpected# 1"
    ```

3. Создать на каждой новой машине пустую директорию `/opt/ydb/cfg` для работы кластера с конфигурацией. Если на одной машине запускается несколько узлов, использовать одну и ту же директорию. Выполнив специальную команду на каждой новой машине, инициализировать эту директорию с использованием произвольного статического узла кластера в качестве источника конфигурации.

    ```bash
    sudo mkdir -p /opt/ydb/cfg
    sudo chown -R ydb:ydb /opt/ydb/cfg
    ydb admin node config init --config-dir /opt/ydb/cfg --seed-node <node.ydb.tech:2135>
    ```

4. Запустить процессы, обслуживающие новые статические узлы кластера, на соответствующих серверах.

5. Убедиться в том, что новые статические узлы отображаются на [странице мониторинга кластера во встроенном UI](../../../reference/embedded-ui/ydb-monitoring.md).

6. Добавить дополнительные группы хранения в одну или несколько баз данных, выполнив команды следующего вида на любом из узлов кластера:

    ```bash
    export LD_LIBRARY_PATH=/opt/ydb/lib
    /opt/ydb/bin/ydbd -f ydbd-token-file --ca-file ca.crt -s grpcs://`hostname -f`:2135 \
        admin database /Root/testdb pools add ssd:1
    echo $?
    ```

    В примере команды выше используются следующие параметры:

    * `ydbd-token-file` - имя файла ранее полученного токена аутентификации;
    * `2135` - номер порта grpcs сервиса статических узлов;
    * `ca.crt` - имя файла с сертификатом центра регистрации;
    * `/Root/testdb` - полный путь к базе данных;
    * `ssd:1` - имя пула хранения и количество выделяемых групп хранения.

7. Убедиться, что добавленные группы хранения отображаются на [странице мониторинга кластера во встроенном UI](../../../reference/embedded-ui/ydb-monitoring.md).

Вывод статических узлов из кластера {{ ydb-short-name }} производится в соответствии с [документированной процедурой декомиссии](../../deployment-options/manual/decommissioning.md).

В случае повреждения и невозможности ремонта сервера, на котором работает статический узел кластера, необходимо разместить недоступный статический узел на новом сервере, содержащем аналогичное или большее количество и объем дисков.
