# Параметры конфигурации кластера

В данной статье приведено описание основных групп конфигурируемых параметров в файле конфигурации кластера.

## host_configs — типовые конфигурации хостов {#host-configs}

Кластер {{ ydb-short-name }} состоит из множества узлов, для развертывания которых обычно используется одна или несколько типовых конфигураций серверов. Для того чтобы не повторять её описание для каждого узла, в файле конфигурации существует раздел `host_configs`, в котором перечислены используемые конфигурации, и им присвоены идентификаторы.

### Синтаксис

```yaml
host_configs:
- host_config_id: 1
  drive:
  - path: <path_to_device>
    type: <type>
  - path: ...
- host_config_id: 2
  ...
```

Атрибут `host_config_id` задает числовой идентификатор конфигурации. В атрибуте `drive` содержится коллекция описаний подключенных дисков. Каждое описание состоит из двух атрибутов:

- `path` : Путь к смонтированному блочному устройству, например `/dev/disk/by-partlabel/ydb_disk_ssd_01`
- `type` : Тип физического носителя устройства: `ssd`, `nvme` или `rot` (rotational - HDD)

### Примеры

Одна конфигурация с идентификатором 1, с одним диском типа SSD, доступным по пути `/dev/disk/by-partlabel/ydb_disk_ssd_01`:

``` yaml
host_configs:
- host_config_id: 1
  drive:
  - path: /dev/disk/by-partlabel/ydb_disk_ssd_01
    type: SSD
```

Две конфигурации с идентификаторами 1 (два SSD диска) и 2 (три SSD диска):

``` yaml
host_configs:
- host_config_id: 1
  drive:
  - path: /dev/disk/by-partlabel/ydb_disk_ssd_01
    type: SSD
  - path: /dev/disk/by-partlabel/ydb_disk_ssd_02
    type: SSD
- host_config_id: 2
  drive:
  - path: /dev/disk/by-partlabel/ydb_disk_ssd_01
    type: SSD
  - path: /dev/disk/by-partlabel/ydb_disk_ssd_02
    type: SSD
  - path: /dev/disk/by-partlabel/ydb_disk_ssd_03
    type: SSD
```

### Особенности Kubernetes {#host-configs-k8s}

{{ ydb-short-name }} Kubernetes operator монтирует NBS диски для Storage узлов на путь `/dev/kikimr_ssd_00`. Для их использования должна быть указана следующая конфигурация `host_configs`:

``` yaml
host_configs:
- host_config_id: 1
  drive:
  - path: /dev/kikimr_ssd_00
    type: SSD
```

Файлы с примерами конфигурации, поставляемые в составе {{ ydb-short-name }} Kubernetes operator, уже содержат такую секцию, и её не нужно менять.

## hosts — статические узлы кластера {#hosts}

В данной группе перечисляются статические узлы кластера, на которых запускаются процессы работы со Storage, и задаются их основные характеристики:

- Числовой идентификатор узла
- DNS-имя хоста и порт, по которым может быть установлено соединение с узлом в IP network
- Идентификатор [типовой конфигурации хоста](#host-configs)
- Размещение в определенной зоне доступности, стойке
- Инвентарный номер сервера (опционально)

### Синтаксис

``` yaml
hosts:
- host: <DNS-имя хоста>
  host_config_id: <числовой идентификатор типовой конфигурации хоста>
  port: <порт> # 19001 по умолчанию
  location:
    unit: <строка с инвентарным номером сервера>
    data_center: <строка с идентификатором зоны доступности>
    rack: <строка с идентификатором стойки>
- host: <DNS-имя хоста>
  # ...
```

### Примеры

``` yaml
hosts:
- host: hostname1
  host_config_id: 1
  node_id: 1
  port: 19001
  location:
    unit: '1'
    data_center: '1'
    rack: '1'
- host: hostname2
  host_config_id: 1
  node_id: 2
  port: 19001
  location:
    unit: '1'
    data_center: '1'
    rack: '1'
```

### Особенности Kubernetes {#hosts-k8s}

При развертывании {{ ydb-short-name }} с помощью оператора Kubernetes секция `hosts` полностью генерируется автоматически, заменяя любой указанный пользователем контент в передаваемой оператору конфигурации. Все Storage узлы используют `host_config_id` = `1`, для которого должна быть задана [корректная конфигурация](#host-configs-k8s).

## Топология кластера {#topology}

Для конфигурации топологии кластера {{ ydb-short-name }} доступны следующие [режимы отказоустойчивости](../../concepts/topology.md):

| Режим | Описание |
| --- | --- |
| `none` | Избыточность отсутствует. Применяется для тестирования. |
| `block-4-2` | Избыточность с коэффициентом 1,5, применяется для однодатацентровых кластеров. |
| `mirror-3-dc` | Избыточность с коэффициентом 3, применяется для мультидатацентровых кластеров. |

Топология кластера задается в качестве параметра `erasure` и принимает одно из значений, указанных в таблице выше.

## Конфигурация безопасности {#security}

В разделе `security_config` задаются режимы [аутентификации](../../security/authentication.md), первичная конфигурация локальных [пользователей](../../concepts/glossary.md#access-user) и [групп](../../concepts/glossary.md#access-group) и их [права](../../concepts/glossary.md#access-right).

```yaml
security_config:
  # настройка режима аутентификации
  enforce_user_token_requirement: false
  enforce_user_token_check_requirement: false
  default_user_sids: <аутентификационный токен для анонимных запросов>
  all_authenticated_users: <имя группы всех аутентифицированных пользователей>
  all_users_group: <имя группы всех пользователей>

  # первичные настройки безопасности
  default_users: <список пользователей по умолчанию>
  default_groups: <список групп по умолчанию>
  default_access: <список прав по умолчанию на корне кластера>

  # настройки привилегий
  viewer_allowed_sids: <список SID'ов с правами просмотра состояния кластера>
  monitoring_allowed_sids: <список SID'ов с правами просмотра и изменения состояния кластера>
  administration_allowed_sids: <список SID'ов с доступом администратора кластера>
  register_dynamic_node_allowed_sids: <список SID'ов с правами регистрации узлов баз данных в кластере>
```

Каждый клиент State Storage (например, таблетка DataShard) использует `nto_select` узлов для записи копий его данных в State Storage. Если State Storage состоит из большего количества узлов чем `nto_select`, то разные узлы могут быть использованы для разных клиентов, поэтому необходимо обеспечить, чтобы любое подмножество из `nto_select` узлов в пределах State Storage отвечало критериям отказоустойчивости.

Для `nto_select` должны использоваться нечетные числа, так как использование четных чисел не улучшает отказоустойчивость по сравнению с ближайшим меньшим нечетным числом.

### Конфигурация безопасности {#security}

В разделе `domains_config.security_config` задаются режимы [аутентификации](../../security/authentication.md), первичная конфигурация локальных [пользователей](../../concepts/glossary.md#access-user) и [групп](../../concepts/glossary.md#access-group) и их [права](../../concepts/glossary.md#access-right).

```yaml
domains_config:
  ...
  security_config:
    # настройка режима аутентификации
    enforce_user_token_requirement: false
    enforce_user_token_check_requirement: false
    default_user_sids: <аутентификационный токен для анонимных запросов>
    all_authenticated_users: <имя группы всех аутентифицированных пользователей>
    all_users_group: <имя группы всех пользователей>

    # первичные настройки безопасности
    default_users: <список пользователей по умолчанию>
    default_groups: <список групп по умолчанию>
    default_access: <список прав по умолчанию на корне кластера>

    # настройки привилегий
    viewer_allowed_sids: <список SID'ов с правами просмотра состояния кластера>
    monitoring_allowed_sids: <список SID'ов с правами просмотра и изменения состояния кластера>
    administration_allowed_sids: <список SID'ов с доступом администратора кластера>
```

[//]: # (TODO: wait for pull/9387, dynamic_node_registration to add info about "register_dynamic_node_allowed_sids: <список SID'ов с правами подключения динамических нод в кластер>")

#### Настройки режима аутентификации {#security-auth}

#|
|| Параметр | Описание ||
|| `enforce_user_token_requirement` | Режим обязательной [аутентификации](../../security/authentication.md).

- `enforce_user_token_requirement: true` — аутентификация обязательна, запросы к {{ ydb-short-name }} обязаны сопровождаться [аутентификационным токеном](../../concepts/glossary.md#auth-token).

    Запросы проходят аутентификацию и проверку прав.

- `enforce_user_token_requirement: false` — аутентификация опциональна, запросы к {{ ydb-short-name }} могут не сопровождаться [аутентификационным токеном](../../concepts/glossary.md#auth-token).

    Запросы без токена выполняются в [анонимном режиме](../../security/authentication.md#anonymous) и без проверки прав.

    Запросы с токеном проходят аутентификацию и проверку прав. Но в случае ошибок аутентификации, запросы не запрещаются, а выполняются в анонимном режиме.

    При `enforce_user_token_check_requirement: true` выполнение запросов с ошибкой аутентификации запрещается.

[//]: # (TODO: добавить про ошибки проверки права на доступ к базе данных, когда появится место для ссылки)

Взамен отсутствующего в запросах токена используется значение параметра `default_user_sids`, если параметр определён и не пустой (см. описание ниже). Тогда аутентификация и проверка прав проводится для [субъекта доступа](../../concepts/glossary.md#access-subject), заданного `default_user_sids`.

Значение по умолчанию: `false`.
    ||
|| `enforce_user_token_check_requirement` | Запрещает игнорировать ошибки аутентификации в режиме `enforce_user_token_requirement: false`.

Значение по умолчанию: `false`.
    ||
|| `default_user_sids` | Список [SID](../../concepts/glossary.md#access-sid)'ов для использования в проверке аутентификации в случае, когда входящий запрос не сопровождается явным [аутентификационным токеном](../../concepts/glossary.md#auth-token).

`default_user_sids` играет роль аутентификационного токена для анонимных запросов. Первым элементом в списке должен быть SID пользователя, за ним должны идти SID'ы групп, к которым пользователь принадлежит.

Непустой `default_user_sids` позволяет использовать режим обязательной аутентификации (`enforce_user_token_requirement: true`) вместе с анонимными запросами. Это может быть полезно в определённых сценариях тестирования {{ ydb-short-name }} или в ознакомительных целях для локальных баз данных.

Значение по умолчанию: пустой список.
    ||
|| `all_authenticated_users` | Имя виртуальной [группы](../../concepts/glossary.md#access-group), в которой состоят все аутентифицированные [пользователи](../../concepts/glossary.md#access-user).

Виртуальную группу не нужно явно создавать, она ведётся системой автоматически. Виртуальную группу нельзя удалить, нельзя получить или изменить список её членов.
Пользователь может использовать её для выдачи [прав](../../concepts/glossary.md#access-right) на [схемных объектах](../../concepts/glossary.md#scheme-object).

Значение по умолчанию: `all-users@well-known`.
    ||
|| `all_users_group` | Имя [группы](../../concepts/glossary.md#access-group), в которую должны добавляться все локальные [пользователи](../../concepts/glossary.md#access-user).

Если `all_users_group` не пустая, то все локальные пользователи в момент создания будут добавляться в группу с указанным именем. В момент создания пользователей группа должна существовать.

`all_users_group` автоматически конфигурируется при выполнении [встроенной настройки безопасности](../../security/builtin-security.md).

Значение по умолчанию: пустая строка.
    ||
|#

### Первичные настройки безопасности {#security-bootstrap}

Параметры `default_users`, `default_groups`, `default_access` влияют на настройку кластера, осуществляемую при первом старте {{ ydb-short-name }}. При последующих запусках первичная настройка не выполняется, эти параметры игнорируются.

См. также раздел по [встроенной настройке безопасности](../../security/builtin-security.md) и влияющие на неё настройки [уровня `security_config`](#security).

#|
|| Параметр | Описание ||
|| `default_users` | Какие [пользователи](../../concepts/glossary.md#access-user) должны быть созданы на кластере при первом запуске.

Список пар логин-пароль. Первый пользователь становится суперпользователем.

{% note info %}

Пароли задаются в открытом виде и оставлять их действующими на долгое время небезопасно. Поэтому после первого запуска кластера и его настройки рекомендуется пароли стартовым пользователям поменять средствами {{ ydb-short-name }} (например, [`ALTER USER`](../../yql/reference/syntax/alter-user.md)).

[//]: # (TODO: добавить про возможность блокировки этих стартовых пользователей, когда такое описание появится)

{% endnote %}

Пример:

```yaml
default_users:
- name: root
  password: <...>
- name: user1
  password: <...>
```

Ошибки в списке (повторение логинов) фиксируются в логе, но не влияют на запуск кластера.

    ||
|| `default_groups` | Какие [группы](../../concepts/glossary.md#access-group) должны быть созданы на кластере при первом запуске.

Список групп и их членов.

Пример:

```yaml
default_groups:
- name: ADMINS
  members: root
- name: USERS
  members:
  - ADMINS
  - root
  - user1
```

Порядок перечисления групп важен: группы создаются в порядке перечисления, и указанные члены группы к моменту создания группы должны существовать, иначе они не будут добавлены в группу.

Ошибки добавления членов групп фиксируются в логе, но не влияют на запуск кластера.

    ||
|| `default_access` | Какие [права](../../concepts/glossary.md#access-right) должны быть выданы на корне кластера.

Список разрешений в формате [краткой записи управления доступом](../../security/short-access-control-notation.md).

Пример:

```yaml
default_access:
- +(CDB|DDB|GAR):ADMINS
- +(ConnDB):USERS
```

    ||
|#

Ошибки в строках прав доступа фиксируются в логе, но не влияют на запуск кластера. Право доступа с ошибкой не будет добавлено.

[//]: # (TODO: требуется доработка, сейчас ошибка в формате приводит к падению процесса)

#### Настройки административных и других привилегий {#security-access-levels}

Управление доступом в {{ ydb-short-name }} реализуется двумя механизмами:

- [списками прав](../../concepts/glossary.md#access-control-list) на [схемных объектах](../../concepts/glossary.md#scheme-object);
- [уровнями доступа](../../concepts/glossary.md#access-level-list), определяющими дополнительные возможности или ограничения.

Оба механизма применяются одновременно: для конкретного [субъекта](../../concepts/glossary.md#access-subject) действие оказывается доступно, если оба механизма его разрешают, и не доступно, если хотя бы один не разрешает.

Уровень доступа субъекта определяется списками разрешений, заданными в конфигурации кластера, и влияет на дополнительные возможности субъекта при работе со [схемными объектами](../../concepts/glossary.md#scheme-object), а также на возможности субъекта в контекстах, не связанных со схемными объектами.

[//]: # (TODO: добавить ссылку на справку по viewer api и требуемым правам, когда она появится)

#|
|| Параметр | Описание ||
|| `viewer_allowed_sids` | Список [SID](../../concepts/glossary.md#access-sid)'ов с доступом уровня наблюдателя.

Даёт возможность просмотра состояния системы, закрытого от публичного доступа (это большая часть страниц Embedded UI ([YDB Monitoring](../embedded-ui/ydb-monitoring.md))), без возможности делать изменения.
    ||
|| `monitoring_allowed_sids` | Список [SID](../../concepts/glossary.md#access-sid)'ов с доступом уровня оператора.

Даёт дополнительные возможности просмотра и выполнения действий, меняющих состояние системы. Например, выполнение бекапа, восстановления базы или выполнение YQL-запросов через Embedded UI.
    ||
|| `administration_allowed_sids` | Список [SID](../../concepts/glossary.md#access-sid)'ов с доступом уровня администратора.

Даёт право на выполнение административных действий с базами или кластером.
    ||
|#

[//]: # (TODO: wait for pull/9387, dinamic_node_registration to add info about `register_dynamic_node_allowed_sids`)

{% note warning %}

По-умолчанию, все списки пустые.

Пустой список разрешает доступ любому пользователю (включая анонимного пользователя).

Все три пустых списка дают возможности администратора любому пользователю системы.

Для защищённого развёртывания {{ ydb-short-name }} важно заранее определить модель прав и прописать в списках соответствующие группы.

{% endnote %}

В списках могут перечисляться индивидуальные SID'ы [пользователей](../../concepts/glossary.md#access-user) или SID'ы [групп пользователей](../../concepts/glossary.md#access-group). Принадлежность пользователя к списку определяется по прямому вхождению или по вхождению в список любой его группы (рекурсивно).
Рекомендуется включать в списки `*_allowed_sids` группы и отдельные сервисные аккаунты, тогда наделение индивидуальных пользователей соответствующими возможностями не будет требовать изменения общей конфигурации кластера.

Списки разрешений можно воспринимать как слои дополнительных разрешений:

- Субъект, не состоящий ни в одном списке разрешений, имеет возможность просмотра публично доступной информации в системе (например, может видеть [список баз на кластере](../embedded-ui/ydb-monitoring.md#tenant_list_page) или [список узлов кластера](../embedded-ui/ydb-monitoring.md#node_list_page)).
- Списки `viewer_allowed_sids`, `monitoring_allowed_sids`, `administration_allowed_sids` последовательно наращивают возможности субъекта. Максимальные возможности требуют включения во все три списка.
- Присутствие в списке `monitoring_allowed_sids` или `administration_allowed_sids` без присутствия во `viewer_allowed_sids` не имеет смысла.

Например:

- оператор должен состоять (прямо или через группы) во `viewer_allowed_sids` и в `monitoring_allowed_sids`;
- полноценный администратор должен состоять во `viewer_allowed_sids`, `monitoring_allowed_sids` и в `administration_allowed_sids`.

### Конфигурация Blob Storage {#domains-blob}

Данный раздел определяет один или более типов пулов хранения, доступных в кластере для данных в базах данных, со следующими возможностями конфигурации:

- Имя пула хранения
- Свойства устройств (например, тип дисков)
- Шифрование данных (вкл/выкл)
- Режим отказоустойчивости

Доступны следующие [режимы отказоустойчивости](../../concepts/topology.md):

| Режим | Описание |
| --- | --- |
| `none` | Избыточность отсутствует. Применяется для тестирования. |
| `block-4-2` | Избыточность с коэффициентом 1,5, применяется для однодатацентровых кластеров. |
| `mirror-3-dc` | Избыточность с коэффициентом 3, применяется для мультидатацентровых кластеров. |

``` yaml
domains_config:
  domain:
    ...
    storage_pool_types:
    - kind: <имя пула хранения>
      pool_config:
        box_id: 1
        encryption_mode: <опциональный, укажите 1 для шифрования данных на диске>
        erasure_species: <имя режима отказоустойчивости - none, block-4-2, or mirror-3-dc>
        kind: <имя пула хранения - укажите то же значение, что выше>
        pdisk_filter:
        - property:
          - type: <тип устройства для сопоставления с указанным в host_configs.drive.type>
        vdisk_kind: Default
    - kind: <имя пула хранения>
```

Каждой базе данных в кластере назначается как минимум один из доступных пулов хранения, выбираемый в операции создания базы данных. Имена пулов хранения среди назначенных могут быть использованы в атрибуте `DATA` при определении групп колонок в операторах YQL [`CREATE TABLE`](../../yql/reference/syntax/create_table/family.md)/[`ALTER TABLE`](../../yql/reference/syntax/alter_table/family.md).

### Конфигурация State Storage {#domains-state}

State Storage (хранилище состояний) — это независимое хранилище в памяти для изменяемых данных, поддерживающее внутренние процессы {{ ydb-short-name }}. Оно хранит реплики данных на множестве назначенных узлов.

Обычно State Storage не требует масштабирования в целях повышения производительности, поэтому количество узлов в нём следует делать как можно меньшим с учетом необходимого уровня отказоустойчивости.

Доступность State Storage является ключевой для кластера {{ ydb-short-name }}, так как влияет на все базы данных, независимо от того какие пулы хранения в них используются.Для обеспечения отказоустойчивости State Storate его узлы должны быть выбраны таким образом, чтобы гарантировать рабочее большинство в случае ожидаемых отказов.

Для выбора узлов State Storage можно воспользоваться следующими рекомендациями:

|Тип кластера|Мин количество<br/>узлов|Рекомендации по выбору|
|---------|-----------------------|-----------------|
|Без отказоустойчивости|1|Выберите один произвольный узел.|
|В пределах одной зоны доступности|5|Выберите пять узлов в разных доменах отказа пула хранения block-4-2, для гарантии, что большинство в 3 работающих узла (из 5) остается при сбое двух доменов.|
|Геораспределенный|9|Выберите три узла в разных доменах отказа внутри каждой из трех зон доступности пула хранения mirror-3-dc для гарантии, что большинство в 5 работающих узлов (из 9) остается при сбое зоны доступности + домена отказа.|

При развертывании State Storage на кластерах, в которых применяется несколько пулов хранения с возможным сочетанием режимов отказоустойчивости, рассмотрите возможность увеличения количества узлов с распространением их на разные пулы хранения, так как недоступность State Storage приводит к недоступности всего кластера.

```yaml
domains_config:
  ...
  state_storage:
  - ring:
      node: <массив узлов StateStorage>
      nto_select: <количество реплик данных в StateStorage>
    ssid: 1
```

Каждый клиент State Storage (например, таблетка DataShard) использует `nto_select` узлов для записи копий его данных в State Storage. Если State Storage состоит из большего количества узлов чем `nto_select`, то разные узлы могут быть использованы для разных клиентов, поэтому необходимо обеспечить, чтобы любое подмножество из `nto_select` узлов в пределах State Storage отвечало критериям отказоустойчивости.

Для `nto_select` должны использоваться нечетные числа, так как использование четных чисел не улучшает отказоустойчивость по сравнению с ближайшим меньшим нечетным числом.

## domains_config — домен кластера {#domains-config}

Данный раздел содержит конфигурацию кластера {{ ydb-short-name }}, включая [конфигурации Blob Storage](#domains-blob) (хранилища бинарных объектов), [State Storage](#domains-state) (хранилища состояний) и [настройки безопасности](#security).

{% note info %}

Не требуется для работы кластера с [автоматической конфигурацией](../../devops/configuration-management/index.md) State Storage и статической группы.

{% endnote %}

### Синтаксис

``` yaml
domains_config:
  domain:
  - name: <имя корня кластера>
    storage_pool_types: <конфигурация Blob Storage>
  state_storage: <конфигурация State Storage>
  security_config: <конфигурация безопасности>
```

{% note info %}

Формально, поле `domain` может содержать много элементов, так как это список. Но имеет значение только первый элемент, остальные будут проигнорированы (в кластере может быть только один «домен»).

{% endnote %}


## Конфигурация Blob Storage {#domains-blob}

{% note info %}

Не требуется для работы кластера с [автоматической конфигурацией](../../devops/configuration-management/index.md) State Storage и статической группы.

{% endnote %}

Данный раздел определяет один или более типов пулов хранения, доступных в кластере для данных в базах данных, со следующими возможностями конфигурации:

- имя пула хранения;
- свойства устройств (например, тип дисков);
- шифрование данных (вкл/выкл);
- [режим отказоустойчивости](#topology).

### Синтаксис

``` yaml
domains_config:
  domain:
    ...
    storage_pool_types:
    - kind: <имя пула хранения>
      pool_config:
        box_id: 1
        encryption_mode: <опциональный, укажите 1 для шифрования данных на диске>
        erasure_species: <имя режима отказоустойчивости - none, block-4-2, or mirror-3-dc>
        kind: <имя пула хранения - укажите то же значение, что выше>
        pdisk_filter:
        - property:
          - type: <тип устройства для сопоставления с указанным в host_configs.drive.type>
        vdisk_kind: Default
    - kind: <имя пула хранения>
```

Каждой базе данных в кластере назначается как минимум один из доступных пулов хранения, выбираемый в операции создания базы данных. Имена пулов хранения среди назначенных могут быть использованы в атрибуте `DATA` при определении групп колонок в операторах YQL [`CREATE TABLE`](../../yql/reference/syntax/create_table/family.md)/[`ALTER TABLE`](../../yql/reference/syntax/alter_table/family.md).

### Конфигурация State Storage {#domains-state}

{% note info %}

Не требуется для работы кластера с [автоматической конфигурацией](../../devops/configuration-management/index.md) State Storage и статической группы.

{% endnote %}

State Storage (хранилище состояний) — это независимое хранилище в памяти для изменяемых данных, поддерживающее внутренние процессы {{ ydb-short-name }}. Оно хранит реплики данных на множестве назначенных узлов.

Обычно State Storage не требует масштабирования в целях повышения производительности, поэтому количество узлов в нём следует делать как можно меньшим с учётом необходимого уровня отказоустойчивости.

Доступность State Storage является ключевой для кластера {{ ydb-short-name }}, так как влияет на все базы данных, независимо от того какие пулы хранения в них используются. Для обеспечения отказоустойчивости State Storate его узлы должны быть выбраны таким образом, чтобы гарантировать рабочее большинство в случае ожидаемых отказов.

Для выбора узлов State Storage можно воспользоваться следующими рекомендациями:

|Тип кластера|Мин количество<br/>узлов|Рекомендации по выбору|
|---------|-----------------------|-----------------|
|Без отказоустойчивости|1|Выберите один произвольный узел.|
|В пределах одной зоны доступности|5|Выберите пять узлов в разных доменах отказа пула хранения block-4-2, для гарантии, что большинство в трёх работающих узлах (из пяти) остаётся при сбое двух доменов.|
|Геораспределенный|9|Выберите три узла в разных доменах отказа внутри каждой из трёх зон доступности пула хранения mirror-3-dc для гарантии, что большинство в пяти работающих узлов (из девяти) остаётся при сбое зоны доступности + домена отказа.|

При развёртывании State Storage на кластерах, в которых применяется несколько пулов хранения с возможным сочетанием режимов отказоустойчивости, рассмотрите возможность увеличения количества узлов с распространением их на разные пулы хранения, так как недоступность State Storage приводит к недоступности всего кластера.

```yaml
domains_config:
  ...
  state_storage:
  - ring:
      node: <массив узлов StateStorage>
      nto_select: <количество реплик данных в StateStorage>
    ssid: 1
```

Каждый клиент State Storage (например, таблетка DataShard) использует `nto_select` узлов для записи копий его данных в State Storage. Если State Storage состоит из большего количества узлов чем `nto_select`, то разные узлы могут быть использованы для разных клиентов. Поэтому необходимо обеспечить, чтобы любое подмножество из `nto_select` узлов в пределах State Storage отвечало критериям отказоустойчивости.

Для `nto_select` должны использоваться нечётные числа, так как использование чётных чисел не улучшает отказоустойчивость по сравнению с ближайшим меньшим нечётным числом.

### Примеры {#domains-examples}

{% list tabs %}

- `block-4-2`

  ```yaml
  domains_config:
    domain:
    - name: Root
      storage_pool_types:
      - kind: ssd
        pool_config:
          box_id: 1
          erasure_species: block-4-2
          kind: ssd
          pdisk_filter:
          - property:
            - type: SSD
          vdisk_kind: Default
    state_storage:
    - ring:
        node: [1, 2, 3, 4, 5, 6, 7, 8]
        nto_select: 5
      ssid: 1
  ```

- `block-4-2` + Auth

  ```yaml
  domains_config:
    domain:
    - name: Root
      storage_pool_types:
      - kind: ssd
        pool_config:
          box_id: 1
          erasure_species: block-4-2
          kind: ssd
          pdisk_filter:
          - property:
            - type: SSD
          vdisk_kind: Default
    state_storage:
    - ring:
        node: [1, 2, 3, 4, 5, 6, 7, 8]
        nto_select: 5
      ssid: 1
    security_config:
      enforce_user_token_requirement: true
  ```

- `mirror-3-dc`

  ```yaml
  domains_config:
    domain:
    - name: global
      storage_pool_types:
      - kind: ssd
        pool_config:
          box_id: 1
          erasure_species: mirror-3-dc
          kind: ssd
          pdisk_filter:
          - property:
            - type: SSD
          vdisk_kind: Default
    state_storage:
    - ring:
        node: [1, 2, 3, 4, 5, 6, 7, 8, 9]
        nto_select: 9
      ssid: 1
  ```

- `none` (без отказоустойчивости)

  ```yaml
  domains_config:
    domain:
    - name: Root
      storage_pool_types:
      - kind: ssd
        pool_config:
          box_id: 1
          erasure_species: none
          kind: ssd
          pdisk_filter:
          - property:
            - type: SSD
          vdisk_kind: Default
    state_storage:
    - ring:
        node:
        - 1
        nto_select: 1
      ssid: 1
  ```

- Несколько пулов

  ```yaml
  domains_config:
    domain:
    - name: Root
      storage_pool_types:
      - kind: ssd
        pool_config:
          box_id: '1'
          erasure_species: block-4-2
          kind: ssd
          pdisk_filter:
          - property:
            - {type: SSD}
          vdisk_kind: Default
      - kind: rot
        pool_config:
          box_id: '1'
          erasure_species: block-4-2
          kind: rot
          pdisk_filter:
          - property:
            - {type: ROT}
          vdisk_kind: Default
      - kind: rotencrypted
        pool_config:
          box_id: '1'
          encryption_mode: 1
          erasure_species: block-4-2
          kind: rotencrypted
          pdisk_filter:
          - property:
            - {type: ROT}
          vdisk_kind: Default
      - kind: ssdencrypted
        pool_config:
          box_id: '1'
          encryption_mode: 1
          erasure_species: block-4-2
          kind: ssdencrypted
          pdisk_filter:
          - property:
            - {type: SSD}
          vdisk_kind: Default
    state_storage:
    - ring:
        node: [1, 16, 31, 46, 61, 76, 91, 106]
        nto_select: 5
      ssid: 1
  ```

## Конфигурация аутентификации {#auth}

[Режим аутентификации](../../security/authentication.md) на кластере {{ ydb-short-name }} задается в разделе `security_config`.

{% note info %}

Данная секция может указываться внутри раздела `domains_config.security_config`, что является устаревшим способом задания параметров аутентификации.

{% endnote %}

### Синтаксис

```yaml
security_config:
  enforce_user_token_requirement: Bool
```

| Ключ | Описание |
| --- | --- |
| `enforce_user_token_requirement` | Требовать токен пользователя.<br/>Допустимые значения:<br/><ul><li>`false` — режим аутентификации анонимный, токен не требуется (применяется по умолчанию, если параметр не задан);</li><li>`true` — режим аутентификации по логину и паролю, для выполнения запроса требуется валидный токен пользователя.</li></ul> |

{% endlist %}

## Настройка акторной системы {#actor-system}

Основной потребитель CPU — акторная система. Все акторы, в зависимости от своего типа, выполняются в одном из пулов (параметр `name`). Конфигурирование заключается в распределении ядер процессора узла по пулам акторной системы. При выделении процессорных ядер пулам нужно учитывать, что PDisk и gRPC API работают вне акторной системы и требуют отдельных ресурсов.

Вы можете использовать [автоматическое](#autoconfig) или [ручное](#tuneconfig) конфигурирование акторной системы. В секции `actor_system_config` укажите:

* тип узла и количество ядер CPU, выделяемых процессу `ydbd` в случае использования автоматической конфигурирования;
* количество ядер CPU для каждой подсистемы кластера {{ ydb-full-name }} при использовании ручного конфигурирования.

Автоматическое конфигурирование является адаптивным, т.е. подстраивается под текущую нагрузку системы. Его рекомендуется использовать в большинстве случаев.

Ручное конфигурирование может быть полезно в случае, когда какой-либо пул акторной системы в процессе работы оказывается перегружен и это влияет на общую производительность БД. Отслеживать нагрузку пулов можно на [странице мониторинга в Embedded UI](../../reference/embedded-ui/ydb-monitoring.md#node_list_page).

### Автоматическое конфигурирование {#autoconfig}

Пример секции `actor_system_config` для автоматического конфигурирования акторной системы:

```yaml
actor_system_config:
  use_auto_config: true
  node_type: STORAGE
  cpu_count: 10
```

| Параметр | Описание |
| --- | --- |
| `use_auto_config` | Включение автоматического конфигурирования акторной системы. |
| `node_type` | Тип узла. Определяет ожидаемую нагрузку и соотношение ядер CPU между пулами. Одно из значений:<ul><li>`STORAGE` — узел работает с блочными устройствами и отвечает за Distributed Storage;</li><li>`COMPUTE` — узел обслуживает пользовательскую нагрузку;</li><li>`HYBRID` — узел работает со смешанной нагрузкой или потребление `System`, `User` и  `IC` узла под нагрузкой приблизительно одинаково. |
| `cpu_count` | Количество ядер CPU, выделенных узлу. |

### Ручное конфигурирование {#tuneconfig}

Пример секции `actor_system_config` для ручного конфигурирование акторной системы:

```yaml
actor_system_config:
  executor:
  - name: System
    spin_threshold: 0
    threads: 2
    type: BASIC
  - name: User
    spin_threshold: 0
    threads: 3
    type: BASIC
  - name: Batch
    spin_threshold: 0
    threads: 2
    type: BASIC
  - name: IO
    threads: 1
    time_per_mailbox_micro_secs: 100
    type: IO
  - name: IC
    spin_threshold: 10
    threads: 1
    time_per_mailbox_micro_secs: 100
    type: BASIC
  scheduler:
    progress_threshold: 10000
    resolution: 256
    spin_threshold: 0
```

| Параметр | Описание |
| --- | --- |
| `executor` | Конфигурация пулов.<br/>В конфигах пулов рекомендуется менять только количество ядер процессора (параметр `threads`). |
| `name` | Имя пула, определяет его назначение. Одно из значений:<ul><li>`System` — предназначен для выполнения быстрых внутренних операций {{ ydb-full-name }} (обслуживает системные таблетки, State Storage, ввод и вывод Distributed Storage, Erasure Сoding);</li><li>`User` — обслуживает пользовательскую нагрузку (пользовательские таблетки, выполнение запросов в Query Processor);</li><li>`Batch` — обслуживает задачи, которые не имеют строгого лимита на время выполнения, фоновых операции (сборка мусора, тяжелые запросы Query Processor);</li><li>`IO` — отвечает за выполнение всех задач с блокирующими операциями (аутентификация, запись логов в файл);</li><li>`IC` — Interconnect, включает нагрузку, связанную с коммуникацией между узлами (системные вызовы для ожидания и отправки по сети данных, сериализация данных, разрезание и склеивание сообщений).</li></ul> |
| `spin_threshold` | Количество тактов процессора перед уходом в сон при отсутствии сообщений. Состояние сна снижает энергопотребление, но может увеличивать latency запросов во время слабой нагрузки. |
| `threads` | Количество ядер процессора, выделенных пулу.<br/>Не рекомендуется суммарно назначать в пулы System, User, Batch, IC больше ядер, чем доступно в системе. |
| `max_threads` | Максимальное количество ядер процессора, которые могут быть выданы пулу в случае использования простаивающих ядер из других пулов. При выставлении параметра включается механизм увеличения размера пула при полном потреблении пула и наличия свободных ядер.<br/>Проверка текущей нагрузки и перераспределение ядер происходит 1 раз в секунду. |
| `max_avg_ping_deviation` | Дополнительное условие для расширения пула по количеству ядер. При потреблении более чем 90% ядер процессора, выделенных пулу, требуется ухудшение показателя SelfPing более чем на `max_avg_ping_deviation` микросекунд от ожидаемых 10 миллисекунд. |
| `time_per_mailbox_micro_secs` | Количество сообщений в каждом акторе, которое будет обработано перед переключением на другой актор. |
| `type` | Тип пула. Одно из значений:<ul><li>`IO` — укажите для пула IO;</li><li>`BASIC` — укажите для всех остальных пулов.</li></ul> |
| `scheduler` | Конфигурация шедулера. Шедулер акторной системы отвечает за доставку отложенных сообщений между акторами.<br/>Не рекомендуется изменять параметры шедулера по умолчанию. |
| `progress_threshold` | В акторной системе есть возможность запросить отправку сообщения в будущем по расписанию. Возможна ситуация, когда в определенный момент времени системе не удастся отправить все запланированные сообщения. В этом случае система начинает рассылать сообщения в «виртуальном времени», обрабатывая в каждом цикле отправку сообщений за период, не превышающий `progress_threshold` в микросекундах, и продвигая виртуальное время на `progress_threshold`, пока оно не догонит реальное. |
| `resolution` | При составлении расписания отправки сообщений используются дискретные временные слоты. Длительность слота задается параметром `resolution` в микросекундах. |

## Контроллер памяти {#memory-controller}

Внутри [узлов](../../concepts/glossary.md#database-node) {{ ydb-short-name }} работают множество различных компонентов, использующих память. Большинству из них требуется фиксированное количество памяти, но некоторые из них могут гибко варьировать объём используемой памяти, тем самым улучшая производительность всей системы. Если компоненты {{ ydb-short-name }} выделяют больше памяти, чем физически доступно, операционная система, вероятно, [завершит](https://en.wikipedia.org/wiki/Out_of_memory#Recovery) весь процесс {{ ydb-short-name }}, что крайне нежелательно. Цель контроллера памяти — позволить {{ ydb-short-name }} избегать ситуаций с нехваткой памяти, при этом эффективно используя имеющийся её объём.

Примеры компонентов, управляемых контроллером памяти:

- [Общий кеш](../../concepts/glossary.md#shared-cache): хранит недавно доступные страницы данных, считанные из [распределённого хранилища](../../concepts/glossary.md#distributed-storage), чтобы уменьшить количество операций ввода-вывода с диска и ускорить получение данных.
- [MemTable](../../concepts/glossary.md#memtable): содержит данные, которые ещё не были записаны в [SST](../../concepts/glossary.md#sst).
- [KQP](../../concepts/glossary.md#kqp): хранит промежуточные результаты обработки запросов.
- Кеши аллокатора: хранят блоки памяти, которые были освобождены, но ещё не возвращены операционной системе.

Лимиты памяти могут быть настроены для контроля общего использования памяти, обеспечивая эффективную работу базы данных в рамках доступных ресурсов.

### Жёсткий лимит памяти {#hard-memory-limit}

Жёсткий лимит памяти определяет общее количество памяти, доступное для процесса {{ ydb-short-name }}.

По умолчанию жёсткий лимит памяти для процесса {{ ydb-short-name }} равен лимиту памяти, указанному в его [cgroups](https://en.wikipedia.org/wiki/Cgroups).

В окружениях без лимита памяти cgroups значение жёсткого лимита памяти по умолчанию равно общему объёму доступной памяти хоста. Эта конфигурация позволяет базе данных использовать все доступные ресурсы, но может привести к конкуренции за ресурсы с другими процессами на том же хосте. Хотя контроллер памяти пытается учесть это внешнее потребление, такое использование не рекомендуется.

Жёсткий лимит памяти также может быть задан в конфигурации. Обратите внимание, что процесс базы данных всё равно может превысить этот лимит. Поэтому настоятельно рекомендуется использовать лимиты памяти cgroups в производственных окружениях для строгого контроля памяти.

Большинство других лимитов памяти можно настроить либо в абсолютных байтах, либо в процентах относительно жёсткого лимита памяти. Использование процентов удобно для управления кластерами с узлами разной ёмкости. Если указаны как абсолютные лимиты в байтах, так и процентные лимиты, контроллер памяти использует комбинацию обоих (максимум для нижних лимитов и минимум для верхних лимитов).

Пример секции `memory_controller_config` с указанным жёстким лимитом памяти:

```yaml
memory_controller_config:
  hard_limit_bytes: 16106127360
```

### Мягкий лимит памяти {#soft-memory-limit}

Мягкий лимит памяти определяет опасный порог, который процесс {{ ydb-short-name }} не должен превышать при нормальных обстоятельствах.

Если мягкий лимит превышен, {{ ydb-short-name }} постепенно уменьшает размер [общего кеша](../../concepts/glossary.md#shared-cache) до нуля. В таком случае следует как можно скорее добавить больше узлов баз данных в кластер или снизить лимиты памяти для отдельных компонентов.

### Целевое использование памяти {#target-memory-utilization}

Целевое использование памяти определяет порог использования памяти процессом {{ ydb-short-name }}, который считается оптимальным.

Гибкие размеры кешей рассчитываются в соответствии с их пределами, чтобы поддерживать потребление памяти процессом вблизи этого значения.

Например, в базе данных, которая расходует немного памяти на выполнение запросов, кеши используют память вблизи этого порога, а остальная память остаётся свободной. Если выполнение запросов начинает потреблять больше памяти, кеши начинают сокращать свои размеры до минимального порога.

### Лимиты памяти для отдельных компонентов

Внутри {{ ydb-short-name }} существует два разных типа компонентов.

Первый тип компонентов, или кеш-компоненты, функционируют как кеши, например, храня последние использованные данные. Каждый кеш-компонент имеет минимальный и максимальный пороговые значения лимита памяти, что позволяет ему динамически изменять свою ёмкость в зависимости от текущего потребления памяти процессом {{ ydb-short-name }}.

Второй тип компонентов, или компоненты-активности, выделяют память для конкретных задач, таких как выполнение запросов или процесс компактизации. Каждый компонент-активность имеет фиксированный лимит памяти. Также существует дополнительный общий лимит памяти для таких компонентов, из которого они пытаются получить необходимую память.

Многие другие вспомогательные компоненты и процессы работают параллельно с процессом {{ ydb-short-name }}, потребляя память. В настоящее время эти компоненты не имеют каких-либо лимитов памяти.

#### Лимиты памяти для кеш-компонентов

К кеш-компонентам относятся:

- Общий кеш;
- MemTable.

Лимиты каждого кеш-компонента динамически пересчитываются каждую секунду, чтобы каждый компонент потреблял память пропорционально своим предельным значениям, а общее потребление памяти оставалось около целевого использования памяти.

Минимальный порог лимита памяти кеш-компонентов не резервируется, что означает, что память остаётся доступной до тех пор, пока она не будет фактически использована. Однако, как только эта память заполнена, компоненты обычно сохраняют данные, действуя в рамках своего текущего лимита памяти. Таким образом, ожидается, что сумма минимальных лимитов памяти кеш-компонентов будет меньше целевого использования памяти.

При необходимости следует переопределить как минимальные, так и максимальные пороговые значения; в противном случае, если пороговое значение отсутствует, оно будет иметь значение по умолчанию.

Пример секции `memory_controller_config` с указанными лимитами общего кеша:

```yaml
memory_controller_config:
  shared_cache_min_percent: 10
  shared_cache_max_percent: 30
```

#### Лимиты памяти для компонентов-активностей

К компонентам-активностям относятся:

- KQP.

Лимит памяти для каждого из компонентов-активностей указывает максимальное количество памяти, которое он может попытаться использовать. Однако, чтобы предотвратить превышение процессом {{ ydb-short-name }} мягкого лимита памяти, общее потребление компонентов-активностей ограничивается дополнительным лимитом, называемым лимитом памяти для активностей. Если общее использование памяти активными компонентами превышает этот лимит, любые дополнительные запросы на память будут отклонены.

Таким образом, хотя суммарные индивидуальные лимиты компонентов-активностей могут в совокупности превышать лимит памяти для активностей, индивидуальный лимит каждого компонента должен быть меньше этого общего предела. Кроме того, сумма минимальных лимитов памяти для кеш-компонентов плюс лимит памяти для активностей должна быть меньше мягкого лимита памяти.

Существуют и другие компоненты-активности, которые в настоящее время не имеют каких-либо индивидуальных лимитов памяти.

Пример секции `memory_controller_config` с указанным лимитом для KQP:

```yaml
memory_controller_config:
  query_execution_limit_percent: 25
```

### Параметры конфигурации

Каждый параметр конфигурации применяется в контексте одного узла базы данных.

Как упоминалось ранее, ожидается, что сумма минимальных лимитов памяти для кеш-компонентов плюс лимит памяти для активностей должна быть меньше мягкого лимита памяти.

Это ограничение можно выразить в упрощённой форме:

$shared\_cache\_min\_percent + mem\_table\_min\_percent + activities\_limit\_percent < soft\_limit\_percent$

Или в детализированной форме:

$Max(shared\_cache\_min\_percent * hard\_limit\_bytes / 100, shared\_cache\_min\_bytes) + Max(mem\_table\_min\_percent * hard\_limit\_bytes / 100, mem\_table\_min\_bytes) + Min(activities\_limit\_percent * hard\_limit\_bytes / 100, activities\_limit\_bytes) < Min(soft\_limit\_percent * hard\_limit\_bytes / 100, soft\_limit\_bytes)$

| Параметры | Значение по умолчанию | Описание |
| --- | --- | --- |
| `hard_limit_bytes` | CGroup&nbsp;memory&nbsp;limit&nbsp;/<br/>Память хоста | Жёсткий лимит использования памяти. |
| `soft_limit_percent`&nbsp;/<br/>`soft_limit_bytes` | 75% | Мягкий лимит использования памяти. |
| `target_utilization_percent`&nbsp;/<br/>`target_utilization_bytes` | 50% | Целевое использование памяти. |
| `activities_limit_percent`&nbsp;/<br/>`activities_limit_bytes` | 30% | Лимит памяти для активностей. |
| `shared_cache_min_percent`&nbsp;/<br/>`shared_cache_min_bytes` | 20% | Минимальный порог для лимита памяти общего кеша. |
| `shared_cache_max_percent`&nbsp;/<br/>`shared_cache_max_bytes` | 50% | Максимальный порог для лимита памяти общего кеша. |
| `mem_table_min_percent`&nbsp;/<br/>`mem_table_min_bytes` | 1% | Минимальный порог для лимита памяти MemTable. |
| `mem_table_max_percent`&nbsp;/<br/>`mem_table_max_bytes` | 3% | Максимальный порог для лимита памяти MemTable. |
| `query_execution_limit_percent`&nbsp;/<br/>`query_execution_limit_bytes` | 20% | Лимит памяти для KQP. |

## blob_storage_config — статическая группа кластера {#blob-storage-config}

Укажите конфигурацию статической группы кластера. Статическая группа необходима для работы базовых таблеток кластера, в том числе `Hive`, `SchemeShard`, `BlobstorageContoller`.
Обычно данные таблетки не хранят много информации, поэтому мы не рекомендуем создавать более одной статической группы.

Для статической группы необходимо указать информацию о дисках и нодах, на которых будет размещена статическая группа. Например, для модели `erasure: none` конфигурация может быть такой:

```bash
blob_storage_config:
  service_set:
    groups:
    - erasure_species: none
      rings:
      - fail_domains:
        - vdisk_locations:
          - node_id: 1
            path: /dev/disk/by-partlabel/ydb_disk_ssd_02
            pdisk_category: SSD
# ...
```

Для конфигурации расположенной в 3 AZ  необходимо указать 3 кольца. Для конфигураций, расположенных в одной AZ, указывается ровно одно кольцо.

## Конфигурация аутентификации {#auth-config}

{{ ydb-short-name }} позволяет использовать различные способы аутентификации пользователя в системе. Настройки аутентификации и провайдеров аутентификации задаются в секции `auth_config`.

### Конфигурация сложности пароля {#password-complexity}

{{ ydb-short-name }} позволяет аутентифицировать пользователей по логину и паролю. Подробнее можно прочитать в разделе [аутентификация по логину и паролю](../../security/authentication.md#static-credentials). Для повышения безопасности в {{ ydb-short-name }} имеется возможность настроить [политику паролей](../../security/authentication.md#password-complexity) пользователей. Параметры политики паролей настраиваются в секции `password_complexity`.

Синтаксис секции `password_complexity`:

```yaml
auth_config:
  ...
  password_complexity:
    min_length: 8
    min_lower_case_count: 1
    min_upper_case_count: 1
    min_numbers_count: 1
    min_special_chars_count: 1
    special_chars: "!@#$%^&*()_+{}|<>?="
    can_contain_username: false
  ...
```

| Параметр | Описание | Значение по умолчанию |
| :--- | :--- | :---: |
| `min_length` | Минимальная длина пароля | 0 |
| `min_lower_case_count` | Минимальное число символов в нижнем регистре | 0 |
| `min_upper_case_count` | Минимальное число символов в верхнем регистре | 0 |
| `min_numbers_count` | Минимальное число цифр в пароле | 0 |
| `min_special_chars_count` | Минимальное число специальных символов из списка `special_chars` | 0 |
| `special_chars` | Специальные символы, которые допустимо использовать в пароле. Допускается указать любое подмножество из следующих символов `!@#$%^&*()_+{}\|<>?=`. Значение (`""`) эквивалентно списку `!@#$%^&*()_+{}\|<>?=` | `""` |
| `can_contain_username` | Может ли пароль содержать имя пользователя | `false` |

{% note info %}

Любые изменения политики паролей не затрагивают уже действующие пароли пользователей, поэтому изменять существующие пароли не требуется, они будут приниматься в текущем виде.

{% endnote %}

### Блокировка пользователя после неуспешных попыток ввода пароля {#account-lockout}

{{ ydb-short-name }} позволяет заблокировать возможность аутентификации пользователя после неудачных попыток ввода пароля. Правила блокировки настраиваются в секции `account_lockout`.

Пример секции `account_lockout`:

```yaml
auth_config:
  ...
  account_lockout:
    attempt_threshold: 4
    attempt_reset_duration: "1h"
  ...
```

| Параметр | Описание | Значение по умолчанию |
| :--- | :--- | :---: |
| `attempt_threshold` | Максимальное количество неуспешных попыток ввода правильного пароля. После `attempt_threshold` неуспешных попыток пользователь будет заблокирован на время, заданное в параметре `attempt_reset_duration`. Нулевое значение параметра `attempt_threshold` указывает на отсутствие каких-либо ограничений на число попыток ввода пароля. После успешной аутентификации (ввода правильных имени пользователя и пароля), счетчик неуспешных попыток сбрасывается в значение 0. | 4 |
| `attempt_reset_duration` | Период времени блокировки пользователя. В течение этого периода пользователь не сможет аутентифицироваться в системе даже если введёт правильные имя пользователя и пароль. Период блокировки отсчитывается с момента последней неверной попытки ввода пароля. Если задан нулевой (`"0s"` - запись, эквивалентная 0 секунд) период блокировки, то пользователь будет считаться заблокированным на неограниченное время. В этом случае снять блокировку должен Администратор системы.<br/><br/>Минимальный интервал времени блокировки 1 секунда. <br/>Поддерживаемые единицы измерения:<ul><li>Секунды. `30s`</li><li>Минуты. `20m`</li><li>Часы. `5h`</li><li>Дни. `3d`</li></ul>Не допускается комбинировать единицы измерения в одной строке. Например такая запись некорректна: `1d12h`. Такую запись нужно заменить на эквивалентную, например `36h`. | "1h" |

### Конфигурация LDAP аутентификации {#ldap-auth-config}

Одним из способов аутентификации пользователей в {{ ydb-short-name }} является использование LDAP каталога. Подробнее о таком виде аутентификации написано в разделе про [использование LDAP каталога](../../security/authentication.md#ldap). Для конфигурирования LDAP аутентификации необходимо описать секцию `ldap_authentication`.

Пример секции `ldap_authentication`:

```yaml
auth_config:
  ...
  ldap_authentication:
    hosts:
      - "ldap-hostname-01.example.net"
      - "ldap-hostname-02.example.net"
      - "ldap-hostname-03.example.net"
    port: 389
    base_dn: "dc=mycompany,dc=net"
    bind_dn: "cn=serviceAccaunt,dc=mycompany,dc=net"
    bind_password: "serviceAccauntPassword"
    search_filter: "uid=$username"
    use_tls:
      enable: true
      ca_cert_file: "/path/to/ca.pem"
      cert_require: DEMAND
  ldap_authentication_domain: "ldap"
  scheme: "ldap"
  requested_group_attribute: "memberOf"
  extended_settings:
      enable_nested_groups_search: true

  refresh_time: "1h"
  ...
```

| Параметр | Описание |
| --- | --- |
| `hosts` | Список имен хостов, на котором работает LDAP сервер |
| `port` | Порт для подключения к LDAP серверу |
| `base_dn` | Корень поддерева в LDAP каталоге, начиная с которого будет производиться поиск записи пользователя |
| `bind_dn` | Отличительное имя (Distinguished Name, DN) сервисного аккаунта, от имени которого выполняется поиск записи пользователя |
| `bind_password` | Пароль сервисного аккаунта, от имени которого выполняется поиск записи пользователя |
| `search_filter` | Фильтр для поиска записи пользователя в LDAP каталоге. В строке фильтра может встречаться последовательность символов *$username*, которая будет заменена на имя пользователя, запрошенное для аутентификации в базе данных |
| `use_tls` | Настройки для конфигурирования TLS соединения между {{ ydb-short-name }} и LDAP сервером |
| `enable` | Определяет, будет ли произведена попытка установить TLS-соединение с [использованием запроса `StartTls`](../../security/authentication.md#starttls). При установке значения этого параметра в `true`, необходимо отключить использование схемы соединения `ldaps`, присвоив параметру `ldap_authentication.scheme` значение `ldap`. |
| `ca_cert_file` | Путь до файла сертификата удостоверяющего центра |
| `cert_require` | Уровень требований к сертификату LDAP сервера.<br/>Возможные значения:<ul><li>`NEVER` - {{ ydb-short-name }} не запрашивает сертификат или проверку проходит любой сертификат.</li><li>`ALLOW` - {{ ydb-short-name }} требует, что бы LDAP сервер предоставил сертификат. Если предоставленному сертификату нельзя доверять, TLS сессия все равно установится.</li><li>`TRY` - {{ ydb-short-name }} требует, что бы LDAP сервер предоставил сертификат. Если предоставленному сертификату нельзя доверять, установление TLS соединения прекращается.</li><li>`DEMAND` и `HARD` - Эти требования эквивалентны параметру `TRY`. По умолчанию установлено значение `DEMAND`.</li></ul> |
| `ldap_authentication_domain` | Идентификатор, прикрепляемый к имени пользователя, позволяющий отличать пользователей из LDAP каталога от пользователей аутентифицируемых с помощью других провайдеров. Значение по умолчанию `ldap` |
| `scheme` | Схема соединения с LDAP-сервером.<br>Возможные значения:<ul><li>`ldap` — {{ ydb-short-name }} будет выполнять соединение с LDAP-сервером без какого-либо шифрования. Пароли будут отправляться на LDAP-сервер в открытом виде. Это значение установлено по умолчанию.</li><li>`ldaps` — {{ ydb-short-name }} будет выполнять зашифрованное соединение с LDAP-сервером по протоколу TLS с самого первого запроса. Для успешного установления соединения по схеме `ldaps` необходимо отключить использование [запроса `StartTls`](../../security/authentication.md#starttls) в секции `ldap_authentication.use_tls.enable: false` и заполнить информацию о сертификате `ldap_authentication.use_tls.ca_cert_file` и уровне требования сертификата `ldap_authentication.use_tls.cert_require`.</li><li>При использовании любого другого значения будет браться значение по умолчанию - `ldap`.</li></ul> |
| `requested_group_attribute` | Атрибут обратного членства в группе. По умолчанию `memberOf`. |
| `extended_settings.enable_nested_groups_search` | Флаг определяет, будет ли выполнятся запрос для получения всего дерева групп, в которые входят непосредственные группы пользователя. |
| `host` | Имя хоста, на котором работает LDAP-сервер. Это устаревший параметр, вместо него должен использоваться параметр `hosts`. |
| `refresh_time` | Определяет время, когда будет попытка обновить информацию о пользователе. Конкретное время обновления будет лежать в интервале от `refresh_time/2` до `refresh_time` |

## Настройка стабильных имен узлов кластера {#node-broker-config}

Присвоение имен узлам осуществляет Node Broker — системная таблетка, которая отвечает за регистрацию динамических узлов в кластере {{ ydb-short-name }}.

Node Broker присваивает имена динамическим узлам при их регистрации в кластере. По умолчанию имя узла состоит из имени хоста и номера порта, на котором работает узел.

В динамической среде, где имена хостов часто меняются, например в Kubernetes, использование имени хоста и порта приводит к неконтролируемому росту количества уникальных имен узлов, даже для базы данных с небольшим количеством динамических узлов. Подобное поведение может быть нежелательным для системы time series мониторинга — количество метрик растет некотролируемо. Для решения этой проблемы администратор системы может настроить *стабильные* имена узлов.

Стабильное имя идентифицирует узел в рамках тенанта. Оно состоит из префикса и порядкового номера узла в рамках тенанта. Если динамический узел был выключен, то по истечении таймаута его стабильное имя может быть занято новым динамическим узлом, обслуживающим того же тенанта.

Чтобы включить стабильные имена узлов, необходимо добавить в конфигурацию кластера следующее:

```yaml
feature_flags:
  enable_stable_node_names: true
```

По умолчанию, префиксом является `slot-`. Для того, чтобы переопределить префикс, необходимо добавить в конфигурацию кластера следующее:

```yaml
node_broker_config:
  stable_node_name_prefix: <новый префикс>
```

## resource_broker_config — брокер ресурсов {#resource-broker-config}

Брокер ресурсов — это [акторный сервис](../../concepts/glossary.md#actor-service), контролирующий потребление ресурсов [узла](../../concepts/glossary.md#node) {{ ydb-short-name }}, таких как:

- `CPU` — количество потоков;
- `Memory` — оперативная память.

Разные виды активностей (фоновые операции, удаление данных по [TTL](../../concepts/ttl.md) и т.д.) запускаются в разных *очередях* брокера ресурсов. Каждая такая очередь имеет лимитированное число ресурсов:

| Название очереди | CPU | Memory | Описание |
| --- | --- | --- | --- |
| `queue_ttl` | 2 | — | Операции удаления данных по [TTL](../../concepts/ttl.md). |
| `queue_backup` | 2 | — | Операции [резервного копирования](../../devops/backup-and-recovery.md#s3). |
| `queue_restore` | 2 | — | Операции [восстановления из резервной копии](../../devops/backup-and-recovery.md#s3). |
| `queue_build_index` | 10 | — | Операции [онлайн-создания вторичного индекса](../../concepts/secondary_indexes.md#index-add). |
| `queue_cdc_initial_scan` | 4 | — | [Первоначальное сканирование таблицы](../../concepts/cdc.md#initial-scan). |

{% note info %}

Рекомендуется **дополнять** конфигурацию брокера ресурсов, используя [теги](../../devops/configuration-management/configuration-v2/dynamic-config-selectors.md#dopolnitelnye-tegi-v-yaml) `!inherit` и `!append`.

{% endnote %}

Пример дополнения конфигурации брокера ресурсов пользовательским лимитом для очереди `queue_ttl`:

```yaml
resource_broker_config: !inherit
  queues: !append
  - name: queue_ttl
    limit:
      cpu: 4
```

## Секция конфигурации `feature_flags` {#feature_flags}

Для включения определённой функциональности в {{ ydb-short-name }}, нужно добавить соответствующий функциональный флаг в секцию `feature_flags` конфигурации кластера. Например, для включения поддержки векторных индексов и автопартиционирования топиков в CDC, нужно добавить следующие строки в конфигурацию:

```yaml
feature_flags:
  enable_vector_index: true
  enable_topic_autopartitioning_for_cdc: true
```

### Функциональные флаги

| Флаг          | Функция |
|---------------------------| ----------------------------------------------------|
| `enable_vector_index`                                    | [Векторный индекс](../../dev/vector-indexes.md) для приближённого векторного поиска |
| `enable_batch_updates`                                   | Поддержка запросов `BATCH UPDATE` и `BATCH DELETE` |
| `enable_kafka_native_balancing`                          | Клиентская балансировка партиций при чтении по [протоколу Kafka](https://kafka.apache.org/documentation/#consumerconfigs_partition.assignment.strategy) |
| `enable_topic_autopartitioning_for_cdc`                  | [Автопартиционирование топиков](../../concepts/cdc.md#topic-partitions) в CDC для строковых таблиц |
| `enable_access_to_index_impl_tables`                     | Возможность [указания числа реплик](../../yql/reference/syntax/alter_table/indexes.md) для вторичного индекса |
| `enable_changefeeds_export`, `enable_changefeeds_import` | Поддержка потоков изменений (changefeed) в операциях резервного копирования и восстановления |
| `enable_view_export`                                     | Поддержка представлений (`VIEW`) в операциях резервного копирования и восстановления |
| `enable_export_auto_dropping`                            | Автоудаление временных директорий и таблиц при экспорте в S3 |
| `enable_followers_stats`                                 | Системные представления с информацией об [истории перегруженных партиций](../../dev/system-views#top-overload-partitions) |
| `enable_strict_acl_check`                                | Запрет на выдачу прав несуществующим пользователям и на удаление пользователей, которым выданы права |
| `enable_strict_user_management`                          | Строгие правила администрирования локальных пользователей (т.е. администрировать локальных пользователей может только администратор кластера или базы данных)|
| `enable_database_admin`                                  | Добавление роли администратора базы данных |


## Примеры конфигураций кластеров {#examples}

В [репозитории](https://github.com/ydb-platform/ydb/tree/main/ydb/deploy/yaml_config_examples/)  можно найти модельные примеры конфигураций кластеров для самостоятельного развертывания. Ознакомьтесь с ними перед развертыванием кластера.
