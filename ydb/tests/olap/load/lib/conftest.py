from __future__ import annotations
import allure
import json
import logging
import os
import pytest
import yatest

from allure_commons._core import plugin_manager
from allure_pytest.listener import AllureListener
from copy import deepcopy
from datetime import datetime
from pytz import timezone
from time import time
from typing import Optional, Union
from ydb.tests.olap.lib.ydb_cli import YdbCliHelper, WorkloadType, CheckCanonicalPolicy
from ydb.tests.olap.lib.ydb_cluster import YdbCluster
from ydb.tests.olap.lib.allure_utils import allure_test_description, NodeErrors
from ydb.tests.olap.lib.results_processor import ResultsProcessor
from ydb.tests.olap.lib.utils import get_external_param
from ydb.tests.olap.scenario.helpers.scenario_tests_helper import ScenarioTestHelper
import ydb.tests.olap.lib.remote_execution as re


class LoadSuiteBase:
    class QuerySettings:
        def __init__(self, iterations: Optional[int] = None, timeout: Optional[float] = None, query_prefix: Optional[str] = None) -> None:
            self.iterations = iterations
            self.timeout = timeout
            self.query_prefix = query_prefix

    iterations: int = 5
    workload_type: WorkloadType = None
    timeout: float = 1800.
    check_canonical: CheckCanonicalPolicy = CheckCanonicalPolicy.NO
    query_syntax: str = ''
    query_settings: dict[int, LoadSuiteBase.QuerySettings] = {}
    scale: Optional[int] = None
    query_prefix: str = get_external_param('query-prefix', '')
    verify_data: bool = True
    float_mode: str = ''
    __nodes_state: Optional[dict[str, YdbCluster.Node]] = None

    @classmethod
    def get_users(cls) -> list[str]:
        return ['']

    @classmethod
    def get_external_path(cls) -> str:
        if not hasattr(cls, 'external_folder'):
            return ''
        result = os.getenv('EXTERNAL_DATA')
        if result is None:
            result = os.getenv('ARCADIA_EXTERNAL_DATA', '')
            if result:
                result = yatest.common.source_path(result)

        if result and cls.external_folder:
            return os.path.join(result, cls.external_folder)
        return result

    @classmethod
    def suite(cls) -> str:
        result = cls.__name__
        if result.startswith('Test'):
            return result[4:]
        return result

    @classmethod
    def _get_query_settings(cls, query_num: Optional[int] = None, query_name: Optional[str] = None) -> QuerySettings:
        result = LoadSuiteBase.QuerySettings(
            iterations=cls.iterations,
            timeout=cls.timeout,
            query_prefix=cls.query_prefix
        )
        for key in query_name, query_num:
            if key is None:
                continue
            q = cls.query_settings.get(key, LoadSuiteBase.QuerySettings())
            if q.iterations is not None:
                result.iterations = q.iterations
            if q.timeout is not None:
                result.timeout = q.timeout
            if q.query_prefix is not None:
                result.query_prefix = q.query_prefix
        return result

    @classmethod
    @allure.step('check tables size')
    def check_tables_size(cls, folder: Optional[str], tables: dict[str, int]):
        wait_error = YdbCluster.wait_ydb_alive(
            int(os.getenv('WAIT_CLUSTER_ALIVE_TIMEOUT', 20 * 60)), (
                folder if folder is not None
                else [t for t in tables.keys()]
            ))
        if wait_error is not None:
            pytest.fail(f'Cluster is dead: {wait_error}')
        sth = ScenarioTestHelper(None)
        errors: list[str] = []
        for table, expected_size in tables.items():
            if folder is None:
                table_full = table
            elif folder.endswith('/') or table.startswith('/'):
                table_full = f'{folder}{table}'
            else:
                table_full = f'{folder}/{table}'
            size = sth.get_table_rows_count(table_full)
            if size != expected_size:
                errors.append(f'table `{table}`: expect {expected_size}, but actually is {size};')
        if len(errors) > 0:
            msg = "\n".join(errors)
            pytest.fail(f'Unexpected tables size in `{folder}`:\n {msg}')

    @staticmethod
    def execute_ssh(host: str, cmd: str):
        local = re.is_localhost(host)
        if local:
            ssh_cmd = cmd
        else:
            ssh_cmd = ['ssh', "-o", "StrictHostKeyChecking=no", "-o", "UserKnownHostsFile=/dev/null"]
            ssh_user = os.getenv('SSH_USER')
            if ssh_user is not None:
                ssh_cmd += ['-l', ssh_user]
            ssh_key_file = os.getenv('SSH_KEY_FILE')
            if ssh_key_file is not None:
                ssh_cmd += ['-i', ssh_key_file]
            ssh_cmd += [host, cmd]
        return yatest.common.execute(ssh_cmd, wait=False, text=True, shell=local)

    @classmethod
    def __hide_query_text(cls, text, query_text):
        if os.getenv('SECRET_REQUESTS', '') != '1' or not query_text:
            return text
        return text.replace(query_text, '<Query text hided by sequrity reasons>')

    @classmethod
    def __attach_logs(cls, start_time, attach_name, query_text, ignore_roles=False):
        if ignore_roles:
            # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ ÑƒÐ½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ñ…Ð¾ÑÑ‚Ñ‹ ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ð° Ð±ÐµÐ· Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸Ð¸ Ð¿Ð¾ Ñ€Ð¾Ð»Ð¸
            hosts = sorted(set(node.host for node in YdbCluster.get_cluster_nodes()))
        else:
            # ÐžÑ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ð°Ñ Ð»Ð¾Ð³Ð¸ÐºÐ° - Ñ‚Ð¾Ð»ÑŒÐºÐ¾ STORAGE Ð½Ð¾Ð´Ñ‹
            hosts = [node.host for node in filter(lambda x: x.role == YdbCluster.Node.Role.STORAGE, YdbCluster.get_cluster_nodes())]

        tz = timezone('Europe/Moscow')
        start = datetime.fromtimestamp(start_time, tz).isoformat()
        cmd = f"ulimit -n 100500;unified_agent select -S '{start}' -s {{storage}}{{container}}"
        exec_kikimr = {
            '': {},
        }
        exec_start = deepcopy(exec_kikimr)
        for host in hosts:
            for c in exec_kikimr.keys():
                try:
                    exec_kikimr[c][host] = cls.execute_ssh(host, cmd.format(
                        storage='kikimr',
                        container=f' -m k8s_container:{c}' if c else ''
                    ))
                except BaseException as e:
                    logging.error(e)
            for c in exec_start.keys():
                try:
                    exec_start[c][host] = cls.execute_ssh(host, cmd.format(
                        storage='kikimr-start',
                        container=f' -m k8s_container:{c}' if c else ''))
                except BaseException as e:
                    logging.error(e)

        if not hosts:
            allure.attach(
                "No cluster hosts found, no kikimr logs collected.",
                f"{attach_name} logs info",
                allure.attachment_type.TEXT
            )
            return

        error_log = ''
        for c, execs in exec_start.items():
            for host, e in sorted(execs.items()):
                e.wait(check_exit_code=False)
                error_log += f'{host}:\n{e.stdout if e.returncode == 0 else e.stderr}\n'
            allure.attach(cls.__hide_query_text(error_log, query_text), f'{attach_name}_{c}_stderr', allure.attachment_type.TEXT)

        for c, execs in exec_kikimr.items():
            dir = os.path.join(yatest.common.tempfile.gettempdir(), f'{attach_name}_{c}_logs')
            os.makedirs(dir, exist_ok=True)
            for host, e in execs.items():
                e.wait(check_exit_code=False)
                with open(os.path.join(dir, host), 'w') as f:
                    f.write(cls.__hide_query_text(e.stdout if e.returncode == 0 else e.stderr, query_text))
            archive = dir + '.tar.gz'
            yatest.common.execute(['tar', '-C', dir, '-czf', archive, '.'])
            allure.attach.file(archive, f'{attach_name}_{c}_logs', extension='tar.gz')

    @classmethod
    def save_nodes_state(cls) -> None:
        cls.__nodes_state = {n.slot: n for n in YdbCluster.get_cluster_nodes(db_only=True)}

    @classmethod
    def __get_core_hashes_by_pod(cls, hosts: set[str], start_time: float, end_time: float) -> dict[str, list[tuple[str, str]]]:
        core_processes = {
            h: cls.execute_ssh(h, 'sudo flock /tmp/brk_pad /Berkanavt/breakpad/bin/kikimr_breakpad_analizer.sh')
            for h in hosts
        }

        core_hashes = {}
        for h, exec in core_processes.items():
            exec.wait(check_exit_code=False)
            if exec.returncode != 0:
                logging.error(f'Error while process coredumps on host {h}: {exec.stderr}')
            exec = cls.execute_ssh(h, ('find /coredumps/ -name "sended_*.json" '
                                       f'-mmin -{(10 + time() - start_time) / 60} -mmin +{(-10 + time() - end_time) / 60}'
                                       ' | while read FILE; do cat $FILE; echo -n ","; done'))
            exec.wait(check_exit_code=False)
            if exec.returncode == 0:
                for core in json.loads(f'[{exec.stdout.strip(",")}]'):
                    slot = f"{core.get('slot', '')}@{h}"
                    core_hashes.setdefault(slot, [])
                    core_hashes[slot].append((core.get('core_id', ''), core.get('core_hash', '')))
            else:
                logging.error(f'Error while search coredumps on host {h}: {exec.stderr}')
        return core_hashes

    @classmethod
    def __get_hosts_with_omms(cls, hosts: set[str], start_time: float, end_time: float) -> set[str]:
        tz = timezone('Europe/Moscow')
        start = datetime.fromtimestamp(start_time, tz).strftime("%Y-%m-%d %H:%M:%S")
        end = datetime.fromtimestamp(end_time, tz).strftime("%Y-%m-%d %H:%M:%S")
        oom_cmd = f'sudo journalctl -k -q --no-pager -S "{start}" -U "{end}" --grep "Out of memory: Kill" --case-sensitive=false'
        ooms = set()
        for h in hosts:
            exec = cls.execute_ssh(h, oom_cmd)
            exec.wait(check_exit_code=False)
            if exec.returncode == 0:
                if exec.stdout:
                    ooms.add(h)
            else:
                logging.error(f'Error while search OOMs on host {h}: {exec.stderr}')
        return ooms

    @classmethod
    def check_nodes(cls, result: YdbCliHelper.WorkloadRunResult, end_time: float) -> list[NodeErrors]:
        """
        ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð½Ð¾Ð´ ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ð° Ð¿Ð¾ÑÐ»Ðµ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ workload
        
        Ð¡Ñ€Ð°Ð²Ð½Ð¸Ð²Ð°ÐµÑ‚ Ñ‚ÐµÐºÑƒÑ‰ÐµÐµ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ñ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸ÐµÐ¼ Ð´Ð¾ Ð·Ð°Ð¿ÑƒÑÐºÐ° workload Ð¸ nemesis
        """
        if cls.__nodes_state is None:
            logging.warning("No initial nodes state available for comparison")
            return []
        
        node_errors = []
        fail_hosts = set()
        
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ñ‚ÐµÐºÑƒÑ‰Ð¸Ðµ Ð½Ð¾Ð´Ñ‹ ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ð°
        current_nodes = YdbCluster.get_cluster_nodes(db_only=True)
        current_nodes_by_slot = {node.slot: node for node in current_nodes}
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÐºÐ°Ð¶Ð´ÑƒÑŽ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð½ÑƒÑŽ Ð½Ð¾Ð´Ñƒ
        for slot, saved_node in cls.__nodes_state.items():
            current_node = current_nodes_by_slot.get(slot)
            
            if current_node is None:
                # ÐÐ¾Ð´Ð° Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð° - Ð¾Ð½Ð° down
                node_errors.append(NodeErrors(saved_node, 'is down'))
                fail_hosts.add(saved_node.host)
                logging.warning(f"Node {slot} is down (not found in current cluster)")
            elif current_node.start_time > saved_node.start_time:
                # ÐÐ¾Ð´Ð° Ð±Ñ‹Ð»Ð° Ð¿ÐµÑ€ÐµÐ·Ð°Ð¿ÑƒÑ‰ÐµÐ½Ð°
                node_errors.append(NodeErrors(current_node, 'was restarted'))
                fail_hosts.add(current_node.host)
                logging.info(f"Node {slot} was restarted (start_time: {saved_node.start_time} -> {current_node.start_time})")
            else:
                # ÐÐ¾Ð´Ð° Ð² Ð¿Ð¾Ñ€ÑÐ´ÐºÐµ
                logging.debug(f"Node {slot} is healthy")
        
        # ÐžÑ‡Ð¸Ñ‰Ð°ÐµÐ¼ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ
        cls.__nodes_state = None
        
        if len(node_errors) == 0:
            logging.info("All nodes are healthy")
            return []

        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ cores Ð¸ OOM Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð½Ñ‹Ñ… Ñ…Ð¾ÑÑ‚Ð¾Ð²
        logging.info(f"Checking cores and OOM for {len(fail_hosts)} problematic hosts")
        core_hashes = cls.__get_core_hashes_by_pod(fail_hosts, result.start_time, end_time)
        ooms = cls.__get_hosts_with_omms(fail_hosts, result.start_time, end_time)
        
        # ÐžÐ±Ð¾Ð³Ð°Ñ‰Ð°ÐµÐ¼ Ð¾ÑˆÐ¸Ð±ÐºÐ¸ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÐµÐ¹ Ð¾ cores Ð¸ OOM
        for node_error in node_errors:
            node_error.core_hashes = core_hashes.get(f'{node_error.node.slot}', [])
            node_error.was_oom = node_error.node.host in ooms
            
            # Ð›Ð¾Ð³Ð¸Ñ€ÑƒÐµÐ¼ Ð´ÐµÑ‚Ð°Ð»Ð¸ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹
            if node_error.core_hashes:
                logging.error(f"Node {node_error.node.slot} has {len(node_error.core_hashes)} cores")
            if node_error.was_oom:
                logging.error(f"Node {node_error.node.slot} had OOM")
        
        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¾ÑˆÐ¸Ð±ÐºÐ¸ Ð² Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚
        for err in node_errors:
            result.add_error(f'Node {err.node.slot} {err.message}')
        
        logging.info(f"Found {len(node_errors)} node issues: {[f'{err.node.slot}:{err.message}' for err in node_errors]}")
        return node_errors

    @classmethod
    def process_query_result(cls, result: YdbCliHelper.WorkloadRunResult, query_name: str, upload: bool):
        def _get_duraton(stats, field):
            r = stats.get(field)
            return float(r) / 1e3 if r is not None else None

        def _duration_text(duration: float | int):
            s = f'{int(duration)}s ' if duration >= 1 else ''
            return f'{s}{int(duration * 1000) % 1000}ms'

        def _attach_plans(plan: YdbCliHelper.QueryPlan, name: str) -> None:
            if plan is None:
                return
            if plan.plan is not None:
                allure.attach(json.dumps(plan.plan), f'{name} json', attachment_type=allure.attachment_type.JSON)
            if plan.table is not None:
                allure.attach(plan.table, f'{name} table', attachment_type=allure.attachment_type.TEXT)
            if plan.ast is not None:
                allure.attach(plan.ast, f'{name} ast', attachment_type=allure.attachment_type.TEXT)
            if plan.svg is not None:
                allure.attach(plan.svg, f'{name} svg', attachment_type=allure.attachment_type.SVG)
            if plan.stats is not None:
                allure.attach(plan.stats, f'{name} stats', attachment_type=allure.attachment_type.TEXT)

        if result.query_out is not None:
            allure.attach(result.query_out, 'Query output', attachment_type=allure.attachment_type.TEXT)

        if result.explain.final_plan is not None:
            with allure.step('Explain'):
                _attach_plans(result.explain.final_plan, 'Plan')

        for iter_num in sorted(result.iterations.keys()):
            iter_res = result.iterations[iter_num]
            s = allure.step(f'Iteration {iter_num}')
            if iter_res.time:
                s.params['duration'] = _duration_text(iter_res.time)
            try:
                with s:
                    _attach_plans(iter_res.final_plan, 'Final plan')
                    _attach_plans(iter_res.in_progress_plan, 'In-progress plan')
                    if iter_res.error_message:
                        pytest.fail(iter_res.error_message)
            except BaseException:
                pass

        query_text = ''

        if result.stdout is not None:
            begin_text = 'Query text:\n'
            begin_pos = result.stdout.find(begin_text)
            if begin_pos >= 0:
                begin_pos += len(begin_text)
                end_pos = result.stdout.find("\n\n\titeration")
                if end_pos < 0:
                    end_pos = len(result.stdout)
                query_text = result.stdout[begin_pos:end_pos]
            if os.getenv('SECRET_REQUESTS', '') != '1':
                allure.attach(query_text, 'Query text', attachment_type=allure.attachment_type.TEXT)
            allure.attach(cls.__hide_query_text(result.stdout, query_text), 'Stdout', attachment_type=allure.attachment_type.TEXT)

        if result.stderr is not None:
            allure.attach(cls.__hide_query_text(result.stderr, query_text), 'Stderr', attachment_type=allure.attachment_type.TEXT)
        end_time = time()
        allure_test_description(
            cls.suite(), query_name,
            start_time=result.start_time, end_time=end_time, node_errors=cls.check_nodes(result, end_time),
            workload_result=result, workload_params=None
        )
        stats = result.get_stats(query_name)
        for p in ['Mean']:
            if p in stats:
                allure.dynamic.parameter(p, _duration_text(stats[p] / 1000.))
        if os.getenv('NO_KUBER_LOGS') is None and not result.success:
            cls.__attach_logs(start_time=result.start_time, attach_name='kikimr', query_text=query_text)
        allure.attach(json.dumps(stats, indent=2), 'Stats', attachment_type=allure.attachment_type.JSON)
        if upload:
            ResultsProcessor.upload_results(
                kind='Load',
                suite=cls.suite(),
                test=query_name,
                timestamp=end_time,
                is_successful=result.success,
                min_duration=_get_duraton(stats, 'Min'),
                max_duration=_get_duraton(stats, 'Max'),
                mean_duration=_get_duraton(stats, 'Mean'),
                median_duration=_get_duraton(stats, 'Median'),
                statistics=stats,
            )
        if not result.success:
            exc = pytest.fail.Exception('\n'.join([result.error_message, result.warning_message]))
            if result.traceback is not None:
                exc = exc.with_traceback(result.traceback)
            raise exc
        if result.warning_message:
            raise Exception(result.warning_message)

    @classmethod
    def setup_class(cls) -> None:
        cls._setup_start_time = time()
        result = YdbCliHelper.WorkloadRunResult()
        result.iterations[0] = YdbCliHelper.Iteration()
        result.add_error(YdbCluster.wait_ydb_alive(int(os.getenv('WAIT_CLUSTER_ALIVE_TIMEOUT', 20 * 60))))
        result.traceback = None
        if not result.error_message and hasattr(cls, 'do_setup_class'):
            try:
                cls.do_setup_class()
            except BaseException as e:
                result.add_error(str(e))
                result.traceback = e.__traceback__
        result.iterations[0].time = time() - cls._setup_start_time
        query_name = '_Verification'
        result.add_stat(query_name, 'Mean', 1000 * result.iterations[0].time)
        nodes_start_time = [n.start_time for n in YdbCluster.get_cluster_nodes(db_only=False)]
        first_node_start_time = min(nodes_start_time) if len(nodes_start_time) > 0 else 0
        result.start_time = max(cls._setup_start_time - 600, first_node_start_time)
        cls.process_query_result(result, query_name, True)

    @classmethod
    def teardown_class(cls) -> None:
        """
        ÐžÐ±Ñ‰Ð¸Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ¸ Ð´Ð»Ñ Ð²ÑÐµÑ… Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ñ… ÐºÐ»Ð°ÑÑÐ¾Ð².
        ÐœÐ¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ Ð¿ÐµÑ€ÐµÐ¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½ Ð² Ð½Ð°ÑÐ»ÐµÐ´Ð½Ð¸ÐºÐ°Ñ… Ð´Ð»Ñ ÑÐ¿ÐµÑ†Ð¸Ñ„Ð¸Ñ‡Ð½Ð¾Ð¹ Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ¸.
        """
        with allure.step('Base teardown: checking for custom cleanup'):
            if hasattr(cls, 'do_teardown_class'):
                try:
                    logging.info(f"Executing custom teardown for {cls.__name__}")
                    cls.do_teardown_class()
                    allure.attach(
                        f"Custom teardown completed for {cls.__name__}",
                        'Custom teardown result',
                        allure.attachment_type.TEXT
                    )
                except Exception as e:
                    error_msg = f"Error during custom teardown for {cls.__name__}: {e}"
                    logging.error(error_msg)
                    allure.attach(error_msg, 'Custom teardown error', allure.attachment_type.TEXT)
            else:
                logging.info(f"No custom teardown defined for {cls.__name__}")
                allure.attach(
                    f"No custom teardown needed for {cls.__name__}",
                    'Teardown result',
                    allure.attachment_type.TEXT
                )

    @classmethod
    def kill_workload_processes(cls, process_names: Union[str, list[str]],
                                target_dir: Optional[str] = None) -> None:
        """
        Ð£Ð´Ð¾Ð±Ð½Ñ‹Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ Ð´Ð»Ñ Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ¸ workload Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐ¾Ð² Ð½Ð° Ð²ÑÐµÑ… Ð½Ð¾Ð´Ð°Ñ… ÐºÐ»Ð°ÑÑ‚ÐµÑ€Ð°.
        Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ YdbCluster.kill_processes_on_nodes.

        Args:
            process_names: Ð¸Ð¼Ñ Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐ° Ð¸Ð»Ð¸ ÑÐ¿Ð¸ÑÐ¾Ðº Ð¸Ð¼ÐµÐ½ Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐ¾Ð² Ð´Ð»Ñ Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ¸
            target_dir: Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ñ, Ð² ÐºÐ¾Ñ‚Ð¾Ñ€Ð¾Ð¹ Ð¸ÑÐºÐ°Ñ‚ÑŒ Ð¿Ñ€Ð¾Ñ†ÐµÑÑÑ‹ (Ð¾Ð¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾)
        """
        with allure.step(f'Killing workload processes: {process_names}'):
            try:
                results = YdbCluster.kill_processes_on_nodes(
                    process_names=process_names,
                    target_dir=target_dir
                )

                total_killed = 0
                for host, host_results in results.items():
                    for process_name, process_result in host_results.items():
                        total_killed += process_result.get('killed_count', 0)

                success_msg = f"Successfully processed {len(results)} hosts, killed {total_killed} processes"
                logging.info(success_msg)
                allure.attach(success_msg, 'Kill processes result', allure.attachment_type.TEXT)

            except Exception as e:
                error_msg = f"Error killing workload processes: {e}"
                logging.error(error_msg)
                allure.attach(error_msg, 'Kill processes error', allure.attachment_type.TEXT)
                raise

    def run_workload_test(self, path: str, query_num: Optional[int] = None, query_name: Optional[str] = None) -> None:
        assert query_num is not None or query_name is not None
        for plugin in plugin_manager.get_plugin_manager().get_plugins():
            if isinstance(plugin, AllureListener):
                allure_test_result = plugin.allure_logger.get_test(None)
                if allure_test_result is not None:
                    for param in allure_test_result.parameters:
                        if param.name in {'query_num', 'query_name'}:
                            param.mode = allure.parameter_mode.HIDDEN.value
        qparams = self._get_query_settings(query_num=query_num, query_name=query_name)
        if query_name is None:
            query_name = f'Query{query_num:02d}'
        self.save_nodes_state()
        result = YdbCliHelper.workload_run(
            path=path,
            query_names=[query_name],
            iterations=qparams.iterations,
            workload_type=self.workload_type,
            timeout=qparams.timeout,
            check_canonical=self.check_canonical,
            query_syntax=self.query_syntax,
            scale=self.scale,
            query_prefix=qparams.query_prefix,
            external_path=self.get_external_path(),
            users=self.get_users(),
        )[query_name]
        self.process_query_result(result, query_name, True)

    @classmethod
    def check_nodes_diagnostics(cls, result: YdbCliHelper.WorkloadRunResult, end_time: float) -> list[NodeErrors]:
        """
        Ð¡Ð¾Ð±Ð¸Ñ€Ð°ÐµÑ‚ Ð´Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸Ñ‡ÐµÑÐºÑƒÑŽ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ Ð½Ð¾Ð´Ð°Ñ… Ð±ÐµÐ· Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ Ð¿ÐµÑ€ÐµÐ·Ð°Ð¿ÑƒÑÐºÐ¾Ð²/Ð¿Ð°Ð´ÐµÐ½Ð¸Ð¹.
        ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚ coredump'Ñ‹ Ð¸ OOM Ð´Ð»Ñ Ð²ÑÐµÑ… Ð½Ð¾Ð´ Ð¸Ð· ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð½Ð¾Ð³Ð¾ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ.
        """
        return cls.check_nodes_diagnostics_with_timing(result, result.start_time, end_time)

    @classmethod
    def check_nodes_diagnostics_with_timing(cls, result: YdbCliHelper.WorkloadRunResult, start_time: float, end_time: float) -> list[NodeErrors]:
        """
        Ð¡Ð¾Ð±Ð¸Ñ€Ð°ÐµÑ‚ Ð´Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸Ñ‡ÐµÑÐºÑƒÑŽ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ Ð½Ð¾Ð´Ð°Ñ… Ñ ÐºÐ°ÑÑ‚Ð¾Ð¼Ð½Ñ‹Ð¼ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ð¼ Ð¸Ð½Ñ‚ÐµÑ€Ð²Ð°Ð»Ð¾Ð¼.
        ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚ coredump'Ñ‹ Ð¸ OOM Ð´Ð»Ñ Ð²ÑÐµÑ… Ð½Ð¾Ð´ Ð¸Ð· ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð½Ð¾Ð³Ð¾ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ.

        Args:
            result: Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ workload
            start_time: Ð²Ñ€ÐµÐ¼Ñ Ð½Ð°Ñ‡Ð°Ð»Ð° Ð¸Ð½Ñ‚ÐµÑ€Ð²Ð°Ð»Ð° Ð´Ð»Ñ Ð´Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÐ¸
            end_time: Ð²Ñ€ÐµÐ¼Ñ Ð¾ÐºÐ¾Ð½Ñ‡Ð°Ð½Ð¸Ñ Ð¸Ð½Ñ‚ÐµÑ€Ð²Ð°Ð»Ð° Ð´Ð»Ñ Ð´Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÐ¸
        """
        if cls.__nodes_state is None:
            return []

        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð²ÑÐµ Ñ…Ð¾ÑÑ‚Ñ‹ Ð¸Ð· ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð½Ð¾Ð³Ð¾ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ
        all_hosts = {node.host for node in cls.__nodes_state.values()}

        # Ð¡Ð¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð´Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸Ñ‡ÐµÑÐºÑƒÑŽ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð´Ð»Ñ Ð²ÑÐµÑ… Ñ…Ð¾ÑÑ‚Ð¾Ð²
        core_hashes = cls.__get_core_hashes_by_pod(all_hosts, start_time, end_time)
        ooms = cls.__get_hosts_with_omms(all_hosts, start_time, end_time)

        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ NodeErrors Ð´Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð¹ Ð½Ð¾Ð´Ñ‹ Ñ Ð´Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð¹ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÐµÐ¹
        node_errors = []
        for node in cls.__nodes_state.values():
            # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ NodeErrors Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ coredump'Ñ‹ Ð¸Ð»Ð¸ OOM
            has_cores = bool(core_hashes.get(node.slot, []))
            has_oom = node.host in ooms

            if has_cores or has_oom:
                node_error = NodeErrors(node, 'diagnostic info collected')
                node_error.core_hashes = core_hashes.get(node.slot, [])
                node_error.was_oom = has_oom
                node_errors.append(node_error)

                # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¾ÑˆÐ¸Ð±ÐºÐ¸ Ð² Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ (cores Ð¸ OOM - ÑÑ‚Ð¾ errors)
                if has_cores:
                    result.add_error(f'Node {node.slot} has {len(node_error.core_hashes)} coredump(s)')
                if has_oom:
                    result.add_error(f'Node {node.slot} experienced OOM')

        cls.__nodes_state = None
        return node_errors

    def _collect_workload_params(self, result, workload_name):
        """
        Ð¡Ð¾Ð±Ð¸Ñ€Ð°ÐµÑ‚ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ workload Ð´Ð»Ñ Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð°.
        1. Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐµÑ‚ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð¸Ð· params_to_include (Ð³Ð°Ñ€Ð°Ð½Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾ Ð¿Ð¾Ð¿Ð°Ð´ÑƒÑ‚ Ð² Ð¾Ñ‚Ñ‡Ñ‘Ñ‚).
        2. Ð—Ð°Ñ‚ÐµÐ¼ Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐµÑ‚ Ð²ÑÐµ Ð¾ÑÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð¸Ð· ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ workload, ÐºÑ€Ð¾Ð¼Ðµ Ð¸ÑÐºÐ»ÑŽÑ‡Ñ‘Ð½Ð½Ñ‹Ñ… (ÑÐ»ÑƒÐ¶ÐµÐ±Ð½Ñ‹Ñ…), Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð½Ðµ Ð¿Ð¾Ñ‚ÐµÑ€ÑÑ‚ÑŒ Ð½Ð¾Ð²Ñ‹Ðµ Ð¸Ð»Ð¸ ÑÐ¿ÐµÑ†Ð¸Ñ„Ð¸Ñ‡Ð½Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸.
        """
        workload_params = {}
        workload_stats = result.get_stats(workload_name)
        if workload_stats:
            # 1. Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÑÐ°Ð¼Ñ‹Ðµ Ð²Ð°Ð¶Ð½Ñ‹Ðµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ (Ð³Ð°Ñ€Ð°Ð½Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾ Ð¿Ð¾Ð¿Ð°Ð´ÑƒÑ‚ Ð² Ð¾Ñ‚Ñ‡Ñ‘Ñ‚)
            params_to_include = [
                'total_runs', 'planned_duration', 'actual_duration',
                'use_iterations', 'workload_type', 'table_type',
                'total_iterations', 'total_threads'
            ]
            for param in params_to_include:
                if param in workload_stats:
                    workload_params[param] = workload_stats[param]
            # 2. Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð²ÑÐµ Ð¾ÑÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹, ÐºÑ€Ð¾Ð¼Ðµ Ð¸ÑÐºÐ»ÑŽÑ‡Ñ‘Ð½Ð½Ñ‹Ñ… ÑÐ»ÑƒÐ¶ÐµÐ±Ð½Ñ‹Ñ…
            # Ð­Ñ‚Ð¾ Ð¿Ð¾Ð·Ð²Ð¾Ð»ÑÐµÑ‚ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð²ÐºÐ»ÑŽÑ‡Ð°Ñ‚ÑŒ Ð½Ð¾Ð²Ñ‹Ðµ/Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
            for key, value in workload_stats.items():
                if key not in workload_params and key not in ['success_rate', 'successful_runs', 'failed_runs']:
                    workload_params[key] = value
        return workload_params

    def _diagnose_nodes(self, result, workload_name):
        """ÐŸÑ€Ð¾Ð²Ð¾Ð´Ð¸Ñ‚ Ð´Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÑƒ Ð½Ð¾Ð´ (cores/oom) Ð¸ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÑÐ¿Ð¸ÑÐ¾Ðº Ð¾ÑˆÐ¸Ð±Ð¾Ðº"""
        try:
            end_time = time()
            diagnostics_start_time = getattr(result, 'workload_start_time', result.start_time)
            node_errors = type(self).check_nodes_diagnostics_with_timing(result, diagnostics_start_time, end_time)
        except Exception as e:
            logging.error(f"Error getting nodes state: {e}")
            result.add_warning(f"Error getting nodes state: {e}")
            node_errors = []
        return node_errors

    def _update_summary_flags(self, result, workload_name):
        """ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÑ‚ summary-Ñ„Ð»Ð°Ð³Ð¸ Ð´Ð»Ñ warning/error Ð¿Ð¾ Ð²ÑÐµÐ¼ Ð¸Ñ‚ÐµÑ€Ð°Ñ†Ð¸ÑÐ¼"""
        has_warning = False
        has_error = False

        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð¾ÑˆÐ¸Ð±ÐºÐ¸ Ð¸ Ð¿Ñ€ÐµÐ´ÑƒÐ¿Ñ€ÐµÐ¶Ð´ÐµÐ½Ð¸Ñ Ð² Ð¸Ñ‚ÐµÑ€Ð°Ñ†Ð¸ÑÑ…
        for iteration in getattr(result, "iterations", {}).values():
            if hasattr(iteration, "warning_message") and iteration.warning_message:
                has_warning = True
            if hasattr(iteration, "error_message") and iteration.error_message:
                has_error = True

        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð¾ÑˆÐ¸Ð±ÐºÐ¸ Ð¸ Ð¿Ñ€ÐµÐ´ÑƒÐ¿Ñ€ÐµÐ¶Ð´ÐµÐ½Ð¸Ñ Ð² Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ðµ
        if result.warnings:
            has_warning = True
        if result.errors:
            has_error = True

        # Ð”Ð»Ñ Ð¾Ð±Ñ€Ð°Ñ‚Ð½Ð¾Ð¹ ÑÐ¾Ð²Ð¼ÐµÑÑ‚Ð¸Ð¼Ð¾ÑÑ‚Ð¸ Ñ‚Ð°ÐºÐ¶Ðµ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑÑ‚Ð°Ñ€Ñ‹Ðµ Ð¿Ð¾Ð»Ñ
        if hasattr(result, "warning_message") and result.warning_message:
            has_warning = True
        if hasattr(result, "error_message") and result.error_message:
            has_error = True

        stats = result.get_stats(workload_name)
        if stats is not None:
            stats["with_warnings"] = has_warning
            stats["with_errors"] = has_error

    def _create_allure_report(self, result, workload_name, workload_params, node_errors, use_node_subcols):
        """Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÑ‚ allure-Ð¾Ñ‚Ñ‡Ñ‘Ñ‚ Ð¿Ð¾ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð°Ð¼ workload"""
        end_time = time()
        start_time = result.start_time if result.start_time else end_time - 1
        additional_table_strings = {}
        if workload_params.get('actual_duration') is not None:
            actual_duration = workload_params['actual_duration']
            planned_duration = workload_params.get('planned_duration', getattr(self, 'timeout', 0))
            actual_minutes = int(actual_duration) // 60
            actual_seconds = int(actual_duration) % 60
            planned_minutes = int(planned_duration) // 60
            planned_seconds = int(planned_duration) % 60
            additional_table_strings['execution_time'] = f"Actual: {actual_minutes}m {actual_seconds}s (Planned: {planned_minutes}m {planned_seconds}s)"
        if 'total_iterations' in workload_params and 'total_threads' in workload_params:
            total_iterations = workload_params['total_iterations']
            total_threads = workload_params['total_threads']
            if total_iterations == 1 and total_threads > 1:
                additional_table_strings['execution_mode'] = f"Single iteration with {total_threads} parallel threads"
            elif total_iterations > 1:
                avg_threads = workload_params.get('avg_threads_per_iteration', 1)
                additional_table_strings['execution_mode'] = f"{total_iterations} iterations with avg {avg_threads:.1f} threads per iteration"
        allure_test_description(
            suite=type(self).suite(),
            test=workload_name,
            start_time=start_time,
            end_time=end_time,
            addition_table_strings=additional_table_strings,
            node_errors=node_errors,
            workload_result=result,
            workload_params=workload_params,
            use_node_subcols=use_node_subcols
        )

    def _handle_final_status(self, result, workload_name, node_errors):
        """
        ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÑÑ‚Ð°Ñ‚ÑƒÑ Ñ‚ÐµÑÑ‚Ð° Ð¿Ð¾ Ð¿Ñ€Ð¾ÑÑ‚Ð¾Ð¹ Ð»Ð¾Ð³Ð¸ÐºÐµ:
        
        1. ðŸ”´ FAIL: ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹ Ñ Ð½Ð¾Ð´Ð°Ð¼Ð¸ (OOM, cores)
        2. ðŸ”´ FAIL: Ð²ÑÐµ Ð¸Ñ‚ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð½Ðµ Ð²Ñ‹Ð¿Ð¾Ð»Ð½Ð¸Ð»Ð¸ÑÑŒ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾
        3. ðŸŸ¡ WARNING: ÐµÑÑ‚ÑŒ timeout, Ð½Ð¾ Ð½Ðµ ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡Ð½Ð¾
        4. ðŸŸ¢ PASS: Ð²ÑÐµ Ñ…Ð¾Ñ€Ð¾ÑˆÐ¾
        """
        stats = result.get_stats(workload_name)
        node_issues = stats.get("nodes_with_issues", 0) if stats else 0
        
        # --- ÐŸÐ Ð˜ÐšÐ Ð•ÐŸÐ›Ð¯Ð•Ðœ Ð›ÐžÐ“Ð˜ Ð•Ð¡Ð›Ð˜ ÐÐ£Ð–ÐÐž ---
        cluster_log_mode = get_external_param('cluster_log', 'default')
        attach_logs_method = getattr(type(self), "_LoadSuiteBase__attach_logs", None)
        if attach_logs_method:
            try:
                # ÐŸÑ€Ð¸ÐºÑ€ÐµÐ¿Ð»ÑÐµÐ¼ Ð»Ð¾Ð³Ð¸ ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹ Ð¸Ð»Ð¸ Ð²ÐºÐ»ÑŽÑ‡ÐµÐ½ Ñ€ÐµÐ¶Ð¸Ð¼ 'all'
                if cluster_log_mode == 'all' or node_issues > 0 or result.errors:
                    attach_logs_method(
                        start_time=getattr(result, "start_time", None),
                        attach_name="kikimr",
                        query_text="",
                        ignore_roles=True
                    )
            except Exception as e:
                logging.warning(f"Failed to attach kikimr logs: {e}")

        # --- 1. FAIL Ð•Ð¡Ð›Ð˜ Ð•Ð¡Ð¢Ð¬ ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐ˜Ð• ÐŸÐ ÐžÐ‘Ð›Ð•ÐœÐ« Ð¡ ÐÐžÐ”ÐÐœÐ˜ ---
        critical_node_issues = sum(1 for err in node_errors if err.was_oom or err.core_hashes)
        if critical_node_issues > 0:
            error_msg = f"Test failed: found {critical_node_issues} node(s) with OOM/cores"
            pytest.fail(error_msg)
        
        # --- 2. FAIL Ð•Ð¡Ð›Ð˜ Ð’Ð¡Ð• Ð˜Ð¢Ð•Ð ÐÐ¦Ð˜Ð˜ ÐÐ• Ð’Ð«ÐŸÐžÐ›ÐÐ˜Ð›Ð˜Ð¡Ð¬ Ð£Ð¡ÐŸÐ•Ð¨ÐÐž ---
        total_iterations = len(result.iterations)
        if total_iterations > 0:
            # Ð¡Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼ ÑƒÑÐ¿ÐµÑˆÐ½Ñ‹Ðµ Ð¸Ñ‚ÐµÑ€Ð°Ñ†Ð¸Ð¸ (Ð±ÐµÐ· Ð¾ÑˆÐ¸Ð±Ð¾Ðº Ð² stderr)
            successful_iterations = 0
            for iteration in result.iterations.values():
                if hasattr(iteration, 'stderr') and iteration.stderr:
                    stderr_clean = iteration.stderr.strip()
                    if not stderr_clean or stderr_clean == "warning: permanently added":
                        successful_iterations += 1
                else:
                    successful_iterations += 1
            
            if successful_iterations == 0:
                pytest.fail("Test failed: all iterations failed to execute successfully")
        
        # --- 3. WARNING Ð•Ð¡Ð›Ð˜ Ð•Ð¡Ð¢Ð¬ TIMEOUT (Ð½Ð¾ Ð½Ðµ fail) ---
        timeout_iterations = sum(1 for iteration in result.iterations.values() 
                               if hasattr(iteration, 'error_message') and 
                               'timeout' in iteration.error_message.lower())
        if timeout_iterations > 0:
            logging.warning(f"Test completed with {timeout_iterations} timeout iterations")
        
        # --- 4. PASS - Ð²ÑÐµ Ð¾ÑÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ðµ ÑÐ»ÑƒÑ‡Ð°Ð¸ ---
        logging.info("Test completed successfully")
        
        # Ð›Ð¾Ð³Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ñ€ÐµÐ´ÑƒÐ¿Ñ€ÐµÐ¶Ð´ÐµÐ½Ð¸Ñ ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ
        if result.warning_message:
            logging.warning(f"Workload completed with warnings: {result.warning_message}")

    def _upload_results(self, result, workload_name):
        stats = result.get_stats(workload_name)
        if stats is not None:
            stats["aggregation_level"] = "aggregate"
            stats["run_id"] = ResultsProcessor.get_run_id()
        end_time = time()
        ResultsProcessor.upload_results(
            kind='Load',
            suite=type(self).suite(),
            test=workload_name,
            timestamp=end_time,
            is_successful=result.success,
            statistics=stats,
        )

    def _upload_results_per_workload_run(self, result, workload_name):
        suite = type(self).suite()
        agg_stats = result.get_stats(workload_name)
        nemesis_enabled = agg_stats.get("nemesis_enabled") if agg_stats else None
        run_id = ResultsProcessor.get_run_id()
        for iter_num, iteration in result.iterations.items():
            runs = getattr(iteration, "runs", None) or [iteration]
            for run_idx, run in enumerate(runs):
                if getattr(run, "error_message", None):
                    resolution = "error"
                elif getattr(run, "warning_message", None):
                    resolution = "warning"
                elif hasattr(run, "timeout") and run.timeout:
                    resolution = "timeout"
                else:
                    resolution = "ok"

                stats = {
                    "iteration": iter_num,
                    "run_index": run_idx,
                    "duration": getattr(run, "time", None),
                    "resolution": resolution,
                    "error_message": getattr(run, "error_message", None),
                    "warning_message": getattr(run, "warning_message", None),
                    "nemesis_enabled": nemesis_enabled,
                    "aggregation_level": "per_run",
                    "run_id": run_id,
                }
                ResultsProcessor.upload_results(
                    kind='Stress',
                    suite=suite,
                    test=f"{workload_name}__iter_{iter_num}__run_{run_idx}",
                    timestamp=time(),
                    is_successful=(resolution == "ok"),
                    duration=stats["duration"],
                    statistics=stats,
                )

    def process_workload_result_with_diagnostics(self, result, workload_name, check_scheme=True, use_node_subcols=False):
        """
        ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ workload Ñ Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸ÐµÐ¼ Ð´Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð¹ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸
        """
        # 1. Ð¡Ð±Ð¾Ñ€ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð¾Ð² workload
        workload_params = self._collect_workload_params(result, workload_name)

        # 2. Ð”Ð¸Ð°Ð³Ð½Ð¾ÑÑ‚Ð¸ÐºÐ° Ð½Ð¾Ð´ (cores/oom)
        node_errors = self._diagnose_nodes(result, workload_name)

        # --- Ð’ÐÐ–ÐÐž: Ð²Ñ‹ÑÑ‚Ð°Ð²Ð»ÑÐµÐ¼ nodes_with_issues Ð´Ð»Ñ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ð¾Ð³Ð¾ fail ---
        stats = result.get_stats(workload_name)
        if stats is not None:
            result.add_stat(workload_name, "nodes_with_issues", len(node_errors))

        # 3. Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ summary/ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸
        self._update_summary_flags(result, workload_name)

        # 4. Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ allure-Ð¾Ñ‚Ñ‡Ñ‘Ñ‚Ð°
        self._create_allure_report(result, workload_name, workload_params, node_errors, use_node_subcols)

        # 5. ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¾ÑˆÐ¸Ð±Ð¾Ðº/ÑÑ‚Ð°Ñ‚ÑƒÑÐ¾Ð² (fail, broken, etc)
        self._handle_final_status(result, workload_name, node_errors)

        # 6. Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð°Ð³Ñ€ÐµÐ³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð²
        self._upload_results(result, workload_name)
        # 7. Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² Ð¿Ð¾ ÐºÐ°Ð¶Ð´Ð¾Ð¼Ñƒ Ð·Ð°Ð¿ÑƒÑÐºÑƒ workload
        self._upload_results_per_workload_run(result, workload_name)


class LoadSuiteParallel(LoadSuiteBase):
    threads: int = 0

    @classmethod
    def get_query_list(cls) -> list[str]:
        return []

    @classmethod
    def get_path(cls) -> str:
        return ''

    __results: dict[str, YdbCliHelper.WorkloadRunResult] = {}

    @classmethod
    def do_setup_class(cls):
        qparams = cls._get_query_settings()
        cls.save_nodes_state()
        cls.__results = YdbCliHelper.workload_run(
            path=cls.get_path(),
            query_names=cls.get_query_list(),
            iterations=qparams.iterations,
            workload_type=cls.workload_type,
            timeout=qparams.timeout,
            check_canonical=cls.check_canonical,
            query_syntax=cls.query_syntax,
            scale=cls.scale,
            query_prefix=qparams.query_prefix,
            external_path=cls.get_external_path(),
            threads=cls.threads,
            users=cls.get_users(),
        )

    def test(self, query_name):
        self.process_query_result(result=self.__results[query_name], query_name=query_name, upload=True)


def pytest_generate_tests(metafunc):
    if issubclass(metafunc.cls, LoadSuiteParallel):
        metafunc.parametrize("query_name", metafunc.cls.get_query_list() + ["Sum"])
