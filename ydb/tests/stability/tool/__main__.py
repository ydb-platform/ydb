# -*- coding: utf-8 -*-

from concurrent.futures import ThreadPoolExecutor
import getpass
import os
import logging
import tempfile
import stat
import sys
import argparse
import re
from argparse import RawTextHelpFormatter

from library.python import resource

logging.getLogger().setLevel(logging.INFO)
logging.getLogger().addHandler(logging.StreamHandler(sys.stderr))

from ydb.tests.library.harness.kikimr_cluster import ExternalKiKiMRCluster # noqa
from ydb.tests.library.wardens.factories import safety_warden_factory, liveness_warden_factory # noqa

logger = logging.getLogger('ydb.connection')
logger.setLevel(logging.CRITICAL)
logger = logging.getLogger(__name__)


STRESS_BINARIES_DEPLOY_PATH = '/Berkanavt/nemesis/bin/'

# Define a simpler approach to timestamping
DATE_FORMAT = '%Y-%m-%d %H:%M:%S.%N'

# Simplified timestamp wrapper that doesn't use nested quotes
TIMESTAMP_WRAPPER_CMD = "timestamp_cmd() { while IFS= read -r line; do d=$(TZ=UTC date +'%Y-%m-%d %H:%M:%S.%N'); printf \"[%s] %s\\n\" \"$d\" \"$line\"; done; }; timestamp_cmd"

DICT_OF_SERVICES = {
    'nemesis' : {
        'status': """
            if systemctl is-active --quiet nemesis; then
                echo "Running"
            else
                echo "Stopped"
            fi""",
        'start_command' : "sudo service nemesis restart",
        'stop_command' : "sudo service nemesis stop"
    }

}

DICT_OF_PROCESSES = {
    'olap_workload' : {
        'status' : """
            if ps aux | grep -E "/Berkanavt/nemesis/bin/olap_workload|/tmp/olap_workload_wrapper.sh" | grep -v grep > /dev/null; then
                echo "Running"
            else
                echo "Stopped"
            fi"""
    },
    'oltp_workload' : {
        'status' : """
            if ps aux | grep -E "/Berkanavt/nemesis/bin/oltp_workload|/tmp/oltp_workload_wrapper.sh" | grep -v grep > /dev/null; then
                echo "Running"
            else
                echo "Stopped"
            fi""",
    },
    'node_broker_workload': {
        'status': """
            if ps aux | grep -E "/Berkanavt/nemesis/bin/node_broker_workload|/tmp/node_broker_workload_wrapper.sh" | grep -v grep > /dev/null; then
                echo "Running"
            else
                echo "Stopped"
            fi""",
    },
    'transfer_workload_row': {
        'status': """
            if ps aux | grep -E "/Berkanavt/nemesis/bin/transfer_workload.*mode row|/tmp/transfer_workload_row_wrapper.sh" | grep -v grep > /dev/null; then
                echo "Running"
            else
                echo "Stopped"
            fi""",
    },
    'transfer_workload_column': {
        'status': """
            if ps aux | grep -E "/Berkanavt/nemesis/bin/transfer_workload.*mode column|/tmp/transfer_workload_column_wrapper.sh" | grep -v grep > /dev/null; then
                echo "Running"
            else
                echo "Stopped"
            fi""",
    },
    's3_backups_workload': {
        'status': """
            if ps aux | grep -E "/Berkanavt/nemesis/bin/s3_backups_workload|/tmp/s3_backups_workload_wrapper.sh" | grep -v grep > /dev/null; then
                echo "Running"
            else
                echo "Stopped"
            fi""",
    },
    'simple_queue_column': {
        'status': """
            if ps aux | grep -E "/Berkanavt/nemesis/bin/simple_queue.*mode column|/tmp/simple_queue_column_wrapper.sh" | grep -v grep > /dev/null; then
                echo "Running"
            else
                echo "Stopped"
            fi"""
    },
    'simple_queue_row' : {
        'status' : """
            if ps aux | grep -E "/Berkanavt/nemesis/bin/simple_queue.*mode row|/tmp/simple_queue_row_wrapper.sh" | grep -v grep > /dev/null; then
                echo "Running"
            else
                echo "Stopped"
            fi"""
    },
    'workload_log_column' : {
        'status' : """
            if ps aux | grep -E "/Berkanavt/nemesis/bin/ydb_cli.*workload.*log.*run.*bulk_upsert.*log_workload_column|/tmp/workload_log_column_wrapper.sh" | grep -v grep > /dev/null; then
                echo "Running"
            else
                echo "Stopped"
            fi"""
    },
    'workload_log_row' : {
        'status' : """
            if ps aux | grep -E "/Berkanavt/nemesis/bin/ydb_cli.*workload.*log.*run.*bulk_upsert.*log_workload_row|/tmp/workload_log_row_wrapper.sh" | grep -v grep > /dev/null; then
                echo "Running"
            else
                echo "Stopped"
            fi"""
    },
    'workload_log_column_select' : {
        'status' : """
            if ps aux | grep -E "/Berkanavt/nemesis/bin/ydb_cli.*workload.*log.*run.*select.*log_workload_column|/tmp/workload_log_column_select_wrapper.sh" | grep -v grep > /dev/null; then
                echo "Running"
            else
                echo "Stopped"
            fi"""
    },
    'workload_log_row_select' : {
        'status' : """
            if ps aux | grep -E "/Berkanavt/nemesis/bin/ydb_cli.*workload.*log.*run.*select.*log_workload_row|/tmp/workload_log_row_select_wrapper.sh" | grep -v grep > /dev/null; then
                echo "Running"
            else
                echo "Stopped"
            fi"""
    },
    'workload_topic' : {
        'status' : """
            if ps aux | grep -E "/Berkanavt/nemesis/bin/ydb_cli.*workload.*topic.*run.*|/tmp/workload_topic.sh" | grep -v grep > /dev/null; then
                echo "Running"
            else
                echo "Stopped"
            fi"""
    }
}


# –°–æ–∑–¥–∞–µ–º –∫–∞—Å—Ç–æ–º–Ω—ã–π –∫–ª–∞—Å—Å ArgumentParser –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π –æ–± –æ—à–∏–±–∫–∞—Ö
class CustomArgumentParser(argparse.ArgumentParser):
    def error(self, message):
        # –ï—Å–ª–∏ –æ—à–∏–±–∫–∞ —Å–≤—è–∑–∞–Ω–∞ —Å –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç–∞ --name
        if "--name" in message:
            workload_choices = list(DICT_OF_PROCESSES.keys())
            self.print_usage(sys.stderr)
            self.exit(2, f"{self.prog}: error: {message}\n\nAvailable workload names:\n" +
                      "\n".join(f"  - {choice}" for choice in workload_choices) + "\n")
        # –ï—Å–ª–∏ –æ—à–∏–±–∫–∞ —Å–≤—è–∑–∞–Ω–∞ —Å –Ω–µ–≤–µ—Ä–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º –¥–ª—è ACTION
        elif "ACTION" in message and "invalid choice" in message:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è –Ω–∞ –º–æ–º–µ–Ω—Ç –≤—ã–∑–æ–≤–∞
            actions_help = {
                "get_errors": "Show all errors from YDB logs",
                "get_errors_aggr": "Show aggregated errors from YDB logs (grouped by similarity)",
                "get_errors_last": "Show only the most recent errors from YDB logs",
                "get_state": "Display current state of all services and workloads",
                "clean_workload": "Clean the database objects for a specific workload (requires --name)",
                "cleanup": "Clean all logs and dumps",
                "cleanup_logs": "Clean only logs",
                "cleanup_dumps": "Clean only core dumps",
                "deploy_ydb": "Deploy YDB cluster and configure it",
                "deploy_tools": "Deploy workload tools to the cluster nodes",
                "start_nemesis": "Start the nemesis service",
                "stop_nemesis": "Stop the nemesis service",
                "start_default_workloads": "Start all default workloads on the cluster",
                "start_workload_simple_queue_row": "Start simple_queue workload with row storage",
                "start_workload_simple_queue_column": "Start simple_queue workload with column storage",
                "start_workload_olap_workload": "Start OLAP workload for analytical load testing",
                "start_workload_oltp_workload": "Start OLTP workload for transactional load testing",
                "start_workload_node_broker_workload": "Start Node Broker workload",
                "start_workload_transfer_workload": "Start topic to table transfer workload",
                "start_workload_s3_backups_workload": "Start auto removal of tmp tables workload",
                "start_workload_log": "Start log workloads with both row and column storage",
                "start_workload_log_column": "Start log workload with column storage",
                "start_workload_log_row": "Start log workload with row storage",
                "start_workload_topic": "Start topic workload",
                "stop_workloads": "Stop all workloads",
                "stop_workload": "Stop a specific workload (requires --name)",
                "perform_checks": "Run safety and liveness checks on the cluster",
                "get_workload_outputs": "Show output from workload processes (supports --mode and --last_n_lines)"
            }

            self.print_usage(sys.stderr)
            self.exit(2, f"{self.prog}: error: {message}\n\nAvailable actions:\n" +
                      "\n".join(f"  - {action}" for action in sorted(actions_help.keys())) + "\n")
        # –ï—Å–ª–∏ –æ—à–∏–±–∫–∞ —Å–≤—è–∑–∞–Ω–∞ —Å –∞—Ä–≥—É–º–µ–Ω—Ç–æ–º --mode
        elif "--mode" in message:
            self.print_usage(sys.stderr)
            self.exit(2, f"{self.prog}: error: {message}\n\nAvailable modes for --mode:\n" +
                      "  - out (show stdout only)\n" +
                      "  - err (show stderr/errors only, default)\n" +
                      "  - all (show both stdout and stderr)\n")
        else:
            super().error(message)


class bcolors:
    HEADER = '\033[95m'
    OKBLUE = '\033[94m'
    OKCYAN = '\033[96m'
    OKGREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'


class StabilityCluster:
    def __init__(self, ssh_username, cluster_path, ydbd_path=None, ydbd_next_path=None, yaml_config=None):
        self.working_dir = os.path.join(tempfile.gettempdir(), "ydb_stability")
        os.makedirs(self.working_dir, exist_ok=True)
        self.ssh_username = ssh_username
        self.slice_directory = cluster_path
        self.ydbd_path = ydbd_path
        self.ydbd_next_path = ydbd_next_path
        self.yaml_config = yaml_config

        self.artifacts = (
            self._unpack_resource('nemesis'),
            self._unpack_resource('simple_queue'),
            self._unpack_resource('olap_workload'),
            self._unpack_resource('oltp_workload'),
            self._unpack_resource('node_broker_workload'),
            self._unpack_resource('transfer_workload'),
            self._unpack_resource('s3_backups_workload'),
            self._unpack_resource('statistics_workload'),
            self._unpack_resource('ydb_cli'),
        )

        if self.yaml_config is None:
            self.kikimr_cluster = ExternalKiKiMRCluster(
                cluster_template=self.slice_directory,
                kikimr_configure_binary_path=self._unpack_resource("cfg"),
                kikimr_path=self.ydbd_path,
                kikimr_next_path=self.ydbd_next_path,
                ssh_username=self.ssh_username,
                deploy_cluster=True,
            )
        else:
            self.kikimr_cluster = ExternalKiKiMRCluster(
                cluster_template=self.slice_directory,
                kikimr_configure_binary_path=None,
                kikimr_path=self.ydbd_path,
                kikimr_next_path=self.ydbd_next_path,
                ssh_username=self.ssh_username,
                yaml_config=self.yaml_config,
            )

    def _unpack_resource(self, name):
        res = resource.find(name)
        path_to_unpack = os.path.join(self.working_dir, name)
        with open(path_to_unpack, "wb") as f:
            f.write(res)

        st = os.stat(path_to_unpack)
        os.chmod(path_to_unpack, st.st_mode | stat.S_IEXEC)
        return path_to_unpack

    def clean_trace(self, traces):
        cleaned_lines = []
        for line in traces.split('\n'):
            line = re.sub(r' @ 0x[a-fA-F0-9]+', '', line)
            # –£–±–∏—Ä–∞–µ–º –≤—Å–µ –¥–æ —Ç–µ–∫—Å—Ç–∞ –æ—à–∏–±–∫–∏ –∏–ª–∏ —É–∫–∞–∑–∞—Ç–µ–ª—è –Ω–∞ —Å—Ç—Ä–æ–∫—É –∫–æ–¥–∞
            match_verify = re.search(r'VERIFY|FAIL|signal 11|signal 6|signal 15|uncaught exception|ERROR: AddressSanitizer|SIG', line)
            match_code_file_line = re.search(r'\s+(\S+\.cpp:\d+).*', line)

            if match_verify:
                cleaned_lines.append(match_verify.group())
            elif match_code_file_line:
                cleaned_lines.append(match_code_file_line.group())

        return "\n".join(cleaned_lines)

    def is_sublist(self, shorter, longer):
        """ Check if 'shorter' is a sublist in 'longer' from the start """
        return longer[:len(shorter)] == shorter

    def find_unique_traces_with_counts(self, all_traces):
        clean_traces_dict = {}
        unique_traces = {}

        for trace in all_traces:
            clean_trace = self.clean_trace(trace)
            if clean_traces_dict.get(clean_trace):
                clean_traces_dict[clean_trace].append(trace)
            else:
                clean_traces_dict[clean_trace] = [trace]

        clean_traces_dict = dict(sorted(clean_traces_dict.items(), key=lambda item: len(item[0])))
        for trace in clean_traces_dict:
            for unique in unique_traces:
                if self.is_sublist(trace, unique):
                    unique_traces[unique] = unique_traces[unique] + clean_traces_dict[trace]
                    break
                elif self.is_sublist(unique, trace):
                    unique_traces[trace] = unique_traces[unique] + clean_traces_dict[trace]
                    del unique_traces[unique]
                    break
            if not unique_traces.get(trace):
                unique_traces[trace] = clean_traces_dict[trace]

        return dict(sorted(unique_traces.items(), key=lambda item: len(item[1]), reverse=True))

    def process_lines(self, text):
        traces = []
        trace = ""
        for host in text:
            host = host.split('\n')
            for line in host:
                if line in ("--", "\n", ""):
                    traces.append(trace)
                    trace = ""
                else:
                    trace = trace + line + '\n'
        return traces

    def get_all_errors(self, mode='all'):
        all_results = []
        if mode == 'all' or mode == 'raw' or mode == 'aggr':
            command = """
                    ls -ltr /Berkanavt/kikim*/logs/kikimr* |
                    awk '{print $NF}' |
                    while read file; do
                    case "$file" in
                        *.txt) cat "$file" ;;
                        *.gz) zcat "$file" ;;
                        *) cat "$file" ;;
                    esac
                    done |
                    grep -E 'VERIFY|FAIL |signal 11|signal 6|signal 15|uncaught exception|ERROR: AddressSanitizer|SIG' -A 40 -B 20
                    """
        elif mode == 'last':
            command = """
                    ls -ltr /Berkanavt/kikim*/logs/kikimr |
                    awk '{print $NF}' |
                    while read file; do
                    cat "$file" | grep -E 'VERIFY|FAIL |signal 11|signal 6|signal 15|uncaught exception|ERROR: AddressSanitizer|SIG' -A 40 -B 20 | tail -120
                    echo "--"
                    done
                    """
        for node in self.kikimr_cluster.nodes.values():
            result = node.ssh_command(command, raise_on_error=False)
            if result:
                all_results.append(result.decode('utf-8'))
        all_results = self.process_lines(all_results)
        return all_results

    def get_errors(self, mode='raw'):
        errors = self.get_all_errors(mode=mode)
        if mode == 'raw' or mode == 'last':
            print('Traces:')
            for trace in errors:
                print(f"{trace}\n{'-'*60}")
        else:
            unique_traces = self.find_unique_traces_with_counts(errors)
            for trace in unique_traces:
                print(f"Trace (Occurrences: {len(unique_traces[trace])}):\n{trace}\n{'-'*60}")

    def perform_checks(self):
        safety_violations = safety_warden_factory(self.kikimr_cluster, self.ssh_username, lines_after=20, cut=False, modification_days=3).list_of_safety_violations()
        liveness_violations = liveness_warden_factory(self.kikimr_cluster, self.ssh_username).list_of_liveness_violations
        coredumps_search_results = {}
        for node in self.kikimr_cluster.nodes.values():
            result = node.ssh_command('find /coredumps/ -type f | wc -l', raise_on_error=False)
            coredumps_search_results[node.host.split(':')[0]] = int(result.decode('utf-8'))
        minidumps_search_results = {}
        for node in self.kikimr_cluster.nodes.values():
            result = node.ssh_command('''
            if [ -d "/Berkanavt/minidumps/" ]; then
                find /Berkanavt/minidumps/ -type f | wc -l
                else
                echo 0
            fi
            ''', raise_on_error=False)
            minidumps_search_results[node.host.split(':')[0]] = int(result.decode('utf-8'))

        print("SAFETY WARDEN:")
        for i, violation in enumerate(safety_violations):
            print("[{}]".format(i))
            print(violation.replace('\n\n', '\n'))

        print("LIVENESS WARDEN:")
        for i, violation in enumerate(liveness_violations):
            print("[{}]".format(i))
            print(violation)

        print("SAFETY WARDEN (total: {})".format(len(safety_violations)))
        print("LIVENESS WARDEN (total: {})".format(len(liveness_violations)))
        print("COREDUMPS:")
        for node in coredumps_search_results:
            print(f'    {node}: {coredumps_search_results[node]}')
        print("MINIDUMPS:")
        for node in coredumps_search_results:
            print(f'    {node}: {minidumps_search_results[node]}')

    def start_nemesis(self):
        self.prepare_config_files()
        with ThreadPoolExecutor() as pool:
            pool.map(lambda node: node.ssh_command(DICT_OF_SERVICES['nemesis']['start_command'], raise_on_error=True), self.kikimr_cluster.nodes.values())

    def stop_workloads_all_nodes(self):
        with ThreadPoolExecutor() as pool:
            pool.map(self.stop_workloads, self.kikimr_cluster.nodes.values())

    def stop_workloads(self, node):
        # –°–Ω–∞—á–∞–ª–∞ –ø–æ–ª—É—á–∏–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö screen —Å–µ—Å—Å–∏–π –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
        screen_sessions = node.ssh_command(
            'screen -ls || true',  # || true to handle case when no screens exist
            raise_on_error=False
        )

        if screen_sessions:
            screen_output = screen_sessions.decode('utf-8')
            print(f"{bcolors.OKCYAN}Debug: Screen sessions before cleanup:{bcolors.ENDC}")
            for line in screen_output.splitlines():
                print(f"{bcolors.OKCYAN}  {line}{bcolors.ENDC}")

            # –ü—Ä–∞–≤–∏–ª—å–Ω–æ –∑–∞–≤–µ—Ä—à–∞–µ–º –∫–∞–∂–¥—É—é screen-—Å–µ—Å—Å–∏—é - –∂–∏–≤—É—é –∏ –º–µ—Ä—Ç–≤—É—é
            node.ssh_command(
                'screen -ls | grep -E "(Detached|Dead)" | cut -f1 -d"." | xargs -r kill -9',
                raise_on_error=False
            )

            # –ü—ã—Ç–∞–µ–º—Å—è –æ—á–∏—Å—Ç–∏—Ç—å –º–µ—Ä—Ç–≤—ã–µ —Å–µ—Å—Å–∏–∏
            node.ssh_command(
                'screen -wipe',
                raise_on_error=False
            )

        # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π —É–±–∏–≤–∞–µ–º –≤—Å–µ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ—Ü–µ—Å—Å—ã —Ä–∞–±–æ—á–∏—Ö –Ω–∞–≥—Ä—É–∑–æ–∫
        node.ssh_command(
            'pkill -f "SCREEN.*workload\\|simple_queue\\|olap_workload\\|oltp_workload\\|node_broker_workload\\|transfer_workload\\|s3_backups_workload"',
            raise_on_error=False
        )

        # –£–±–∏–≤–∞–µ–º –≤—Å–µ wrapper-—Å–∫—Ä–∏–ø—Ç—ã
        node.ssh_command(
            'pkill -f "_wrapper.sh"',
            raise_on_error=False
        )

        # –ù–∞–¥–µ–∂–Ω–æ —É–±–∏–≤–∞–µ–º –≤—Å–µ –æ—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ—Ü–µ—Å—Å—ã —Ä–∞–±–æ—á–∏—Ö –Ω–∞–≥—Ä—É–∑–æ–∫
        for workload_pattern in [
            "/Berkanavt/nemesis/bin/simple_queue",
            "/Berkanavt/nemesis/bin/olap_workload",
            "/Berkanavt/nemesis/bin/oltp_workload",
            "/Berkanavt/nemesis/bin/ydb_cli.*workload.*log.*run",
            "/Berkanavt/nemesis/bin/ydb_cli.*workload.*topic.*"
        ]:
            node.ssh_command(
                f'pkill -9 -f "{workload_pattern}"',
                raise_on_error=False
            )

        # –ù–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –ø–æ–ø—Ä–æ–±—É–µ–º –µ—â–µ —Ä–∞–∑ —É–±–∏—Ç—å –≤—Å–µ screen
        node.ssh_command(
            'sudo pkill screen',
            raise_on_error=False
        )

        # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞, –æ—Å—Ç–∞–ª–∏—Å—å –ª–∏ –∫–∞–∫–∏–µ-—Ç–æ —Å–µ—Å—Å–∏–∏
        after_sessions = node.ssh_command(
            'screen -ls || true',
            raise_on_error=False
        )

        if after_sessions:
            after_output = after_sessions.decode('utf-8')
            if "No Sockets found" not in after_output:
                print(f"{bcolors.WARNING}Warning: Some screen sessions still exist after cleanup:{bcolors.ENDC}")
                for line in after_output.splitlines():
                    print(f"{bcolors.WARNING}  {line}{bcolors.ENDC}")
            else:
                print(f"{bcolors.OKGREEN}All screen sessions cleaned up successfully.{bcolors.ENDC}")

    def stop_workload(self, workload_name):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Ä–∞–±–æ—á–µ–π –Ω–∞–≥—Ä—É–∑–∫–∏ –Ω–∞ –≤—Å–µ—Ö —É–∑–ª–∞—Ö"""
        if workload_name not in DICT_OF_PROCESSES:
            print(f"{bcolors.FAIL}–û—à–∏–±–∫–∞: –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π workload '{workload_name}'{bcolors.ENDC}")
            return

        print(f"{bcolors.BOLD}{bcolors.HEADER}=== –û—Å—Ç–∞–Ω–æ–≤–∫–∞ {workload_name} –Ω–∞ –≤—Å–µ—Ö nodes ==={bcolors.ENDC}")

        for node in self.kikimr_cluster.nodes.values():
            node_host = node.host.split(':')[0]
            print(f"{bcolors.BOLD}–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º {workload_name} –Ω–∞ {node_host}:{bcolors.ENDC}")

            # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Å–≤—è–∑–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ü–µ—Å—Å—ã —Å —ç—Ç–æ–π —Ä–∞–±–æ—á–µ–π –Ω–∞–≥—Ä—É–∑–∫–æ–π
            node.ssh_command(
                f"pkill -9 -f '/tmp/{workload_name}_wrapper.sh'",
                raise_on_error=False
            )

            # –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤—Å–µ—Ö screen-—Å–µ—Å—Å–∏–π —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º –∏–º–µ–Ω–µ–º, –≤–∫–ª—é—á–∞—è –º–µ—Ä—Ç–≤—ã–µ (Dead)
            node.ssh_command(
                f"screen -ls | grep -E '(Detached|Dead).*{workload_name}' | cut -f1 -d'.' | xargs -r kill -9",
                raise_on_error=False
            )

            # –ü—ã—Ç–∞–µ–º—Å—è —É–¥–∞–ª–∏—Ç—å –º–µ—Ä—Ç–≤—ã–µ —Å–µ—Å—Å–∏–∏ –Ω–∞–ø—Ä—è–º—É—é
            node.ssh_command(
                "screen -wipe",
                raise_on_error=False
            )

            # –£–±–∏–≤–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å—ã —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–π —Ä–∞–±–æ—á–µ–π –Ω–∞–≥—Ä—É–∑–∫–∏, –Ω—É–∂–Ω—ã–π —à–∞–±–ª–æ–Ω –±–µ—Ä–µ–º –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            status_cmd = DICT_OF_PROCESSES[workload_name]['status']
            grep_pattern = next((line for line in status_cmd.split('\n') if 'grep' in line and '-v grep' not in line), '')
            if grep_pattern:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —à–∞–±–ª–æ–Ω grep –∏–∑ –∫–æ–º–∞–Ω–¥—ã –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∞—Ç—É—Å–∞
                grep_parts = grep_pattern.split('grep')
                if len(grep_parts) > 1:
                    pattern = grep_parts[1].strip().replace('"', '').replace("'", "").split('|')[0]
                    node.ssh_command(
                        f"pkill -9 -f '{pattern}'",
                        raise_on_error=False
                    )

            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ –∏–º–µ–Ω–∏ –Ω–∞–≥—Ä—É–∑–∫–∏
            node.ssh_command(
                f"ps aux | grep -E '{workload_name}|{workload_name.replace('_', '.*')}' | grep -v grep | awk '{{print $2}}' | xargs -r kill -9",
                raise_on_error=False
            )

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            result = node.ssh_command(DICT_OF_PROCESSES[workload_name]['status'], raise_on_error=False)
            status = result.decode('utf-8').replace('\n', '')
            if status == 'Stopped':
                print(f"{bcolors.OKGREEN}Workload {workload_name} —É—Å–ø–µ—à–Ω–æ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –Ω–∞ {node_host}{bcolors.ENDC}")
            else:
                print(f"{bcolors.FAIL}–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å {workload_name} –Ω–∞ {node_host}, —Å—Ç–∞—Ç—É—Å: {status}{bcolors.ENDC}")

        print(f"{bcolors.OKGREEN}–ó–∞–≤–µ—Ä—à–µ–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ {workload_name} –Ω–∞ –≤—Å–µ—Ö —É–∑–ª–∞—Ö{bcolors.ENDC}")

    def stop_nemesis(self):
        print(f"{bcolors.BOLD}{bcolors.HEADER}=== –û–°–¢–ê–ù–û–í–ö–ê NEMESIS ==={bcolors.ENDC}")

        # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º nemesis –Ω–∞ –≤—Å–µ—Ö –Ω–æ–¥–∞—Ö
        with ThreadPoolExecutor() as pool:
            pool.map(lambda node: node.ssh_command(DICT_OF_SERVICES['nemesis']['stop_command'], raise_on_error=False), self.kikimr_cluster.nodes.values())

        print(f"{bcolors.OKGREEN}Nemesis –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –Ω–∞ –≤—Å–µ—Ö –Ω–æ–¥–∞—Ö{bcolors.ENDC}")

        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∫–ª–∞—Å—Ç–µ—Ä –ø–æ—Å–ª–µ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ nemesis
        print(f"\n{bcolors.BOLD}{bcolors.OKCYAN}=== –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–û–ï –í–û–°–°–¢–ê–ù–û–í–õ–ï–ù–ò–ï –ü–û–°–õ–ï –û–°–¢–ê–ù–û–í–ö–ò NEMESIS ==={bcolors.ENDC}")
        self.restore_cluster()

    def restore_cluster(self):
        """
        –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Å–µ—Ç–µ–≤—É—é —Å–≤—è–∑–∞–Ω–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Ç–µ—Ä–∞, –Ω–∞—Ä—É—à–µ–Ω–Ω—É—é nemesis.
        –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ –ø–æ—Ä—Ç—ã –∏ –º–∞—Ä—à—Ä—É—Ç—ã, –Ω–µ —Ç—Ä–æ–≥–∞–µ—Ç —Å–µ—Ä–≤–∏—Å—ã YDB.
        """
        print(f"{bcolors.BOLD}{bcolors.HEADER}=== –í–û–°–°–¢–ê–ù–û–í–õ–ï–ù–ò–ï –°–ï–¢–ï–í–û–ô –°–í–Ø–ó–ê–ù–ù–û–°–¢–ò ==={bcolors.ENDC}")

        # –°—á–µ—Ç—á–∏–∫–∏ –¥–ª—è –∏—Ç–æ–≥–æ–≤–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        total_nodes = len(self.kikimr_cluster.nodes.values())
        restored_nodes = 0
        cleared_fw_rules = 0
        cleared_routes = 0
        available_ports = 0

        with ThreadPoolExecutor() as pool:
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–µ—Ç–µ–≤—É—é —Å–≤—è–∑–∞–Ω–Ω–æ—Å—Ç—å –≤—Å–µ—Ö –Ω–æ–¥ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
            results = list(pool.map(self._restore_node, self.kikimr_cluster.nodes.values()))

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        for result in results:
            if result:
                restored_nodes += 1
                cleared_fw_rules += result.get('fw_cleared', 0)
                cleared_routes += result.get('routes_cleared', 0)
                available_ports += result.get('available_ports', 0)

        # –í—ã–≤–æ–¥–∏–º –∏—Ç–æ–≥–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        print(f"\n{bcolors.BOLD}üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:{bcolors.ENDC}")
        print(f"  ‚úÖ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –Ω–æ–¥: {restored_nodes}/{total_nodes}")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–∞—Ä—É—à–µ–Ω–∏–π
        total_violations = cleared_fw_rules + cleared_routes
        if total_violations > 0:
            print(f"  üîß –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ –Ω–∞—Ä—É—à–µ–Ω–∏–π: {total_violations}")
            print(f"    ‚Ä¢ –ü—Ä–∞–≤–∏–ª ip6tables: {cleared_fw_rules}")
            print(f"    ‚Ä¢ –ù–µ–¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–∞—Ä—à—Ä—É—Ç–æ–≤: {cleared_routes}")
        else:
            print("  ‚úÖ –ù–∞—Ä—É—à–µ–Ω–∏–π –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")

        # –ò—Ç–æ–≥–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        if restored_nodes == total_nodes:
            if total_violations > 0:
                print(f"\n{bcolors.OKGREEN}üéâ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ {total_violations} –Ω–∞—Ä—É—à–µ–Ω–∏–π.{bcolors.ENDC}")
            else:
                print(f"\n{bcolors.OKGREEN}üéâ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –ù–∞—Ä—É—à–µ–Ω–∏–π –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ.{bcolors.ENDC}")
        else:
            print(f"\n{bcolors.WARNING}‚ö†Ô∏è  –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è–º–∏{bcolors.ENDC}")

    def _restore_node(self, node):
        """
        –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Å–µ—Ç–µ–≤—É—é —Å–≤—è–∑–∞–Ω–Ω–æ—Å—Ç—å –Ω–æ–¥—ã –∫–ª–∞—Å—Ç–µ—Ä–∞.
        –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ –ø–æ—Ä—Ç—ã –∏ –º–∞—Ä—à—Ä—É—Ç—ã, –Ω–µ —Ç—Ä–æ–≥–∞–µ—Ç —Å–µ—Ä–≤–∏—Å—ã YDB.

        Args:
            node: –ù–æ–¥–∞ –∫–ª–∞—Å—Ç–µ—Ä–∞ –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è

        Returns:
            dict: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –Ω–æ–¥—ã
        """
        node_host = node.host.split(':')[0]

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞
        stats = {
            'node': node_host,
            'fw_cleared': 0,
            'routes_cleared': 0,
            'available_ports': 0,
            'success': False
        }

        try:
            # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–µ—Ç–µ–≤—ã–µ –ø—Ä–∞–≤–∏–ª–∞
            fw_rules_cleared = 0
            routes_cleared = 0

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∏–ª–∞ ip6tables YDB_FW
            fw_check = node.ssh_command("sudo /sbin/ip6tables -w -L YDB_FW 2>/dev/null | grep -v 'Chain YDB_FW' | grep -v 'target' | wc -l", raise_on_error=False)
            if fw_check:
                try:
                    rules_count = int(fw_check.decode('utf-8').strip())
                    if rules_count > 0:
                        fw_result = node.ssh_command("sudo /sbin/ip6tables -w -F YDB_FW", raise_on_error=False)
                        if fw_result:
                            fw_rules_cleared = rules_count
                            print(f"    üîß –ù–∞–π–¥–µ–Ω–æ –∏ –æ—á–∏—â–µ–Ω–æ {rules_count} –ø—Ä–∞–≤–∏–ª ip6tables")
                except (ValueError, AttributeError):
                    pass

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ —É–¥–∞–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–∞—Ä—à—Ä—É—Ç—ã
            unreach_result = node.ssh_command("sudo /usr/bin/ip -6 route show | grep unreachable", raise_on_error=False)
            if unreach_result:
                unreach_routes = unreach_result.decode('utf-8').strip().split('\n')
                found_routes = 0
                for route in unreach_routes:
                    if route.strip():
                        ip_match = re.search(r'unreachable\s+([^\s]+)', route)
                        if ip_match:
                            ip = ip_match.group(1)
                            node.ssh_command(f"sudo /usr/bin/ip -6 route del unreachable {ip}", raise_on_error=False)
                            routes_cleared += 1
                            found_routes += 1

                if found_routes > 0:
                    print(f"    üîß –ù–∞–π–¥–µ–Ω–æ –∏ —É–¥–∞–ª–µ–Ω–æ {found_routes} –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–∞—Ä—à—Ä—É—Ç–æ–≤")

            # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–µ—Ç–µ–≤—É—é –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å
            ports_to_check = [2135, 2136, 8765, 19001]
            available_ports_count = 0

            for port in ports_to_check:
                port_result = node.ssh_command(f"nc -z localhost {port}", raise_on_error=False)
                if port_result:
                    available_ports_count += 1

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            stats['fw_cleared'] = fw_rules_cleared
            stats['routes_cleared'] = routes_cleared
            stats['available_ports'] = available_ports_count
            stats['success'] = True

            # –ö—Ä–∞—Ç–∫–∏–π –≤—ã–≤–æ–¥ –¥–ª—è –Ω–æ–¥—ã —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –Ω–∞—Ä—É—à–µ–Ω–∏–π
            status_icon = "‚úÖ" if stats['success'] else "‚ùå"
            violations = []
            if fw_rules_cleared > 0:
                violations.append(f"FW:{fw_rules_cleared}")
            if routes_cleared > 0:
                violations.append(f"Routes:{routes_cleared}")

            if violations:
                violations_str = f" [–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: {', '.join(violations)}]"
            else:
                violations_str = " [–ù–∞—Ä—É—à–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ]"

            print(f"{status_icon} {node_host}: Ports={available_ports_count}/4{violations_str}")

        except Exception as e:
            print(f"‚ùå {node_host}: –û—à–∏–±–∫–∞ - {e}")

        return stats

    def get_state(self):
        logging.getLogger().setLevel(logging.WARNING)
        state_objects_dic = dict(list(DICT_OF_SERVICES.items()) + list(DICT_OF_PROCESSES.items()))
        for node_id, node in enumerate(self.kikimr_cluster.nodes.values()):
            node_host = node.host.split(':')[0]
            print(f'{bcolors.BOLD}{node_host}{bcolors.ENDC}:')
            for state_object in state_objects_dic:
                try:
                    result = node.ssh_command(
                        state_objects_dic[state_object]['status'],
                        raise_on_error=True
                    )
                    status = result.decode('utf-8').replace('\n', '')
                    if status == 'Running' :
                        status = bcolors.OKGREEN + status + bcolors.ENDC
                    else:
                        status = bcolors.FAIL + status + bcolors.ENDC
                    print(f'\t{state_object}:\t{status}')
                except Exception as e:
                    print(f'\t{state_object}:\t{bcolors.FAIL}{e}{bcolors.ENDC}')

    def cleanup(self, mode='all'):
        for node in self.kikimr_cluster.nodes.values():
            if mode in ['all', 'dumps']:
                node.ssh_command('sudo find /coredumps/ -type f -exec rm -f {} +', raise_on_error=False)
                node.ssh_command('sudo find /Berkanavt/kikim*/minidumps/ -type f -exec rm -f {} +', raise_on_error=False)
                node.ssh_command('sudo find /Berkanavt/kikimr/bin/versions/ -type f -exec rm -f {} +', raise_on_error=False)
            if mode in ['all', 'logs']:
                node.ssh_command('sudo find /Berkanavt/kikim*/logs/kikimr* -type f -exec rm -f {} +', raise_on_error=False)
                node.ssh_command('sudo find /Berkanavt/nemesis/log/ -type f -exec rm -f {} +', raise_on_error=False)
        if mode in ['all', 'logs']:
            self.kikimr_cluster.cleanup_logs()

    def deploy_ydb(self):
        self.cleanup()
        self.kikimr_cluster.start()

        with open(self._unpack_resource("tbl_profile.txt")) as f:
            self.kikimr_cluster.client.console_request(f.read())

        self.kikimr_cluster.client.update_self_heal(True)

        node = list(self.kikimr_cluster.nodes.values())[0]
        node.ssh_command("/Berkanavt/kikimr/bin/kikimr admin console validator disable bootstrap", raise_on_error=True)

        self.deploy_tools()
        self.get_state()

    def deploy_node_tools(self, node):
        node.ssh_command(["sudo", "mkdir", "-p", STRESS_BINARIES_DEPLOY_PATH], raise_on_error=False)
        for artifact in self.artifacts:
            node_artifact_path = os.path.join(
                STRESS_BINARIES_DEPLOY_PATH,
                os.path.basename(
                    artifact
                )
            )
            node.copy_file_or_dir(
                artifact,
                node_artifact_path
            )
            node.ssh_command(f"sudo chmod 777 {node_artifact_path}", raise_on_error=False)

    def prepare_config_files(self):
        with ThreadPoolExecutor() as pool:
            if self.yaml_config is None:
                pool.map(lambda node: node.copy_file_or_dir(
                    self.slice_directory,
                    '/Berkanavt/kikimr/cfg/cluster.yaml'
                ), self.kikimr_cluster.nodes.values())
            else:
                pool.map(lambda node: node.copy_file_or_dir(
                    self.slice_directory,
                    '/Berkanavt/kikimr/cfg/databases.yaml'
                ), self.kikimr_cluster.nodes.values())
                pool.map(lambda node: node.copy_file_or_dir(
                    self.yaml_config,
                    '/Berkanavt/kikimr/cfg/config.yaml'
                ), self.kikimr_cluster.nodes.values())

    def deploy_tools(self):
        with ThreadPoolExecutor(len(self.kikimr_cluster.nodes)) as pool:
            pool.map(self.deploy_node_tools, self.kikimr_cluster.nodes.values())
        self.prepare_config_files()

    def get_workload_outputs(self, mode='err', last_n_lines=10):
        """Capture last N lines of output from all running workload screens."""
        logging.getLogger().setLevel(logging.WARNING)
        for node_id, node in enumerate(self.kikimr_cluster.nodes.values()):
            node_host = node.host.split(':')[0]
            print(f'\n{bcolors.BOLD}{bcolors.HEADER}=== {node_host} ==={bcolors.ENDC}')

            # First check running processes to match get_state behavior
            running_workloads = {}  # workload_name -> pid
            for workload_name, workload in DICT_OF_PROCESSES.items():
                result = node.ssh_command(workload['status'], raise_on_error=False)
                if result and 'Running' in result.decode('utf-8'):
                    # Get the PID of the screen process for this workload
                    ps_result = node.ssh_command(
                        f'ps aux | grep "[S]CREEN.*{workload_name}\\|[s]creen.*{workload_name}" | grep -v grep',
                        raise_on_error=False
                    )
                    if ps_result:
                        try:
                            pid = ps_result.decode('utf-8').split()[1]
                            running_workloads[workload_name] = pid
                            print(f"{bcolors.OKCYAN}Debug: Found screen process for {workload_name} with PID {pid}{bcolors.ENDC}")
                        except (IndexError, ValueError):
                            running_workloads[workload_name] = None
                            print(f"{bcolors.WARNING}Warning: Could not extract PID for {workload_name} from ps output:{bcolors.ENDC}")
                            print(ps_result.decode('utf-8'))

            if running_workloads:
                print(f"{bcolors.OKCYAN}Found running workloads: {', '.join(running_workloads.keys())}{bcolors.ENDC}")

            # Get list of running screen sessions with their proper names
            result = node.ssh_command(
                'screen -ls || true',  # || true to handle case when no screens exist
                raise_on_error=False
            )
            if not result:
                print(f"{bcolors.WARNING}No screen sessions found{bcolors.ENDC}")
                continue

            screens = result.decode('utf-8').strip().split('\n')
            print(f"{bcolors.OKCYAN}Debug: Found screen sessions:{bcolors.ENDC}")
            for screen in screens:
                print(f"{bcolors.OKCYAN}  {screen}{bcolors.ENDC}")

            found_screens = False
            for screen in screens:
                if not screen.strip() or 'Socket' in screen:  # Skip socket directory line
                    continue

                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –º–µ—Ä—Ç–≤—ã–µ —Å–µ—Å—Å–∏–∏
                if 'Dead' in screen:
                    continue

                # Extract PID from screen listing (format: PID..hostname)
                try:
                    screen_pid = screen.strip().split('.')[0].split('\t')[0]
                    screen_name = screen.strip().split('\t')[0].split('.')[1]
                    print(f"{bcolors.OKCYAN}Debug: Processing screen with PID {screen_pid}, name {screen_name}{bcolors.ENDC}")
                except IndexError:
                    print(f"{bcolors.WARNING}Warning: Could not extract PID from screen line: {screen}{bcolors.ENDC}")
                    continue

                # Match screen session with workload by PID
                for workload_name, pid in running_workloads.items():
                    if pid == screen_pid:
                        found_screens = True
                        print(f'\n{bcolors.BOLD}{bcolors.OKCYAN}=== {workload_name} ==={bcolors.ENDC}')

                        # Get log output - with our new approach, both stdout and stderr go to the same log file
                        log_file = f'/tmp/{workload_name}.out.log'

                        # Display all log lines if requested
                        if mode in ['out', 'all']:
                            result = node.ssh_command(
                                f'tail -n {last_n_lines} {log_file} 2>/dev/null || true',
                                raise_on_error=False
                            )
                            print(f"\n{bcolors.BOLD}{bcolors.OKGREEN}LOG OUTPUT (last {last_n_lines} lines):{bcolors.ENDC}")
                            if result:
                                output_lines = result.decode('utf-8').split('\n')
                                for line in output_lines:
                                    if line.strip():  # Skip empty lines
                                        print(line)
                            else:
                                print(f"{bcolors.WARNING}No output found{bcolors.ENDC}")

                        # Show only errors if requested
                        if mode in ['err', 'all']:
                            result = node.ssh_command(
                                f'cat {log_file} 2>/dev/null | grep -E "error:|Error:|ERROR|FATAL|WARN|WARNING|exit.*status" | tail -n {last_n_lines} || true',
                                raise_on_error=False
                            )
                            print(f"\n{bcolors.BOLD}{bcolors.FAIL}ERROR MESSAGES (last {last_n_lines} error/warning lines):{bcolors.ENDC}")
                            if result:
                                error_lines = result.decode('utf-8').split('\n')
                                for line in error_lines:
                                    if line.strip():  # Skip empty lines
                                        if 'FATAL' in line or 'exit.*status' in line:
                                            print(f"{bcolors.BOLD}{bcolors.FAIL}{line}{bcolors.ENDC}")
                                        elif 'ERROR' in line.capitalize():
                                            print(f"{bcolors.FAIL}{line}{bcolors.ENDC}")
                                        elif 'WARN' in line or 'WARNING' in line:
                                            print(f"{bcolors.WARNING}{line}{bcolors.ENDC}")
                                        else:
                                            print(line)
                            else:
                                print(f"{bcolors.WARNING}No errors found{bcolors.ENDC}")

                        # Ensure we detach from the screen session
                        node.ssh_command(f'screen -d {screen_pid} 2>/dev/null || true', raise_on_error=False)

            if not found_screens and running_workloads:
                print(f"\n{bcolors.WARNING}Warning: Found running workloads but no matching screen sessions. The workloads might be running outside of screen.{bcolors.ENDC}")
                print(f"{bcolors.WARNING}Try checking process output directly:{bcolors.ENDC}")
                for workload in running_workloads:
                    result = node.ssh_command(f'ps aux | grep "{workload}" | grep -v grep', raise_on_error=False)
                    if result:
                        print(f"\n{bcolors.OKCYAN}Process info for {workload}:{bcolors.ENDC}")
                        print(result.decode('utf-8'))

                    # Also check for wrapper script
                    script_path = f'/tmp/{workload}_wrapper.sh'
                    result = node.ssh_command(f'cat {script_path} 2>/dev/null || true', raise_on_error=False)
                    if result:
                        print(f"\n{bcolors.OKCYAN}Wrapper script for {workload}:{bcolors.ENDC}")
                        print(result.decode('utf-8'))

    def _create_workload_command(self, workload_name, command, log_file=None):
        """
        Helper function to create a properly formatted screen command for running a workload.

        Args:
            workload_name: Name of the workload (used for screen session name)
            command: The actual command to run in a loop (without TZ=UTC prefix)
            log_file: Optional custom log file path. Defaults to /tmp/{workload_name}.out.log

        Returns:
            A joined string command ready to be passed to ssh_command
        """
        if log_file is None:
            log_file = f'/tmp/{workload_name}.out.log'

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏
        has_time_limit = False
        timeout_seconds = 0  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –Ω–µ—Ç —Ç–∞–π–º–∞—É—Ç–∞

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ --duration
        if '--duration' in command:
            has_time_limit = True
            try:
                duration_parts = command.split('--duration')
                if len(duration_parts) > 1:
                    duration_value = duration_parts[1].strip().split()[0]
                    if duration_value.isdigit():
                        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ 5% –∫ duration –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Ç–∞–π–º–∞—É—Ç–∞
                        timeout_seconds = int(duration_value) * 1.05
            except Exception:
                pass

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ --seconds (–æ–Ω –∏–º–µ–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã –æ–±–∞)
        if '--seconds' in command:
            has_time_limit = True
            try:
                seconds_parts = command.split('--seconds')
                if len(seconds_parts) > 1:
                    seconds_value = seconds_parts[1].strip().split()[0]
                    if seconds_value.isdigit():
                        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ 5% –∫ seconds –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Ç–∞–π–º–∞—É—Ç–∞
                        timeout_seconds = int(seconds_value) * 1.05
            except Exception:
                pass

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç —Ä–∞–∑—É–º–Ω—ã–º–∏ –ø—Ä–µ–¥–µ–ª–∞–º–∏ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω —É–∫–∞–∑–∞–Ω
        if has_time_limit:
            if timeout_seconds < 30:
                timeout_seconds = 30  # –ú–∏–Ω–∏–º—É–º 30 —Å–µ–∫—É–Ω–¥
            elif timeout_seconds > 86400:
                timeout_seconds = 86400  # –ú–∞–∫—Å–∏–º—É–º 24 —á–∞—Å–∞

            # –ü—Ä–∏–≤–æ–¥–∏–º –∫ —Ü–µ–ª–æ–º—É —á–∏—Å–ª—É
            timeout_seconds = int(timeout_seconds)

            print(f"Debug: Set timeout for {workload_name} to {timeout_seconds} seconds")
        else:
            print(f"Debug: No timeout set for {workload_name}, it will run without time limit")

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –±–∞–∑–æ–≤—É—é –∫–æ–º–∞–Ω–¥—É –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –æ—á–∏—Å—Ç–∫–∏ –ø—Ä–∏ —Ç–∞–π–º–∞—É—Ç–µ
        base_command = command.split()[0] if command else ""

        # Create a script content with safer function-based approach
        script_content = f"""#!/bin/bash
# Auto-generated script for {workload_name}

# Define a function to add timestamps to output
timestamp_output() {{
  while IFS= read -r line; do
    current_time=$(date +'{DATE_FORMAT}')
    printf "[%s] %s\\n" "$current_time" "$line"
  done
}}

# Define cleanup function for timeout
handle_timeout() {{
  echo "[$(date +'%Y-%m-%d %H:%M:%S.%N')] TIMEOUT: Command took longer than {timeout_seconds} seconds"
  echo "[$(date +'%Y-%m-%d %H:%M:%S.%N')] Performing emergency cleanup for {workload_name}..."

  # –°–æ—Ö—Ä–∞–Ω—è–µ–º PID –ø—Ä–æ—Ü–µ—Å—Å–∞ bash, –∫–æ—Ç–æ—Ä—ã–π –∑–∞–ø—É—Å—Ç–∏–ª –∫–æ–º–∞–Ω–¥—É (–µ—Å–ª–∏ –µ—â–µ –∑–∞–ø—É—â–µ–Ω)
  PIDS=$(ps -ef | grep "{command}" | grep -v grep | grep -v timeout | awk '{{print $2}}')

  if [ -n "$PIDS" ]; then
    echo "[$(date +'%Y-%m-%d %H:%M:%S.%N')] Found processes to kill: $PIDS"
    for pid in $PIDS; do
      echo "[$(date +'%Y-%m-%d %H:%M:%S.%N')] Killing process $pid"
      kill -9 $pid 2>/dev/null || true
    done
  else
    echo "[$(date +'%Y-%m-%d %H:%M:%S.%N')] No matching processes found"
  fi

  # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –∫–æ–º–∞–Ω–¥—ã
  if [[ "{base_command}" == *"oltp_workload"* ]]; then
    echo "[$(date +'%Y-%m-%d %H:%M:%S.%N')] Performing oltp_workload specific cleanup"
    # –£–±–∏–≤–∞–µ–º Python –ø—Ä–æ—Ü–µ—Å—Å—ã, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å oltp_workload
    pkill -9 -f "oltp_workload" || true

  elif [[ "{base_command}" == *"ydb_cli"* ]] && [[ "{command}" =~ workload\\ (log|topic) ]]; then
    echo "[$(date +'%Y-%m-%d %H:%M:%S.%N')] Performing workload log specific cleanup"
    # –£–±–∏–≤–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å—ã ydb_cli workload log
    pkill -9 -f "ydb_cli.*workload.*log" || true

  elif [[ "{base_command}" == *"simple_queue"* ]]; then
    echo "[$(date +'%Y-%m-%d %H:%M:%S.%N')] Performing simple_queue specific cleanup"
    # –£–±–∏–≤–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å—ã simple_queue
    pkill -9 -f "simple_queue" || true

  elif [[ "{base_command}" == *"olap_workload"* ]]; then
    echo "[$(date +'%Y-%m-%d %H:%M:%S.%N')] Performing olap_workload specific cleanup"
    # –£–±–∏–≤–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å—ã olap_workload
    pkill -9 -f "olap_workload" || true

  elif [[ "{base_command}" == *"node_broker_workload"* ]]; then
    echo "[$(date +'%Y-%m-%d %H:%M:%S.%N')] Performing node_broker_workload specific cleanup"
    # –£–±–∏–≤–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å—ã node_broker_workload
    pkill -9 -f "node_broker_workload" || true

  elif [[ "{base_command}" == *"transfer_workload"* ]]; then
    echo "[$(date +'%Y-%m-%d %H:%M:%S.%N')] Performing transfer_workload specific cleanup"
    # –£–±–∏–≤–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å—ã transfer_workload
    pkill -9 -f "transfer_workload" || true

  elif [[ "{base_command}" == *"s3_backups_workload"* ]]; then
    echo "[$(date +'%Y-%m-%d %H:%M:%S.%N')] Performing s3_backups_workload specific cleanup"
    # –£–±–∏–≤–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å—ã s3_backups_workload
    pkill -9 -f "s3_backups_workload" || true
  fi

  echo "[$(date +'%Y-%m-%d %H:%M:%S.%N')] Emergency cleanup completed"
}}

# Trap for SIGTERM to perform cleanup if the script itself is killed
trap handle_timeout SIGTERM

# –ë–µ—Å–∫–æ–Ω–µ—á–Ω—ã–π —Ü–∏–∫–ª –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã
echo "[$(date +'%Y-%m-%d %H:%M:%S.%N')] Starting command in continuous loop: {command}"
while true; do
  echo "[$(date +'%Y-%m-%d %H:%M:%S.%N')] Running command..."
  echo "[$(date +'%Y-%m-%d %H:%M:%S.%N')] COMMAND: {command}"
  echo "[$(date +'%Y-%m-%d %H:%M:%S.%N')] === COMMAND OUTPUT START ==="

  # –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –¥–ª—è –ø–µ—Ä–µ—Ö–≤–∞—Ç–∞ –≤—ã–≤–æ–¥–∞
  # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—ã–≤–æ–¥–∞ –≤ —Å–ª—É—á–∞–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
  TMP_OUT_FILE="/tmp/{workload_name}_output_$$.log"

  if {'true' if has_time_limit else 'false'}; then
    # –ü–µ—Ä–≤—ã–π –º–µ—Ç–æ–¥: –ø—Ä—è–º–æ–π –∑–∞–ø—É—Å–∫ —Å –æ—Ç–∫–ª—é—á–µ–Ω–Ω–æ–π –±—É—Ñ–µ—Ä–∏–∑–∞—Ü–∏–µ–π
    stdbuf -o0 -e0 timeout -k 10 {timeout_seconds}s {command} 2>&1 | tee "$TMP_OUT_FILE" | while IFS= read -r line || [[ -n "$line" ]]; do
      echo "[$(date +'%Y-%m-%d %H:%M:%S.%N')] $line"
    done

    status=${{PIPESTATUS[0]}}
    LINES_COUNT=$(wc -l < "$TMP_OUT_FILE")

    # –ï—Å–ª–∏ –≤—ã–≤–æ–¥ –ø–æ—á—Ç–∏ –ø—É—Å—Ç–æ–π –∏ –∫–æ–¥ –≤–æ–∑–≤—Ä–∞—Ç–∞ –æ—à–∏–±–æ—á–Ω—ã–π, –ø—Ä–æ–±—É–µ–º –≤—Ç–æ—Ä–æ–π –º–µ—Ç–æ–¥
    if [ $status -eq 1 ] && [ $LINES_COUNT -lt 3 ]; then
      echo "[$(date +'%Y-%m-%d %H:%M:%S.%N')] Switching to script method for better output capture"
      SCRIPT_FILE="/tmp/{workload_name}_transcript_$$.txt"

      # –í—Ç–æ—Ä–æ–π –º–µ—Ç–æ–¥: –∑–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ script –¥–ª—è –ø–µ—Ä–µ—Ö–≤–∞—Ç–∞ –æ—Å–æ–±–æ–≥–æ –≤—ã–≤–æ–¥–∞
      script -q -c "timeout -k 10 {timeout_seconds}s {command}" "$SCRIPT_FILE" >/dev/null 2>&1
      status=$?

      # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –≤—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Å —Ç–∞–π–º—Å—Ç–µ–º–ø–∞–º–∏
      cat "$SCRIPT_FILE" | grep -v "^Script " | while IFS= read -r line || [[ -n "$line" ]]; do
        echo "[$(date +'%Y-%m-%d %H:%M:%S.%N')] $line"
      done

      rm -f "$SCRIPT_FILE"
    fi
  else
    # –¢–æ –∂–µ —Å–∞–º–æ–µ –¥–ª—è –∫–æ–º–∞–Ω–¥ –±–µ–∑ —Ç–∞–π–º–∞—É—Ç–∞
    stdbuf -o0 -e0 {command} 2>&1 | tee "$TMP_OUT_FILE" | while IFS= read -r line || [[ -n "$line" ]]; do
      echo "[$(date +'%Y-%m-%d %H:%M:%S.%N')] $line"
    done

    status=${{PIPESTATUS[0]}}
    LINES_COUNT=$(wc -l < "$TMP_OUT_FILE")

    if [ $status -eq 1 ] && [ $LINES_COUNT -lt 3 ]; then
      echo "[$(date +'%Y-%m-%d %H:%M:%S.%N')] Switching to script method for better output capture"
      SCRIPT_FILE="/tmp/{workload_name}_transcript_$$.txt"

      script -q -c "{command}" "$SCRIPT_FILE" >/dev/null 2>&1
      status=$?

      cat "$SCRIPT_FILE" | grep -v "^Script " | while IFS= read -r line || [[ -n "$line" ]]; do
        echo "[$(date +'%Y-%m-%d %H:%M:%S.%N')] $line"
      done

      rm -f "$SCRIPT_FILE"
    fi
  fi

  # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
  rm -f "$TMP_OUT_FILE"

  echo "[$(date +'%Y-%m-%d %H:%M:%S.%N')] === COMMAND OUTPUT END ==="

  if {'true' if has_time_limit else 'false'} && [ $status -eq 124 ]; then
    echo "[$(date +'%Y-%m-%d %H:%M:%S.%N')] WARNING: Command reached timeout after {timeout_seconds} seconds"
  fi

  echo "[$(date +'%Y-%m-%d %H:%M:%S.%N')] Command exited with status $status, restarting in 5 seconds..."

  # –ñ–¥–µ–º –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–æ–º
  sleep 5
done
"""

        # Create a temporary script path on the remote host
        script_path = f'/tmp/{workload_name}_wrapper.sh'

        # Use cat with a heredoc approach for more reliable script generation
        cmd = f"cat > {script_path} << 'EOFSCRIPT'\n{script_content}\nEOFSCRIPT\n" + \
              f"chmod +x {script_path} && screen -S {workload_name} -d -m -L -Logfile {log_file} {script_path}"

        return cmd

    def _clean_and_start_workload(self, node, workload_name, command, log_file=None):
        """
        Clean logs and start a workload.

        Args:
            node: Node to run the workload on
            workload_name: Name of the workload
            command: Command to run (without TZ=UTC prefix)
            log_file: Optional custom log file path
        """
        print(f"{bcolors.BOLD}{bcolors.HEADER}=== –ó–∞–ø—É—Å–∫ {workload_name} ==={bcolors.ENDC}")
        if log_file is None:
            log_file = f'/tmp/{workload_name}.out.log'

        # Clean log file
        node.ssh_command(['rm', '-f', log_file], raise_on_error=False)

        # Create and run command
        screen_command = self._create_workload_command(workload_name, command, log_file)
        print(f"Debug: Running command: {screen_command}")
        node.ssh_command([screen_command], raise_on_error=True)


def path_type(path):
    # Expand the user's home directory if ~ is present
    expanded_path = os.path.expanduser(path)
    # Check if the file exists
    if not os.path.exists(expanded_path):
        raise argparse.ArgumentTypeError(f"The file {expanded_path} does not exist.")
    return expanded_path


def parse_args():
    parser = CustomArgumentParser(
        description="""YDB Stability Testing Tool

This tool provides capabilities for managing and testing YDB clusters in a stability/stress testing environment.
It can deploy YDB, manage workloads, collect logs, and analyze errors.

Common usage scenarios:
1. Deploy YDB and tools:
   tool --cluster_path /path/to/cluster.yaml --ydbd_path /path/to/ydbd deploy_ydb deploy_tools

2. Start workloads:
   tool --cluster_path /path/to/cluster.yaml start_default_workloads

3. Check workload status:
   tool --cluster_path /path/to/cluster.yaml get_state

4. View workload outputs:
   tool --cluster_path /path/to/cluster.yaml get_workload_outputs --mode all

5. Stop specific workload:
   tool --cluster_path /path/to/cluster.yaml stop_workload --name olap_workload

6. Stop all workloads:
   tool --cluster_path /path/to/cluster.yaml stop_workloads
""",
        formatter_class=RawTextHelpFormatter
    )
    parser.add_argument(
        "--cluster_path",
        required=True,
        type=path_type,
        help="Path to cluster.yaml configuration file defining the cluster topology",
    )
    parser.add_argument(
        "--ydbd_path",
        required=False,
        type=path_type,
        help="Path to ydbd binary to deploy to the cluster",
    )
    parser.add_argument(
        "--next_ydbd_path",
        required=False,
        type=path_type,
        help="Path to next ydbd version binary (for cross-version testing)",
    )
    parser.add_argument(
        "--yaml-config",
        required=False,
        default=None,
        type=path_type,
        help="Path to Yandex DB configuration v2",
    )
    parser.add_argument(
        "--ssh_user",
        required=False,
        default=getpass.getuser(),
        type=str,
        help="SSH username for connecting to cluster nodes (defaults to current user)",
    )

    # Define all available actions
    actions_help = {
        "get_errors": "Show all errors from YDB logs",
        "get_errors_aggr": "Show aggregated errors from YDB logs (grouped by similarity)",
        "get_errors_last": "Show only the most recent errors from YDB logs",
        "get_state": "Display current state of all services and workloads",
        "clean_workload": "Clean the database objects for a specific workload (requires --name)",
        "cleanup": "Clean all logs and dumps",
        "cleanup_logs": "Clean only logs",
        "cleanup_dumps": "Clean only core dumps",
        "deploy_ydb": "Deploy YDB cluster and configure it",
        "deploy_tools": "Deploy workload tools to the cluster nodes",
        "start_nemesis": "Start the nemesis service",
        "stop_nemesis": "Stop the nemesis service and automatically restore cluster",
        "restore_cluster": "Restore network connectivity (ports and routes) caused by nemesis",
        "start_default_workloads": "Start all default workloads on the cluster",
        "start_workload_simple_queue_row": "Start simple_queue workload with row storage",
        "start_workload_simple_queue_column": "Start simple_queue workload with column storage",
        "start_workload_olap_workload": "Start OLAP workload for analytical load testing",
        "start_workload_oltp_workload": "Start OLTP workload for transactional load testing",
        "start_workload_node_broker_workload": "Start Node Broker workload",
        "start_workload_transfer_workload": "Start topic to table transfer workload",
        "start_workload_s3_backups_workload": "Start auto removal of tmp tables workload",
        "start_workload_log": "Start log workloads with both row and column storage",
        "start_workload_log_column": "Start log workload with column storage",
        "start_workload_log_row": "Start log workload with row storage",
        "start_workload_topic": "Start topic workload",
        "stop_workloads": "Stop all workloads",
        "stop_workload": "Stop a specific workload (requires --name)",
        "perform_checks": "Run safety and liveness checks on the cluster",
        "get_workload_outputs": "Show output from workload processes (supports --mode and --last_n_lines)"
    }

    # Group actions by categories for better readability
    action_categories = {
        "CLUSTER MANAGEMENT": [
            "deploy_ydb", "deploy_tools", "start_nemesis", "stop_nemesis",
            "restore_cluster", "get_state", "perform_checks"
        ],
        "ERROR HANDLING": [
            "get_errors", "get_errors_aggr", "get_errors_last"
        ],
        "CLEANUP": [
            "cleanup", "cleanup_logs", "cleanup_dumps", "clean_workload"
        ],
        "WORKLOAD MANAGEMENT": [
            "start_default_workloads", "stop_workloads", "stop_workload",
            "get_workload_outputs"
        ],
        "SPECIFIC WORKLOADS": [
            "start_workload_simple_queue_row", "start_workload_simple_queue_column",
            "start_workload_olap_workload",
            "start_workload_oltp_workload",
            "start_workload_node_broker_workload",
            "start_workload_transfer_workload",
            "start_workload_s3_backups_workload",
            "start_workload_log", "start_workload_log_column", "start_workload_log_row",
            "start_workload_topic",
        ]
    }

    # –°–æ–∑–¥–∞–µ–º –ø–æ–Ω—è—Ç–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–ª—è —Å–ø—Ä–∞–≤–∫–∏ —Å —á–µ—Ç–∫–∏–º–∏ –æ—Ç—Å—Ç—É–ø–∞–º–∏ –∏ –ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏ —Å—Ç—Ä–æ–∫
    actions_help_str = "Actions to execute (one or more of the following):\n"

    # –î–æ–±–∞–≤–ª—è–µ–º –¥–µ–π—Å—Ç–≤–∏—è –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º, –∫–∞–∂–¥–æ–µ —Å –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏ –∏ –æ—Ç—Å—Ç—É–ø–æ–º
    for category, actions in action_categories.items():
        actions_help_str += f"\n{category}:\n"
        for action in actions:
            description = actions_help[action]
            actions_help_str += f"  {action}\n      {description}\n"

    parser.add_argument(
        "actions",
        type=str,
        nargs="+",
        choices=list(actions_help.keys()),
        help=actions_help_str,
        metavar="ACTION",
    )

    args, unknown = parser.parse_known_args()

    # Add action-specific arguments
    if "stop_workload" in args.actions:
        workload_choices = list(DICT_OF_PROCESSES.keys())
        workload_help = "Available workloads:\n"
        for wl in workload_choices:
            workload_help += f"  {wl}\n"

        parser.add_argument(
            "--name",
            type=str,
            required=True,
            help=f"Name of the workload to stop\n{workload_help}",
            choices=workload_choices,
            metavar="WORKLOAD_NAME",
        )

    if "clean_workload" in args.actions:
        workload_choices = list(DICT_OF_PROCESSES.keys())
        workload_help = "Available workloads:\n"
        for wl in workload_choices:
            if "log_" in wl:
                workload_help += f"  {wl}\n"

        parser.add_argument(
            "--name",
            type=str,
            required=True,
            help=f"Name of the workload to clean\n{workload_help}",
            choices=workload_choices,
            metavar="WORKLOAD_NAME",
        )

    if "get_workload_outputs" in args.actions:
        parser.add_argument(
            "--last_n_lines",
            type=int,
            default=10,
            help="Number of lines to show from the end of each log (default: 10)",
            metavar="N",
        )
        parser.add_argument(
            "--mode",
            type=str,
            choices=['out', 'err', 'all'],
            default='err',
            help="Which output to show: 'out' (stdout only), 'err' (stderr only), or 'all' (both) (default: err)",
            metavar="MODE",
        )

    return parser.parse_args()


def main():
    args = parse_args()
    ssh_username = args.ssh_user
    yaml_config = args.yaml_config
    print('Initing cluster info')
    stability_cluster = StabilityCluster(
        ssh_username=ssh_username,
        cluster_path=args.cluster_path,
        ydbd_path=args.ydbd_path,
        ydbd_next_path=args.next_ydbd_path,
        yaml_config=yaml_config,
    )

    for action in args.actions:
        print(f'Start action {action}')
        if action == "get_errors":
            stability_cluster.get_errors(mode='raw')
        if action == "get_errors_aggr":
            stability_cluster.get_errors(mode='aggr')
        if action == "get_errors_last":
            stability_cluster.get_errors(mode='last')
        if action == "get_state":
            stability_cluster.get_state()
        if action == "deploy_ydb":
            stability_cluster.deploy_ydb()
        if action == "cleanup":
            stability_cluster.cleanup()
        if action == "cleanup_logs":
            stability_cluster.cleanup('logs')
        if action == "cleanup_dumps":
            stability_cluster.cleanup('dumps')
        if action == "deploy_tools":
            stability_cluster.deploy_tools()
        if action == "start_default_workloads":
            for node_id, node in enumerate(stability_cluster.kikimr_cluster.nodes.values()):
                stability_cluster._clean_and_start_workload(
                    node,
                    'simple_queue_row',
                    '/Berkanavt/nemesis/bin/simple_queue --database /Root/db1 --mode row'
                )
                stability_cluster._clean_and_start_workload(
                    node,
                    'simple_queue_column',
                    '/Berkanavt/nemesis/bin/simple_queue --database /Root/db1 --mode column'
                )
                stability_cluster._clean_and_start_workload(
                    node,
                    'olap_workload',
                    f'/Berkanavt/nemesis/bin/olap_workload --database /Root/db1 --path olap_workload_{node_id}'
                )
            stability_cluster.get_state()
        if action == "stop_workload":
            workload_name = args.name
            stability_cluster.stop_workload(workload_name)
            stability_cluster.get_state()
        if action == "clean_workload":
            workload_name = args.name
            if DICT_OF_PROCESSES.get(workload_name):
                store_type_list = []
                if 'column' in workload_name:
                    store_type_list.append('column')
                elif 'row' in workload_name:
                    store_type_list.append('row')
                else:
                    store_type_list = ['column', 'row']
                if 'log_' in workload_name:
                    first_node = stability_cluster.kikimr_cluster.nodes[1]
                    for store_type in store_type_list:
                        first_node.ssh_command([
                            '/Berkanavt/nemesis/bin/ydb_cli',
                            '--endpoint', f'grpc://localhost:{first_node.grpc_port}',
                            '--database', '/Root/db1',
                            'workload', 'log', 'clean',
                            '--path', f'log_workload_{store_type}',
                            ],
                            raise_on_error=True
                        )
                else:
                    print(f"Not supported workload clean command for {workload_name}")
            else:
                print(f"Unknown workload {workload_name}")
            stability_cluster.get_state()
        if "start_workload_log" in action:
            store_type_list = []
            if action == 'start_workload_log_column':
                store_type_list.append('column')
            elif action == 'start_workload_log_row':
                store_type_list.append('row')
            else:
                store_type_list = ['column', 'row']
            first_node = stability_cluster.kikimr_cluster.nodes[1]
            for store_type in store_type_list:
                first_node.ssh_command([
                    '/Berkanavt/nemesis/bin/ydb_cli',
                    '--endpoint', f'grpc://localhost:{first_node.grpc_port}',
                    '--database', '/Root/db1',
                    'workload', 'log', 'init',
                    '--min-partitions', '100',
                    '--partition-size', '10',
                    '--auto-partition', '0',
                    '--store', store_type,
                    '--path', f'log_workload_{store_type}',
                    '--ttl', '4800'
                    ],
                    raise_on_error=False
                )
                for node_id, node in enumerate(stability_cluster.kikimr_cluster.nodes.values()):
                    node.ssh_command(['rm', '-f', f'/tmp/workload_log_{store_type}.out.log'], raise_on_error=False)
                    stability_cluster._clean_and_start_workload(
                        node,
                        f'workload_log_{store_type}',
                        (
                            f'/Berkanavt/nemesis/bin/ydb_cli --endpoint grpc://localhost:{node.grpc_port} '
                            f'--database /Root/db1 workload log run bulk_upsert --rows 2000 --threads 10 '
                            f'--timestamp_deviation 180 --seconds 86400 --path log_workload_{store_type}'
                        )
                    )

                    node.ssh_command(['rm', '-f', f'/tmp/workload_log_{store_type}_select.out.log'], raise_on_error=False)
                    stability_cluster._clean_and_start_workload(
                        node,
                        f'workload_log_{store_type}_select',
                        (
                            f'/Berkanavt/nemesis/bin/ydb_cli --verbose --endpoint grpc://localhost:{node.grpc_port} '
                            f'--database /Root/db1 workload log run select --client-timeout 1800000 --threads 1 '
                            f'--seconds 86400 --path log_workload_{store_type}'
                        ),
                        f'/tmp/workload_log_{store_type}_select.out.log'
                    )
            stability_cluster.get_state()
        if action == "start_workload_topic":
            def run_topic_workload(node):
                node.ssh_command(['rm', '-f', '/tmp/workload_topic.out.log'], raise_on_error=False)

                stability_cluster._clean_and_start_workload(
                    node,
                    'workload_topic',
                    (
                        f'/Berkanavt/nemesis/bin/ydb_cli --verbose --endpoint grpc://localhost:{node.grpc_port} '
                        f'--database /Root/db1 workload topic run full -s 60 --byte-rate 100M --use-tx --tx-commit-interval 2000 -p 100 -c 50'
                    ),
                    '/tmp/workload_topic.out.log'
                )
            init_node = list(stability_cluster.kikimr_cluster.nodes.values())[0]
            init_node.ssh_command([
                '/Berkanavt/nemesis/bin/ydb_cli',
                '--verbose',
                '--endpoint',
                f'grpc://localhost:{init_node.grpc_port}',
                '--database',
                '/Root/db1',
                'workload',
                'topic',
                'init',
                '-c',
                '50',
                '-p',
                '100'], raise_on_error=False)
            with ThreadPoolExecutor() as pool:
                pool.map(run_topic_workload, stability_cluster.kikimr_cluster.nodes.values())
            stability_cluster.get_state()
        if action == "start_workload_simple_queue_row":
            for node_id, node in enumerate(stability_cluster.kikimr_cluster.nodes.values()):
                stability_cluster._clean_and_start_workload(
                    node,
                    'simple_queue_row',
                    '/Berkanavt/nemesis/bin/simple_queue --database /Root/db1 --mode row'
                )
            stability_cluster.get_state()
        if action == "start_workload_simple_queue_column":
            for node_id, node in enumerate(stability_cluster.kikimr_cluster.nodes.values()):
                stability_cluster._clean_and_start_workload(
                    node,
                    'simple_queue_column',
                    '/Berkanavt/nemesis/bin/simple_queue --database /Root/db1 --mode column'
                )
            stability_cluster.get_state()
        if action == "start_workload_olap_workload":
            for node_id, node in enumerate(stability_cluster.kikimr_cluster.nodes.values()):
                stability_cluster._clean_and_start_workload(
                    node,
                    'olap_workload',
                    f'/Berkanavt/nemesis/bin/olap_workload --database /Root/db1 --path olap_workload_{node_id}'
                )
            stability_cluster.get_state()
        if action == "start_workload_oltp_workload":
            for node_id, node in enumerate(stability_cluster.kikimr_cluster.nodes.values()):
                stability_cluster._clean_and_start_workload(
                    node,
                    'oltp_workload',
                    f'/Berkanavt/nemesis/bin/oltp_workload --database /Root/db1 --path {node_id}'
                )
            stability_cluster.get_state()
        if action == "start_workload_node_broker_workload":
            for node_id, node in enumerate(stability_cluster.kikimr_cluster.nodes.values()):
                stability_cluster._clean_and_start_workload(
                    node,
                    'node_broker_workload',
                    f'/Berkanavt/nemesis/bin/node_broker_workload --database /Root/db1 --mon-endpoint http://localhost:{node.mon_port}'
                )
            stability_cluster.get_state()
        if action == "start_workload_transfer_workload":
            modes = ['row', 'column']
            for node_id, node in enumerate(stability_cluster.kikimr_cluster.nodes.values()):
                for mode in modes:
                    stability_cluster._clean_and_start_workload(
                        node,
                        f'transfer_workload_{mode}',
                        f'/Berkanavt/nemesis/bin/transfer_workload --database /Root/db1 --mode {mode}'
                    )
            stability_cluster.get_state()
        if action == "start_workload_s3_backups_workload":
            for node_id, node in enumerate(stability_cluster.kikimr_cluster.nodes.values()):
                stability_cluster._clean_and_start_workload(
                    node,
                    's3_backups_workload',
                    '/Berkanavt/nemesis/bin/s3_backups_workload --database /Root/db1'
                )
            stability_cluster.get_state()
        if action == "stop_workloads":
            stability_cluster.stop_workloads_all_nodes()
            stability_cluster.get_state()

        if action == "stop_nemesis":
            stability_cluster.stop_nemesis()
            stability_cluster.get_state()

        if action == "start_nemesis":
            stability_cluster.start_nemesis()
            stability_cluster.get_state()

        if action == "restore_cluster":
            stability_cluster.restore_cluster()
            stability_cluster.get_state()

        if action == "perform_checks":
            stability_cluster.perform_checks()

        if action == "get_workload_outputs":
            stability_cluster.get_workload_outputs(mode=args.mode, last_n_lines=args.last_n_lines)


if __name__ == "__main__":
    main()
